understand hashtable performance in the worst-case the load factor denote the average expect length of a chain , therefore it be interesting for a average case analysis , not the worst case analysis . that s why on average you expect need constant time for search operation . in the worst case however , all you element hash to the same location and be part of one long chain of size <code> n </code> . then , it depend on the datum structure use to implement the chaining . if you choose a sort array , you can do binary search and the worst case complexity for search be <code> o -lrb- log n -rrb- </code> . if you choose a unsorted list , you have a worst case of <code> o -lrb- n -rrb- </code> for search . depend on you choice of datum structure , the performance -lrb- worst and average case -rrb- of insert , delete and search change . accord to <a href="http://coding-geek.com/how-does-a-hashmap-work-in-java/"> coding-geek . com </a> , java 7 s hashmap implementation use a link list -lrb- unsorted -rrb- , but java 8 use a balanced binary tree instead . of course , insert\/delete\/search in a balanced tree of size <code> n </code> have complexity <code> o -lrb- log n -rrb- </code> . 