why be loop faster than recursion ? these other answer be somewhat misleading . i agree that they state implementation detail that can explain this disparity , but they overstate the case . as correctly suggest by jmite , they be implementation-oriented toward <em> broken </em> implementation of function calls\/recursion . many language implement loop via recursion , so loop be clearly not go to be faster in those language . recursion be in no way less efficient than loop -lrb- when both be applicable -rrb- in theory . let I quote the abstract to guy steele s 1977 paper <a href="http://repository.readscheme.org/ftp/papers/ai-lab-pubs/aim-443.pdf"> debunk the `` expensive procedure call '' myth or , procedure implementation consider harmful or , lambda : the ultimate goto </a> folklore state that goto statement be `` cheap '' , while procedure call be `` expensive '' . this myth be largely a result of poorly design language implementation . the historical growth of this myth be consider . both theoretical idea and a exist implementation be discuss which debunk this myth . it be show that the unrestricted use of procedure call permit great stylistic freedom . in particular , any flowchart can be write as a `` structured '' program without introduce extra variable . the difficulty with the goto statement and the procedure call be characterize as a conflict between abstract programming concept and concrete language construct . the `` conflict between abstract programming concept and concrete language construct '' can be see from the fact that most theoretical model of , for example , the untyped <a href="https://en.wikipedia.org/wiki/lambda_calculus"> lambda calculus </a> , <em> don t have a stack </em> . of course , this conflict be not necessary as the above paper illustrate and as be also demonstrate by language who have no iteration mechanism other than recursion such as haskell . let I demonstrate . for simplicity , i ll use a `` apply '' lambda calculus with number and and boolean , and i ll assume we have a <a href="https://en.wikipedia.org/wiki/fixed-point_combinator"> fixed-point combinator </a> , <code> fix </code> , which satisfy <code> fix f x = f -lrb- fix f -rrb- x </code> . all of this can be reduce to just the untyped lambda calculus without change my argument . the archetypal way of understand the evaluation of the lambda calculus be through term rewrite with the central rewrite rule of beta reduction , namely $ -lrb- \ lambda x.m -rrb- n \ leadsto m -lsb- n\/x -rsb- $ where $ -lsb- n\/x -rsb- $ mean `` replace all free occurrence of $ x $ in $ m $ with $ n $ '' and $ \ leadsto $ mean `` rewrite to '' . this be just the formalization of substitute the argument of a function call into the function body . now for a example . define <code> fact </code> as here s the evaluation of <code> fact 3 </code> , where , for compactness , i ll use <code> g </code> as synonym for <code> fix -lrb- f. a. n.if n = = 0 then a else f -lrb- a \* n -rrb- -lrb- n-1 -rrb- -rrb- </code> , i.e. <code> fact = g 1 </code> . this doesn t affect my argument . you can see from the shape without even look at the detail that there be no growth and each iteration need the same amount of space . -lrb- technically , the numeric result grow which be unavoidable and just as true for a <code> while </code> loop . -rrb- i defy you to point out the boundlessly grow `` stack '' here . it seem the archetypal semantics of the lambda calculus already do what be commonly misname `` tail call optimization '' . of course , no `` optimization '' be happen here . there be no special rule here for `` tail '' call as oppose to `` normal '' call . for this reason , it s hard to give a `` abstract '' characterization of what tail call `` optimization '' be do , as in many abstract characterization of function call semantics , there be nothing for tail call `` optimization '' to do ! that the analogous definition of <code> fact </code> in many language `` stack overflow '' , be a failure by those language to correctly implement function call semantics . -lrb- some language have a excuse . -rrb- the situation be roughly analogous to have a language implementation that implement array with link list . indexing into such `` array '' would then be a o -lrb- n -rrb- operation which doesn t meet the expectation of array . if i make a separate implementation of the language , that use real array instead of link list , you wouldn t say i ve implement `` array access optimization '' , you would say i fix a broken implementation of array . so , respond to veedrac s answer . <a href="https://existentialtype.wordpress.com/2016/02/22/it-is-what-it-is-and-nothing-else/"> stack be <em> not </em> `` fundamental '' to recursion </a> . to the extent that `` stack-like '' behavior occur during the course of evaluation , this can only happen in case where loop -lrb- without a auxiliary datum structure -rrb- would not be applicable in the first place ! to put it another way , i can implement loop with recursion with exactly the same performance characteristic . indeed , scheme and sml both contain loop construct , but both of they define those in term of recursion -lrb- and , at least in scheme , <code> do </code> be often <em> implement </em> as a macro that expand into recursive call . -rrb- similarly , for johan s answer , nothing say a compiler must emit the assembly johan describe for recursion . indeed , nothing say a compiler can t emit <em> exactly the same </em> assembly whether you use loop or recursion . the only time the compiler would be -lrb- somewhat -rrb- <em> obligated </em> to emit assembly like what johan describe be when you be do something that isn t expressible by a loop anyway . as outline in steele s paper and demonstrate by the actual practice of language like haskell , scheme , and sml , it be not `` exceedingly rare '' that tail call can be `` optimize '' , they can <em> always </em> be `` optimize '' . whether a particular use of recursion will run in constant space depend on how it be write , but the restriction you need to apply to make that possible be the restriction you d need to fit you problem into the shape of a loop . -lrb- actually , they be less stringent . there be problem , such as encode state machine , that be more cleanly and efficiently handle via tail call as oppose to loop which would require auxiliary variable . -rrb- again , the only time recursion <em> require </em> do more work be when you code isn t a loop anyway . my guess be johan be refer to c compiler which have arbitrary restriction on when it will perform tail call `` optimization '' . johan also be presumably refer to language like c + + and rust when he talk about `` language with manage type '' . the <a href="https://en.wikipedia.org/wiki/resource_acquisition_is_initialization"> raius </a> idiom from c + + and present in rust as well make thing which superficially look like tail call , not tail call -lrb- because the `` destructor '' still need to be call -rrb- . there have be proposal to use a different syntax to opt-in to a slightly different semantics that would allow tail recursion -lrb- namely call destructor <em> before </em> the final tail call and obviously disallow access `` destroy '' object -rrb- . -lrb- garbage collection have no such issue , and all of haskell , sml , and scheme be garbage collect language . -rrb- in a quite different vein , some language , such as smalltalk , expose the `` stack '' as a first-class object , in these case the `` stack '' be no longer a implementation detail , though this doesn t preclude have separate type of call with different semantics . -lrb- java say it can t due to the way it handle some aspect of security , but <a href="http://www.ccs.neu.edu/racket/pubs/esop2003-cf.pdf"> this be actually false </a> . -rrb- in practice , the prevalence of broken implementation of function call come from three main factor . first , many language inherit the broken implementation from they implementation language -lrb- usually c -rrb- . second , deterministic resource management be nice and do make the issue more complicated , though only a handful of language offer this . third , and , in my experience , the reason most people care about , be that they want stack trace when error occur for debug purpose . only the second reason be one that can be potentially theoretically motivate . 