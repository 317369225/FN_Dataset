How does a relational DBMS internally store its data?
How does DBMS 1. store data internally such that it overcomes main memory disadvantage ( i.e. rapid retrieval ) of file system ? There's no way to overcome the disadvantage vis-à-vis the performance of a file system compared to accessing data in main memory.  DMBSs go to great lengths to minimize file I/O, but it can never be eliminated. [Edit: I am speaking of persistent databases here; not in-memory databases.]   Database systems typically store data in fixed size blocks called pages.  The pages are (should be) a multiple of the disk blocking factor.  Recall that a disk is a 'block device'. The disk is always going to read/write entire blocks, even if the read request is for some smaller amount of data. IOW, if you call read() (in the C language) and request to read 100 sequential bytes of a file, the disk is going to read the entire block that contains the 100 bytes from the media into its cache, which will be copied into the file system's cache, and 100 bytes of it will be copied into your program's buffer. So, database system page sizes should be aligned to the disk blocking factor so that none of that I/O is wasted.  IOW, if the disk block size is 4K, it is inefficient to have a database page size of 1K knowing that the disk is going to read/write 4K regardless.  Make the database page size a multiple of the file system block size (1X, 2X, ...).   2. In what type of data-structure ?   This varies greatly between DBMS, but the structures will generally be stored within the fixed-size database page 'containers', if you will.  The structures can be any/all of: fixed length records of structured data, variable length records of structured data, variable length records of opaque data (e.g. BLOB or the 'value' in a key/value pair), hash table entries, and nodes of tree indexes of various types (b-tree, r-tree, kd-tree, patricia trie, ...). This is, by no means, an exhaustive list of the 'structures' different DBMS use.   In addition, there are various other structures that we generally call "meta data", or data about the data, that the DBMS needs to perform its function (the function being to manage the data).  The most commonly known is the database dictionary.  With respect to mitigating the impact of file I/O, there is an index of cache pages in the database systems memory.  The DBMS conducts a lookup in this index to determine if the page of a file it needs to operate on (read from or write to) is in the cache, or not.  Obviously, if it's in the cache, a file I/O is avoided.  Also obvious, that cache index lookup takes time, but is rewarded by far less file I/O which is orders of magnitude slower.   3. How does It offer the rapid retrieval without loading the entire database into the main memory ( I have heard many DBMS uses B-Trees).   Not just b-trees. There are many types of indexes, as mentioned above.  Further, there is an operation called a "covered query" that you should lookup and read about.   Perhaps most important is the DBMS cache.  There are often "hot spots" of data, IOW some subset of the entire database that is read/written more frequently than the rest of the database.  DBMSs employ algorithms to keep the most frequently accessed data in its cache.  Lookup and read about LRU (least recently used) algorithms for the most common implementation. Since all b-tree searches start from the top (the root node) of the tree, a DBMS cache will almost always have the root nodes of all the indexes commonly used, in cache. (Some indexes are rarely used and therefore might not be in cache.)   As another responder said, this is a huge topic. I've just barely hit the highlights. 