What is going on with (x^2 - 9)/(x+3)? Why do weird things happen when x gets close to -3?
Ahh, this is a good observation. It doesn't make sense, does it? We can write that equation as (x-3)(x+3) / (x+3), and so long as x doesn't equal -3 (because of divide by zero), we can cancel and get an answer for y. So the answer we expect is (-2.999999 - 3) = -5.99999 or so. Also, (x - 3) is a straight line, so why does what we see on screen oscilate? What you're seeing is the limit of the numerical precision of the calculator. Computers represent numbers as strings of zeros and ones, usually of length 32 (on a 32 bit computer, anyway). So 01100110011001100110011001100110 is a number, if you interpret it correctly. (Your calculator may use fewer than 32 binary digits, depends on the model) Since there are 32 positions, and each position can be either 1 or 0, there are 2 ^ 32 possible sequences of zeros and ones. But real numbers can have thousands of numbers after the decimal point if we want them to, so it's impossible to specify every number perfectly. After a point, we have to round the number off and accept some small error. So why do we see it wobbling up and down on screen? It's to do with dividing by a small number, and rounding. As we move along the plot, X changes, and is rounded. Sometimes the calculator rounds X down, and sometimes up, because it doesn't have the precision to represent it completely. Normally, these wobbles are so small that they don't appear on screen. However, if you divide by a tiny number, the resulting number is very large. So small errors caused by rounding X in the denominator are magnified in the final answer, causing the wobbles that you see. For example, say we have the number 0.15 in the denominator, and our computer has only one digit of precision. The correct answer to 3 / 0.15 is 20. But if we round 0.15 up, the answer becomes 3 / 0.2 = 15. If we round 0.15 down, the answer becomes 3 / 0.1 = 30. So an error of between 5 and 10 units in the final answer was caused by a much smaller error of 0.05 in the denominator. As an aside, this stuff can be a real pain when doing engineering computing. If you'd like to read about how computers represent numbers in more detail, you can look into floating point numbers =) 