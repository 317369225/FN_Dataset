What is an intuitive explanation for bias-variance tradeoff?
In my mind this is really a trade-off between ability to generalize on the one hand and ability to model data with a complex structure on the other. If the model is too complex it finds patterns in the data that are not really there but just due to noise. This hurts the ability of the model to generalize. In the extreme case the model becomes a lookup table for the training data. It can perfectly reproduce the training data but cannot generalize at all. This is known as variance. If the model is not complex enough it cannot fit the data even with a large training set. This is known as b... (more)