Why do overfit models have high variance but low bias?
Linguistically, you can say that the graph is “varying a lot”. When high-variance and low bias occurs, the graph plotted on training samples passes through almost all the training samples. This means, the graph is not biased towards one or two samples (since it tries to pass through all the training data) but because of this the graph needs to vary a lot (vary it’s coeffients, go in higher orders, etc) When the reverse happens…. low-variance and high bias…. imagine this to be smoothened out graph, where it hardly passes through one or two or three trainig samples. The graph here is being bias... (more)