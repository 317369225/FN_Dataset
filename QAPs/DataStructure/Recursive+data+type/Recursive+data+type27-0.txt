Are there any useful recursive functions that do not contain a base case?
Yes There is a whole class of recursive functions (and recursive structures) that is perfectly well-defined and usable but has no base cases. We call this kind of recursion corecursion and these functions corecursive. Additionally, we can work with circularly defined data and functions by calculating their fixed points. Instead of naÃ¯vely evaluating the function or definition step by step, we can do some analysis ahead of time to find or approximate a solution. This will not work in general, but can be very useful in constrained situations like attribute grammars, where we can define mutually recursive attributes that do not have a "base case". Roughly speaking, the property of "having a base case" corresponds to being well-founded. Most standard mathematics talks about functions and structures that are well-founded because standard set theories (say ZF) usually include an "Axiom of Foundation" that ensures every set is "well-founded"--that is, sets can only be nested finitely deep. This means we cannot normally define a set like [math]a = \mathcal{P}(a)[/math] or even [math]a = \{a\}[/math]. Conceptually, [math]a = \{a\}[/math] is actually simple--it's just [math]\{\{\{\ldots\}\}\}[/math] with an infinite number of braces; however, we cannot normally construct this because [math]a \in a[/math] is not allowed--sets aren't allowed to nest in themselves. Happily, there are alternate set theories that discard the Axiom of Foundation, designed especially for working with circular structures--like recursive functions without base cases! These non-well-founded are usually called hypersets. Vicious Circles is a wonderful book introducing this concept. I have just started reading it, but so far it seems extremely accessible to non-mathematicians (ie me). This book talks about corecursion and also defines some very useful tools for dealing with circular phenomena like coinduction and bisimulation. Since I haven't quite gotten to those chapters--and stuff I've found online was too confusing--I'll have to elaborate about these later :). CorecursionCorecursion is a sufficiently important concept that it deserves elaboration and some examples. It's an invaluable tool of the serious functional programmer which can be used to intuitively model circular structures and leads to neater, more modular code. What not to like? Keep in mind that practical corecursion depends on laziness. Most of my examples are in Haskell, which is lazy by default. Having a basic understanding of lazy evaluation will help with understanding corecursion, although you can embed corecursion in a strict language using a special lazy data structure like a stream or a generator. Functions without a base case do not terminate--they are just like an infinite loop. Usually, we do not want infinite loops, but for some things (like running servers and reactive systems) infinite loops are indispensable. On the other hand, infinite busy loops that just spin forever without producing any more output are never useful. We need some simple, structural way to build "useful" infinite loops without admitting useless ones. This is where corecursion comes in. The basic idea is that an infinite functions is "useful" if it is productive. At any point, it will produce additional output in a finite number of steps. A function like this can keep on producing output forever as long as it stays productive. Being productive for a corecursive function is just like always having a base case for a normal recursive function. A simple corecursive definition could, for example, produce an infinite lazy list of some number n. The function will never terminate since there is no base case, but we can still use it because we can access any given element of the list in finite time. This is very natural in Haskell because everything is lazy by default: numbers :: Integer -> [Integer]numbers n = n : numbers n However, we can get the same result using specifically lazy data types like Racket's streams: (require racket/stream)(define (numbers n) (stream-cons n (numbers n))) We can define less trivial structures the same way. For example, the usual Haskell implementation of Fibonacci is corecursive, producing an infinite list of Fibonacci numbers: fibs :: [Integer]fibs = 0 : 1 : zipWith (+) fibs (tail fibs) A good way to understand exactly how corecursion works is to manually evaluate the first few elements of fibs and convince yourself that it works. Of course, corecursion is not limited to lists. You can easily produce other structures like infinite trees, as long as you stay productive. This makes it very easy to write minimax by splitting it into a corecursive game tree and a recursive function consuming the game tree. This is very nice because it decouples how you generate moves from how you consume them--you can easily use the same game tree for normal minimax, alpha-beta pruning or any other pruning strategy. gameTree :: State -> Tree StategameTree current = Node current (map gameTree (moves current))minimax :: Integer -> Tree State -> Scoreminimax depth tree = ...score :: State -> Scorescore = minimax defaultDepth . gameTree (Where . is function composition.) This sort of programming starts depending pretty heavily on laziness. You could write a similar definition using a custom lazy tree type in a strict language, but it quickly gets really awkward. Besides, one of the main advantages of this approach is modularity, which is heavily hampered by having to use a custom lazy tree instead of the standard strict one! Another example of corecursive programming is for writing reactive systems--systems that give a response to a potentially infinite amount of input, taking a finite time for each additional input. A simple example of a reactive system like this is a server: it takes a potentially infinite lazy list of requests and produces a lazy list of responses. In order to be useful, the server has to take a finite amount of time for each request, but it doesn't have to terminate itself! We could model a server like this corecursively: server :: [Request] -> [Response]server (request:rest) = respond request : server rest Of course, this is a really simplified model of reactive programming that would not really fly in the world. Happily, we have a much richer reactive paradigm in functional reactive programming (FRP); the basic structures used in FRP are corecursive themselves but also richer than mere lists. In fact, semantically, you can think of event streams as lazy lists with each entry annotated by time--that is, a stream of keyboard events is basically a lazy list of (time, keyboard event) pairs. For more details, check out my answer to What is Functional Reactive Programming? We can use this idea of corecursion to allow non-terminating functions in total languages. "Total" means that every single function in the language has a well defined output for every possible input. This means no busy loops and non-termination! By their very nature, total languages cannot be Turing-complete. And yet, by extending them with corecursion, we can have "good" non-terminating functions while preventing bad ones! I think that's pretty exciting; it really feels like having your cake and eating it too. Check out Total Functional Programming for a fairly accessible introduction to the idea of total functional programming with corecursion. 