What are the best applications of linearity of expectation?
Here's a few cute examples involving permutations. What is the expected number of fixed points in a permutation [math]\pi[/math] of [math](1, 2, \dots, n)[/math]? Let [math]I_k[/math] denote the indicator random variable that is [math]1[/math]  if [math]\pi(k) = k[/math], and 0 otherwise. It is clear that [math]\mathbb{E}[I_k] = \frac{1}{n}[/math]. By linearity of expectation, [math] \mathbb{E} [I_1 + I_2 + \dots + I_n] = \sum_{k = 1}^n \mathbb{E}[I_k] = \sum_{k = 1}^n \frac{1}{n} = 1.[/math] So the expected number of fixed points in a permutation is independent of the number of elements in the permutation. What is the expected number of cycles in a permutation [math]\pi[/math] of [math](1, 2, \dots, n)[/math]? Let [math]X_k = \frac{1}{l}[/math], where the length of the cycle including [math]k[/math] is [math]l[/math]. Let [math]X = X_1 + X_2 + \dots + X_n[/math]. We want to compute [math]\mathbb{E}[X][/math], since each cycle of length [math]l[/math] contributes a total of [math]l \cdot \frac{1}{l} = 1[/math] to the sum. We'll compute [math]X_k[/math] for some [math]k[/math]. For each [math]l[/math], the probability that [math]k[/math] is in a cycle of length [math]l[/math] is [math] \frac{n-1}{n} \cdot \frac{n-2}{n-1} \cdot \dots \cdot \cdot \frac{n - l + 1}{n - l + 2} \cdot \frac{1}{n - l + 1} = \frac{1}{n}.[/math] It follows that [math]\mathbb{E}[X_k] = \sum_{i = 1}^n \frac{1}{ni} = \frac{1}{n}H_n[/math], where [math]H_n[/math] denotes the [math]n[/math]th harmonic number. By linearity of expectation, [math]\mathbb{E}[X] = \sum_{k = 1}^n \mathbb{E}[X_k] = H_n,[/math] which is roughly [math]\ln n[/math]. Let [math](a_1, a_2, \dots, a_n)[/math] be a random permutation of [math](1, 2, \dots, n)[/math]. What is the expected number of distinct values in [math]\{ \max_{1 \le i \le n} (a_1, \dots, a_i) \}[/math]? For each [math]1 \le k \le n[/math] let [math]I_k[/math] denote the indicator random variable that is [math]1[/math] if [math]\max_{1 \le i \le k} (a_1, \dots, a_i) \neq \max_{1 \le i \le k - 1}(a_1, \dots, a_i)[/math], and 0 otherwise. Then [math]I_k[/math] is [math]1[/math] if [math]a_k[/math] is larger than each of [math]a_{k-1}, \dots, a_1[/math], which occurs with probability [math]\frac{1}{k}[/math]. By linearity of expectation, [math] \mathbb{E} [I_1 + I_2 + \dots + I_n] = \sum_{k = 1}^n \mathbb{E}[I_k] = \sum_{k = 1}^n \frac{1}{k} = H_n,[/math] which is roughly [math]\ln n[/math]. Updated 51w ago • View Upvotes