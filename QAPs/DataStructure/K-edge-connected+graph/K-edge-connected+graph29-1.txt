What is an intuitive explanation of spectral clustering in the context of machine learning?
There is a well-known explanation in terms of an optimal partitioning of the neighborhood/pairwise-similarity graph, which was mentioned by others. The cut should be minimal, i.e., you should separate on the longest edges (that represent the minimal similarity). The straightforward formulation of the optimal graph cutting problem is NP-hard, I believe. The spectral clustering provides a solution to a "relaxed" problem, which can be seen as an approximation of the original NP-hard one. For the details, see, e.g., the following slides: Page on cmu.edu 