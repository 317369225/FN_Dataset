Why are so many psychology results irreproducible?
Get a fair coin. That is, one that should land on heads 50% of the time and tails 50% of the time. Flip the coin 10 times. Write down what you get. Flip the same coin another 10 times. Write down what you get. Was it the same? Was the number of heads or tails approxiametly equal in both cases? How many times do you think you might have to flip that coin to get exactly 50% heads vs tails? If you flip the coin 100 times and get 49/51 heads/tails, could you call that 50/50 result? How about 2 trials of 100 each where the results are 40/60 and 65/35?  Any measurement or natural phenomenon has an inherent random variability. When we test or measure something experimentally, we are usually taking a limited set of measurements or taking a sample from a larger population. That is the same for ANY experimental science, whether psychology or neuroimaging, or cancer research, or [insert your favorite experimental science here]. Reproducing experiments is one way to get a proper estimate of the variability of a result. Recently, a group of scientists, led by Brian Nosek, set out to try and reproduce a large number (100) of studies in the field of psychology: Source of image: First results from psychology’s largest reproducibility test Each of those boxes is a different sort of experiment, with different design and population sampling methods. 39/100 original cases passed this particular study's "replication" standard. Of the 61 that didn't, some came close ("Moderately/somewhat/slightly" similar).  An earlier, smaller experiment reproduced 10 of 13 results. Fortunately, the writers of the Nosek paper have posted publically accessible data and analysis code for all of the 100 studies they tested here: Reproducibility Project: Psychology Wiki Based on the current data, one might conclude that the variability of psychology results are higher than other experimental sciences. But there are also reports of failure to replicate landmark cancer studies. The point is: attempting to reproduce results is straightforward -- assuming you can get the original protocol and study design of the experiment you want to replicate. In an ideal world, ALL experimental results, would be replicated several times until we had estimates of the variability of the result. In an ideal world, there would be a (close to) complete transparency when it came to the statistical methods and experimental design of highly publicized results. In an ideal world, scientists would have the incentive to do more replication work, and would be rewarded for making their work reproducible. But this is not an ideal world, and for various reasons, including publication bais, emphasis on positive results, incentives against repeating experimental work, etc, there is a lack of reproducibility studies done not only in psychology but across most experimental science fields. For science to move forward, we need more validation and more reproduction, but various non-scientific issues with the structure of academic research are slowing down this type of research. The Nosek paper is really just the most recent demonstration of the need for more reproducility. It does NOT indicate that psychology results are inherently non-reproducible. For a great summary of the structural issues go read Brian Farley's answer to: What do academics think about the meta research that found psychology findings weaker than claimed? 