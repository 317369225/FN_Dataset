Is real-time search fundamentally different from the various search services Google already provides?
Yes, a number of technological differences separate real-time search queries from less time-sensitive queries. The focus on freshness, in particular, means that crawling and indexing latency need to be reduced down to seconds and that stale results quickly lose value.  The major differences can be summarized as follows: Real-time search requires infrastructure for supporting incremental index updates.  Up until recently, much of Google's web indexing pipeline was powered through a series of MapReduces; newly crawled documents waited in a queue for the next batch of MapReduce jobs to run before they could be indexed [1].  Only in April 2010 did Google transition to a new indexing system called Caffeine that supported incremental index updates; Caffeine reduced the median latency for a crawled page to be incorporated into the web index by 100x, down to 2 seconds on a synthetic benchmark [2].  Given that a one-day old tweet on a hot, trending topic is significantly less valuable than a webpage changed one day ago, it's very likely that Google needed to invest in infrastructure beyond Caffeine to support the large volume of incremental updates required for real-time search. Effective real-time search requires push-based APIs for updates rather the traditional poll-based approach for web crawling.  For standard web pages, the Googlebot crawls the web periodically, with the frequency determined by signals like PageRank, links to a given page, load on the website, etc. [3]  Minimizing latency, however, requires both fast discovery, ingestion, and indexing, and the conventional crawling pipeline would be too inefficient due to all the link traversals and page fetches required to stay up-to-date.  Google therefore partners with companies like Twitter, Facebook, FriendFeed (acquired company), and Jaiku [4] to gain access to real-time feed APIs like Twitter's firehose API [5] in order to speed up discovery and indexing as much as possible. Real-time search necessitates new search UIs that can dynamically update.  Prior to Google Instant, Google's results pages were relatively static, with minor javascript interactions for UI features like maps and local results.  The introduction of real-time search meant that the results pages now needed a way to pull in new results onto the page without the user having to manually refresh the page.  The current manifestation of this is a scrollable widget where new real-time results flow in. Real-time search provides significantly fewer opportunities to use click data for ranking.  The recent Google-Bing controversy over questions like Did Bing intentionally copy Google's search results? becomes moot for real-time results because there usually isn't much click data for results that happened a few seconds or minutes ago.  Many traditional ranking signals like PageRank, clicks, and backlinks cannot be directly applied to real-time results, and new ranking signals must be developed. Because less click data is available and because many real-time search results come from social networks like Twitter, leveraging the social graph for ranking becomes more important in real-time ranking.  Retweets, the volume of recent results on a given query, the number of friends or followers for a user, and other signals from the social graph, become much more important for measuring the quality of a given tweet or news item.  Personalization of results with individuals in your own social graph also become much more promising, as evidenced by Google's inclusion of Twitter and Quora annotations into search results: Of course, even though differences exist between the real-time search queries and less time-sensitive queries, many of the basic tenets for building a good search product, like speed, simplicity, and quality, remain the same.  And Google is pretty well-positioned to reuse many of the same techniques and abstractions that it's previously used to accomplish those goals. ---------- [1] MapReduce: Simpliﬁed Data Processing on Large Clusters.  Jeff Dean and Sanjay Ghemawat.  http://labs.google.com/papers/ma... [2] Large-scale Incremental Processing Using Distributed Transactions and Notifications.  Daniel Peng and Frank Dabek. http://www.usenix.org/event/osdi... [3] http://www.google.com/support/we... [4] http://googleblog.blogspot.com/2... [5] http://techcrunch.com/2010/03/01... Updated 250w ago • View Upvotes