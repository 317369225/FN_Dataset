How do you interpret decision tree regression to a lay man?At each node of the decision tree, you can find the average regression output for each branch of the decision tree, and reason about why the outputs differ at each branch. This gets easier if the splits are on a numeric or ordinal feature. The interpretation then devolves to: “Given all decisions from root to node A, the regression output increases/decreases with the value of the feature being used for splitting at node A.” For categorical features, I think the interpretation would become more business-specific. If you ordered the values of a categorical feature using the average output value and used that to learn the tree (as in [1]), you could still interpret the decision split on the categorical feature as you would do for an ordinal or numeric feature. If your features are useful and interpretable business-wise, you read off each path from from root of tree to the leaf and thus turn the decision tree into an interpretable decision list of conjunction rules each with its own regression output. But, this is more obfuscating in general that reading the decision tree directly. [1] PLANET: Massively Parallel Learning of Tree Ensembles with MapReduce. Biswanath Panda, Joshua S. Herbach, Sugato Basu, Roberto J. Bayardo. Google, Inc. 372 Views