What are the difference between decision tree and ols?OLS is a simple linear regression solved with least squares. Decision trees can be used for classification or regression. I will compare only the regression setup for decision trees, since classification serves a too different purpose. Regarding the statistical model they propose: OLS is one of the strictest type of models you can have. The assumptions for OLS are that noise in data is independent and Gaussian and the relation between independent and dependent variables is linear. Decision trees does not assume any parametric structure of the data. It is a greedy approach and can handle a lot of relations between independent and dependent variables. So their assumptions are totally different. Regarding stability: Obviously the OLS is expected to be very stable. This does not happened always since OLS depends on the features to not be collinear or close to that and to not have extreme values since the expected value is not a robust statistic. But other than that OLS should be stable. Decision trees on the other hand have a lot of variability in predictions. Due to greedy strategy a change in a single point can change the whole shape of the tree. So flexibility comes at a price. Regarding improvements: OLS can be improved a lot with addition of regularization (like ridge, lasso, elastic net and so on). Also generalized linear models which are a generalization of OLS allows one to go further modelling different kind of errors by means of link functions and distribution of errors. Decision trees were used mainly into bagging (like random forests) or boosting ensembles. All those type of assembles tries to use the flexibility of trees and attenuate it's sins (like large variability) Regarding interpretation: Their history differs since linear models comes from statistical inference and decision trees comes from machine learning, and as a consequence, their theory is disproportionate. Their use for interpretation is I would say their single point in common. Very often decision trees are used to get an idea about the relation between the independent variables and the predictor. It is often seen in medical inference as a way to summarize what is going on behind the scenes. This is true also for OLS which is used often for the same purpose. When talking about classification the Logistic regression is the correspondent of classification decision trees. 242 Views