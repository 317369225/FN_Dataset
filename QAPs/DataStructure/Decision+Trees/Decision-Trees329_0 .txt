How can I validate my decision tree apart from cross-validation?Without cross-validation, it is really hard to find a meaningful metric to assess the "quality" of a tree. Say you'd use the internal impurity of the terminal nodes as an intrinsic performance measure. Here, it becomes very hard to make comparisons between different trees. Intuitively, you'd think that the tree with the lowest leaf-node impurity is the best. However, without cross-validation, you don't know anything about the variance of this tree, i.e., whether or not it is overfitting on the training data. So basically, I can think of 3 different ways to measure the performance of a tree Discriminative/predictive power: the typical contenders (accuracy, precision, f1, recall, ...); of course cross-validation dependent Stability: Decision Tree Instability and Active Learning Simplicity (number of rules or number of leaves): Trading accuracy for simplicity in decision trees 360 Views  View Upvotes