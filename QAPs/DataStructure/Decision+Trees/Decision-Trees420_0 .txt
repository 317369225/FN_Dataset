When building a decision tree from the root node using TDIDT (Top-Down Induction of Decision Trees) why is it important to properly order the attributes/nodes?[Note: Clarified the question with the author] If your calculation of the gain or splitting value is incorrect, then your trees may not be as optimal as they could be; but ironically if it's not too far off, and your class labels are still accurate, it probably doesn't make that much difference. Subsequent nodes will correct for attribute noise by making locally optimal decision. There is a limit, however, and the more noise there is, the higher the probability that no pure nodes exist (you'll end up with leaf nodes that are not pure). Another way to solve this is to bag (i.e. build multiple trees) -- see Bootstrap aggregating. This adds considerable robustness in the face of noise like this. 441 Views  View Upvotes