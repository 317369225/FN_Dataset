What method XGBoost uses for pruning and regularization?Pruning is a method to improve generalisation in decision trees. One way to do pruning is to take a test data set and look at the entropy gain at each split of the trained tree and stop where entropy gain starts to go negative which means that overall this split does not create better classification of data. This whole exercise can be done in a cross validation setting. Regularisation of xgboost model will involve not only pruning but other parameter tuning as well. While you are iteratively adding trees to the model you can keep the learning rate small so overfilled trees don't effect the model. This is specific to gradient boosting. 187 Views  View Upvotes