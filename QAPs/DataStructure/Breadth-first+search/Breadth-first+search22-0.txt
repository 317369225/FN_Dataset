How can I implement breadth-first-search to find the shortest path between two Wikipedia pages for longer paths?I'm trying to implement a breadth-first-search to find the shortest way of going from some ABC Wikipedia page to another XYZ page. My code works if it takes a few steps but for longer paths, Wikipedia temporarily blocks me from the server. Is there any bypass to make it work for longer paths too? Thanks!
Presumably wikipedia is blocking you for making too many requests too rapidly. Either crawl a static database dump of wikipedia, (available at Wikimedia Downloads), or rate limit your crawler. Using a static dump is preferred, but if you must crawl the live site, you should rate limit your crawler to no more than one request per second, as indicated in the robots.txt file on wikipedia (the Crawl-delay parameter, which is commented out, but still shows their intent). 