When should you use the different GCC optimization flags (e.g. -O2)?I am new to code optimization and g++/gcc compiler flags. This question arose when I saw that OpenCV uses the "-O2" optimization instead of "-O3" on 32-bit Linux. What are the pros/cons of each optimization level?
As Robert Love mentioned, -O{0,1,2,3,s,z} can be generally translated into space-time tradeoffs. One thing to have in mind is that these are optimization sets that, in general, will compile things having a specific goal in mind.  They tend to work towards that goal for most programs tested by a specific compiler developer/vendor.  There are no guarantees, though, and there are lots of corner cases. GCC implements -O2 as a balanced, safe optimization level, that won't consume either too much memory or compilation time, while delivering better code at the machine level.  -O3 will enable an aggressive set of optimizations, which is to say that the compiler will try really hard to perform more code transformations that, in general, produce faster-running code, at the expense of more compilation-time resources (time, memory, etc), and possibly creating a larger binary. The bad news is that it is not necessarily true that you will get better code as you enable more optimizations.  This is because of their interplay, where one specific code-transformation may interfere on another in an unpredictable way.  This is a hot topic on compiler research for a long time now, and largely an unsolved problem, with no single solution in the foreseeable future.  Why, you might ask?  Because the running time of your program is not only dependent on the code stream the compiler generated, but how your input (or inputs) affect the execution. The good news is that a significant portion of performance problems are due to suboptimal algorithm selection and other mundane techniques, which you can quickly spot under a code profiler.  You should be good with either -O2 or -O3. 