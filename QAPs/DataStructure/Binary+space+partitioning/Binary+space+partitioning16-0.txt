When should you use the different GCC optimization flags (e.g. -O2)?I am new to code optimization and g++/gcc compiler flags. This question arose when I saw that OpenCV uses the "-O2" optimization instead of "-O3" on 32-bit Linux. What are the pros/cons of each optimization level?
Different types of optimization are generally space-time tradeoffs. That is, while some optimizations improve both, many optimizations improve execution time at the expense of a larger binary or shrink the binary at the expense of longer execution times. As an example, we can consider function and data aligning. To optimize space, functions and data can be "packed" together, aligned to the minimum requirements of the architecture (or not at all). To optimize time, functions and data can be more liberally aligned, satisfying not only architecture alignment requirements but efficiently utilizing caches. There are many more examples, particularly of optimizations that sacrifice space for time: Loop unrolling, function inlining, and code reordering & partitioning all may improve execution time but certainly increase code size. gcc offers four compilation levels, plus two special modes: O0. No optimization. This is the default. There is a clear relationship between each line of code and each resulting machine instruction. The compiler is actually slower at this level, as dead-code elimination and other unperformed optimizations minimize the amount of work the compiler needs to do. Moreover, some warnings are not available with optimization disabled as the compiler cannot detect certain issues without using its optimizer. The only use case for this level is debugging, but I try to debug in my standard level if at all possible. O1. Enables basic optimizations. There generally isn't a reason to use this level over the next. O2. Enables even more optimizations. This mode turns on nearly all optimizations that do not incur significant space-time tradeoffs. This is the default for many software projects, including the Linux kernel and all GNU projects. Because it is the default for so many (important) projects, it is the most tested option. This level is my recommendation. O3. Enables yet more optimizations. This includes optimizations that incur a space-time tradeoff in favor of time, such as loop unrolling and automatic function inlining. Your binary will almost certainly be larger. Your program may be faster. Os. Optimize for size. This mode is similar to O2, except a handful of optimizations are disabled and a handful of new ones are enabled. Your binary will almost certainly be smaller than with O2. It is also likely to be slower, although it may be faster, due to improved cache utilization. Ofast. Optimize even more than O3, including optimizations that can generate incorrect code even for standards-compliant software. Most notably, this disables IEEE-compliant floating point. I would never use this. My recommendation: Use O2 and do not worry about it. Spend your time writing clear, clean code. If, in the future, when you have a mature codebase, a suite of tests and benchmarks to measure changes, and a specific use case that you wish to optimize further, research whether O3, Os, or (preferred) enabling a specific optimization flag on top of O2 is an improvement. 