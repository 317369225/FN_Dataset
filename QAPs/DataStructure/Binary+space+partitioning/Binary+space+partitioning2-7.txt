What is the coolest data structure?Which one makes you say, "Wow! That's cool!"? What makes it so cool? What are some applications?
I'm partial to the binomial heap. It's a data structure that can be used to implement a priority queue, just like a binary heap can be. While it offers good asymptotic time complexities for all the operations it supports -- the same as binary heaps, except that insert is improved to amortized O(1) -- what really sets it apart is its mathematical elegance. There is a direct and very beautiful analog between the binomial heap and adding numbers in binary. A binomial heap consists of a collection of (at most log n) trees, each one of which obeys the heap property. Each tree's size is a power of 2, and there is at most one tree of each size. A tree of size 1 is a single node, and trees of size 2 i+1   are created by taking two trees of size 2 i   and making one tree's root a child of the other tree's root. Which tree will be the parent is decided based on which tree's root value needs to be on top to preserve the heap property (min or max heap). The idea now is, that whenever you end up with two trees of the same size, you join one to the other (O(1) operation) and get a tree of the next larger size. If that causes you to have two trees of the next larger size, you merge them again, and so on.   An insert operation is done by adding a tree of size 1 containing the value. If there's another tree of size 1 already present, the two will be merged, and the amalgamation will be a tree of size 2, which will again be merged with any other tree of size 2 that is already present, and so on until a tree is created of a size that was not previously present. The pseudocode might look something like this: treeNumber = 0 newTree = {value} while (existingTrees[treeNumber] != null) { newTree = join(existingTrees[treeNumber], newTree) //the existing tree was consumed in the merge existingTrees[treeNumber] = null treeNumber++ } //found a size that didn't exist before existingTrees[treeNumber] = newTree   This code runs in worst-case O(logn)  because the k-th tree is of size 2 k   , so there are at most log 2 n  trees. This algorithm is exactly analogous to incrementing a binary counter, if it were represented as an array of digits with the lowest bits at the beginning! This also means that if you do an amortized and not a worst-case analysis of insertion into a binomial heap, the runtime is actually O(1)  , by the same argument that  incrementing a binary counter is amortized  O(1)  . Let's look at the code for that:   digitNumber = 0 carry = 1 while (digits[digitNumber] != 0) { //if we reached this line, it will always evaluate to 1, so no need for it. It's here just to demonstrate the similarity. carry = logicalAnd (digits[digitNumber], carry) //the existing digit was consumed in the add digits[digitNumber] = 0 digitNumber++ } //found a position that wasn't set to 1 before digits[digitNumber] = 1   Now, the really awesome thing is how the remove-min procedure works. Let's say you want to use remove-min (in a min-heap): Check the roots of the (at most log n) trees you have for the least value, since the heap property guarantees that the min value must be at one of the roots. Now, you know from which tree you must remove the value. Write the size of this tree as 2 k   . Either k=0, in which case this is a tree of size 1 that you can delete and you're done, or k > 0, in which case this tree was created by joining two trees of size 2 k−1   . If that's the case, the value you're deleting came from one of those trees. Separate those two trees (O(1) operation, just detach the most recently added child of the root), set the child subtree aside, and repeat the procedure on the root tree (now of size  2 k−1   , since you removed a subtree of size  2 k−1   when the initial tree was size  2 k   ). Over the course of the procedure, the trees that are set aside will be of size  2 k−1   , 2 k−2   , 2 k−3   , ...1  . Note that this is analogous to subtracting 1 from a power of two when using binary numbers. For example, 10000 - 1 = 01111 = 1000 + 100 + 10 + 1 You have all these trees that have been set aside, and now they need to be re-incorporated into the rest of the binomial heap (which might have trees other than the one you dismantled). The trees you set aside in fact form a valid binomial heap, taken together, since each tree is of a size that's a power of 2 and there's only one tree of each size! So, the problem of performing remove-min is now reduced to the problem of merging two binomial heaps. Two binomial heaps can be merged by a procedure that is analogous to adding two binary numbers: 1. Check whether each heap has a tree of size 1. If neither one does, the resulting heap will not have one either (0 + 0= 0). If just one does, that tree of size 1 will be inherited by the resulting heap (0 + 1 = 1 + 0 = 1). If both do, the resulting heap will not have a tree of size 1, but we will merge the two trees of size 1 into a tree of size 2, and "carry" the tree of size 2 (1 + 1 = 10 in binary, which results in writing down a 0 and carrying the 1). 2. The trees of size 2 (up to 3: the carry, and the two possible trees of size 2 from the heaps being merged), will then be added again, resulting in a possible tree of size 2 for the result, and possibly a "carry" of size 4. This procedure will repeat until all the trees have been merged. Since there are at most O(logn)  trees, the merge procedure, and the overall remove-min procedure, run in O(logn)  . Pretty darn cool, huh? 