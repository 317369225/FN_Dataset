How is discrete mathematics used in control theory?
The field of "hybrid control systems" is rife with discrete math. In control systems, it's not uncommon that there's a mix of discrete and continuous parameters. A discrete variable can be the {on, off} value of a switch, a symbolic value for specific events, like "valve stuck" or "initiate cleaning". The variables may be measured in a point of time which itself is treated either as a discrete or a continuous variable. When discrete and continuous values mix in the control system, it is generally referred to as a "Hybrid Control System". Such control systems have been an active field of research for decades. See for instance Hybrid Control Systems: An Introductory Discussion which I'm basing this answer on. When a system described by differential equations using continuous variables and continuous time is controlled by a control system operating with discrete time, it is commonly termed "Digital Control System". You can think of this as a subset of hybrid control systems or as a synonym. After all, any dynamics in the real world will have some continuous variables and any computer controlling it will discretize to some degree. An instructive example is "switching systems" which you can think of as discrete automatons or petri nets, where each node corresponds to a set of differential equations, each modeling parts of the system dynamics. The role of the discrete math is then to switch around in the Petri net according to logical rules. In this case it's a clear division of labor between discrete and continuous mathematics. But you'll also see discrete math coming to save the day when dynamical systems have discontinuities. The simples example is a thermostat, where the continuous temperature variable is translated into a discontinuous {too hot, too cold, ok} value, which is then translated into continuous variables like electrical currents, fan speed, etc. 