What's the difference between distributed and distributional (semantic) representations?Besides the differences in learning algorithms, i.e. LSA for distributional and neural net language models for the distributed, what is the intrinsic difference between these two kinds of word semantic representations?
Actually, as Yoav Goldberg showed in the presentation "word embeddings what, how and whither" that they are equivalent when using words as context. 