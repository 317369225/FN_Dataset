What is a bloom filter and what are they used for?
Bloom Filter is a compact data structure for probabilistic representation of a set of variables to ensure whether elements in set are certainly present or definitely not present in the set. It uses bit array for certainty along with some hash functions. Multiple hash functions are needed to ensure no collision happened for two inputs to same hash. Bloom Filter dosnt keep the hash of the input instead it generates a hash(numerical value) with a range bounded within bit array. then it sets that index in bit array. so for n hashes it generates n values and its corresponding index is set to "1". So "0" means theres no input whose hash is calculated to that index by any of the hash function. As a hash definately generates something within a range so "0" means the input is definitely not present. For "1" there might be chance that some other input might set that index (collision inside hash function) but more than 1 hash  functions genrates lesser collisions. Mathematically   If m is the number of bits in the array, the probability that a certain bit is not set to 1 by a certain hash function during the insertion of an element is If k is the number of hash functions, the probability that the bit is not set to 1 by any of the hash functions is A Bloom filter with 1% error and an optimal value of k, in contrast, requires only about 9.6 bits per element — regardless of the size of the elements. This advantage comes partly from its compactness, inherited from arrays, and partly from its probabilistic nature. The 1% false-positive rate can be reduced by a factor of ten by adding only about 4.8 bits per element. source Bloom filter So we cant sure that 1 means value is sure present but it tells probability of presence of that input For two hashes you can check it manually on Bloom Filters by Example It uses murmur and fnv as hash Applications It is widely used in distributed database such as casandra. In cassandra there is a strategy "NetworkToplogy" which divides original data and stor it in chunks at different servers. now when we call to get that value internally it has RPC on other servers for the appropriate chunks. Each node in cluster has an in-memory bloom filter that tells whether the given values hash is present in database or not if it is "1" (bloom filter index) then only it goes to the disk for fetching it depending on the probability value. As disk I/O is slow so bloom filter is used to decrease latency. It can also be used in hadoop for joining inputs.  If input is coming from different sources then instead of directly passing the values to Reducer class, first in Mapper generates its bloom values then pass it through OutPutCollector to Reducer class then reduce it using bloom filter values.  Hadoop already provided BloomFilter class in its util package. see @BloomJoin: BloomFilter + CoGroup In the networking world, one successful product using Bloom filters is the open source distributed web proxy called Squid . Squid caches frequently accessed web content to save bandwidth and give users a faster web experience. In a cluster of Squid servers, each one can cache a different set of content. An incoming request should be routed to the Squid server holding a copy of the requested content, or in case of a cache miss, the request is passed on to the originating server. Besides this HashCache is going to use bloom filter for cache hit. source @Page on nec-labs.com 