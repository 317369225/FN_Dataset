Is my teacher correct in saying that a significance test for correlation measures the number of points in the graph that are close to the line of best fit?
Your teacher is "not even wrong"; you are at least on the right track. The p value tells you one thing: If, in the population from which this sample was randomly drawn, the correlation was 0.00, how likely is it that, in a sample the size of the one we took, we would get a correlation at least as extreme as the one we got? "The number of points that are close to the line" is essentially meaningless. First, "close" is not defined. Second, however it is defined, it will go up as N goes up, if the correlation stays the same. On the other hand, significance will go down as N goes up, if the correlation stays the same. For example, given this R code x <- rnorm(5) y <- x+rnorm(5,0,.01) cor(x,y) cor.test(x,y) plot(x,y) we find a near perfect correlation, a significance that is very close to 0 and all 5 points very very close to the line.Â  If we increased the sample, the number of points close to the line would go up. 