Which Relational/NoSQL approach is best suited for storing trees, with real-time aggregation from child nodes to parent nodes?
There's no reason to get fancy. Given the three main considerations: How often the statistics change? How often the cost calculations change? Reads need to be near real time (< 2s)There's an RDBMS (SQL) approach that doesn't make any assumptions on the first two, while being fast enough for moderately sized data to satisfy the third. This is likely the best solution for someone prototyping an idea, before features are settled down enough to make some cutting decisions that would enable more stuff to be indexed on write. Aggregates down trees are exactly what RDBMSs do with "group by" aggregates. RDBMSs are no good for unbounded relationships like general graphs, but work well with bounded trees (for example, depth <= 128). I've seen the following type of schema work well for large data sets: a unique ID for each node in the complete tree, a (node ID, terminal node ID) table that describes the path to each node in the tree, and the fact tables around each node. The following query computes the aggregates for all nodes in ~500 milliseconds for a full tree with branching factor 5 and depth 8 (~100k nodes), on the analytical DB MonetDB running on dual core box. Adding new nodes to this schema is O(depth) because the path to each node is compressed to each of its ancestors, whereas aggregates are faster because of the de-normalized paths. CREATE TABLE tree (  node_id bigint not null,  end_node_id bigint not null,  PRIMARY KEY (node_id, path_node_id))-- Random fact tableCREATE TABLE stats1 (  node_id bigint not null,  stat int not null,  primary key (node_id)) Generate a summary for all nodes (~500ms for ~100k nodes) SELECT  tree.node_id as node_id,  AVG(stats1.stat) as s1 -- AVG can be any UDF f(int*)FROM tree  INNER JOIN stats1 ON stats1.node_id = tree.end_node_idGROUP BY tree.node_id Generate a summary for a single node (~1ms for ~100k nodes) SELECT  AVG(stats1.stat) as s1 -- again AVG can be any UDFFROM tree  INNER JOIN stats1 ON stats1.node_id = tree.end_node_idWHERE tree.node_id = ${any_node_id} The above queries are data parallelized per node and a good analytical DB will plan them in parallel. Throwing iron at problems like this is a reasonable scale up strategy. Start with server X, then scale to a 32-core machine with 128GB RAM (can get this for under $10k), then shard the tables by node ID and run each query across all the partitions and bring the results together in the application logic. (that order is not necessarily correct for you. e.g. running on EC2 would favor sharding before larger boxes) Another reasonable strategy to bring down the time of the queries gets too much is to invest some time in building your own high performance data structure that solves exactly your problem. In this case, you don't need general Complex Event Processing (CEP) system. A tree with a fast aggregate implementation would do wonders. Here's Scala code to run the above queries end to end (though you'll need to create your DB):   def main(in: Array[String]) {    Class.forName("nl.cwi.monetdb.jdbc.MonetDriver");    val con = DriverManager.getConnection("jdbc:monetdb://localhost/${your_db_name}", "monetdb", "monetdb");    val s = con.createStatement()    // Clear the tables    s.executeUpdate("DELETE FROM tree")    s.executeUpdate("DELETE FROM stats1")    val treePath = "/home/brien/treetable"    val statsPath = "/home/brien/statstable"    val (n, m) = writeTables(treePath, statsPath)    s.executeUpdate("COPY " + n + " RECORDS INTO tree FROM '" + treePath + "'")    s.executeUpdate("COPY " + m + " RECORDS INTO stats1 FROM '" + statsPath + "'")    for (i <- 0 until 10) {      // Summarize all nodes with a simple average      val time0 = System.nanoTime      val rs = s.executeQuery("""		    SELECT tree.node_id as node_id, AVG(stats1.stat) as s1				FROM tree				INNER JOIN stats1 ON stats1.node_id = tree.end_node_id				GROUP BY tree.node_id		    """)      while (rs.next()) {        val id = rs.getLong("node_id")        val s1 = rs.getDouble("s1")        if (10 == id) {          printf(">> %d\t%f\n", id, s1)        }      }      rs.close()      val time1 = System.nanoTime      printf("Summarized all nodes in %dms\n", (time1 - time0) / (1000 * 1000))    }    for (i <- 0 until 10) {      // Summarize one node with a simple average      val time0 = System.nanoTime      val rs = s.executeQuery("""		    SELECT AVG(stats1.stat) as s1				FROM tree				INNER JOIN stats1 ON stats1.node_id = tree.end_node_id				WHERE tree.node_id = 10		    """)      while (rs.next()) {        val s1 = rs.getDouble("s1")        printf(">> %d\t%f\n", 10, s1)      }      rs.close()      val time1 = System.nanoTime      printf("Summarized one node in %dms\n", (time1 - time0) / (1000 * 1000))    }  }  def writeTables(treePath: String, statsPath: String): (Int, Int) = {    val pw = new PrintWriter(new BufferedWriter(new FileWriter(new File(treePath))))    val pws = new PrintWriter(new BufferedWriter(new FileWriter(new File(statsPath))))    val r = new scala.util.Random()    // Insert a full tree of depth D branching B    val D = 8    val B = 5    var id = 0L    var pn = 0    val p = new Array[Long](D)    def btree(d: Int) {      p(d) = id      for (i <- d until D) {        pw.print("%d|%d\n" format (p(i), id))        pn += 1      }      pws.print("%d|%d\n" format (id, r.nextInt(1024 * 1024 * 32)))      id += 1      if (0 < d)        for (i <- 0 until B)          btree(d - 1)    }    btree(D - 1)    pw.close()    pws.close()    printf("Inserted %d nodes\n", id)    (pn, id.toInt)  } Updated 198w ago â€¢ View Upvotes