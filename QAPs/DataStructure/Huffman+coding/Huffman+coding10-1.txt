How do I calculate the code word length using Huffman Coding?
The formula is wrong. Huffman’s construction does not guarantee that all the code words are the binary log of the probability, rounded up. So the “correct” solution is not correct. Given that it’s not correct, I wouldn’t be surprised if there are also calculation errors in there, explaining how they can get five bits for a symbol of probability 0.1. For this problem, it is quite easy to do the algorithm by hand, and you find that the resulting tree uses 1 bit for U4, 2 bits for U3, and 3 bits each for U1 and U2. Disregard this incorrect information and find a better source! 928 Views · Answer requested by Alena Everdeen