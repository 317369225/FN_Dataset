What are examples of long-run marginal costs, and why are they positioned on the graph to intersect the lowest point of the long-run curve?
Long run marginal costs are the additional costs of increasing output when you have the opportunity to vary all the factors of production.  By way of example, imagine you run a restaurant and your output is meals served.  In the "short run" you can choose to employ extra cooks and servers, but you can't vary the size of your kitchen, so the only way to increase the number of meals you serve is to hire extra cooks and crowd them into the kitchen.  Up to a point you'll get more meals - six cooks can produce more meals per hour than three cooks - but the additional cooks won't produce as much as the ones you currently have - six cooks won't make twice as many meals as three cooks in the same kitchen. In the long run, you can also increase output by buying extra kitchen space.  So instead of hiring three extra cooks to hit a certain output, you might hire one extra cook and install an extra cooktop.  This -we're assuming - will be cheaper than hiring three cooks, so the long run marginal cost of producing the extra meals is lower than the short run cost, because you have more options.  The long run marginal cost of the extra meals is the cost of the extra cook (going from three to four) and the cost of the extra cooktop, divided by the number of extra meals you are able to produce. Why does this measure of marginal cost cut the average cost curve at its lowest point?  It's nothing to do with economics, it's simple maths: average cost is total cost divided by total output.  If each extra unit is costing you less than your current average then the average must be falling - if you are making 100 meals at an average cost of $10 each and you make some more meals which cost less than $10 each then the average has to fall, because you are adding lower numbers into the average. The reverse argument applies if the extra cost of adding units is higher than your existing average.  If making more meals costs you more than $10 per meal then your average cost per meal has to rise. So whenever the average cost is falling that must mean the marginal cost curve lies below the average cost.  Wherever average cost is rising, that must mean than marginal cost is higher than average cost.  So where do the two curves cross?  That can only happen when average cost is neither rising nor falling - at a minimum on the average cost curve. This is long, but hopefully fairly complete. 