What does object-oriented programming do better than functional programming, and why is it the most popular paradigm when everybody seems to say functional programming is superior?
As I've answered before, Object-Oriented Programming's greatest strengths are Discoverability, Modularity, and Extensibility, but I'll expand on each of those in this question. I'll mostly ignore the question about popularity, since that's mostly a social phenomena, and has hardly any relationship with the technical merits of both models of computation. Note that for the sake of answering this question, I'll be considering William Cook's simplified, modern definitions of "Object" and "Object Oriented", but within the original view Alan Kay had when he coined the term. In short, this means that this answer considers "Object Oriented" any program that is comprised entirely of objects (as defined by Cook), and whose computations (including control flow) are performed exclusively by objects communicating amongst themselves. Thus, I'm mostly going to talk about Smalltalk dialects and environments, and ignore virtually everything else (C++, Java, JavaScript, Python, Ruby, …, as these don't meet the minimum requirements — e.g.: they have if, for, etc. statements, which are neither objects, nor messages). How are OOP programs Discoverable?Programs written in an Object Oriented model of computation are comprised entirely of objects, and computations are expressed solely as messages sent from one object to another. Given a reflective environment, and an object, any user may ask the system what kind of computations they can perform with that object. Smalltalk environments are entirely based on this, and they try very hard to make the experience feel like working directly with live objects, rather than descriptions of programs. You manipulate actual entities, you ask those entities to do work, directly. Writing code at all in Smalltalk is a very accidental thing, and a very different experience from writing code in any other environment too — you can see the changes right away, there's no such a thing as "writing a program" and "running a program", they're one and the same. Discoverability is a very important issue, because in order to make a system do any work at all, a programmer must first know what they can do with the system. Reflective OOP environments, such as those used in Smalltalk, try to solve this problem at the very core of their programming experience, from the programming language and model itself, to the environment in which you interact with them. The Discoverability problem can also be solved in other languages/models, of course. But you can't ask the data itself what you can do with it (logic and constraint models aside). In functional languages, this can be solved by asking the type system what you can do with a type, instead, or by using any other kind of constraint system (external to the actual data) to resolve the relationships. I am only aware of Haskell, PureScript, and dependently typed functional languages, such as Agda and Idris, trying to take advantage of this, however — although you could consider intellisense and type-aware completion a similar feature in IDEs, to a certain extent. How are OOP programs Modular?Programs written in an Object Oriented model of computation must perform computations only by having objects communicate with each other, through message passing. Because of this, each object must be entirely self-contained units of computation, that expose a well-defined set of operations. Interestingly, this is also the definition of Modules in ML, as formalised by Rossberg et al. A modular entity allows a set of very desirable properties in a system. In essence, each module is a completely independent component, which can only interact with other components through a well-defined interface. Given this, it's possible to replace, at any given time, said component by another with an equivalent interface, without having to change anything else in the system. And any local changes are confined to the module itself, so long as the interface does not change. While ML is the dialect of functional languages with the best module system in existence (1ML has first-class modules, OCaml has applicative parametric modules, and SML has generative parametric modules), very few mainstream functional languages have a good support for writing this kind of system. Haskell did not get a real module system until the Backpack research kicked in, and it's still very far from ML. On the other hand, very few OOP languages tend to use this property to provide the user with a powerful module system, such as ML's, the only one I'm familiar with is Newspeak's first-class generative parametric modules as objects — which work in interesting (and very powerful!) ways with Newspeak's hierarchy inheritance semantics as far as extension and refinement goes. How are OOP programs Extensible?My other answer used the term "polymorphism" with a footnote clarification of the kinds of polymorphism I meant... which is an horrible thing to do, so for this answer I decided to use a better term: "Extensible." BY THE WAY You should totally read Cardelli's On Understanding Types, Data Abstraction, And Polymorphism paper if you just went "eh?" over the previous phrase. Cook has a follow up contrasting ADTs and Objects, too. There are too many contextual usages of the word "extensible" for different things in PL, but in general it means that the user of the system (language, library, etc) may extend the amount of meanings natively encoded in the system. So, for example, if the word "+" is used for arithmetic addition, natively, an extensible system would allow the user to extend the meaning of that word to also cover lists, strings, vectors, and other data structures. There are many ways of going about this, some of which are very interesting, but impractical. In the Object Oriented model, one gets ad-hoc polymorphism for free because of how dynamic dispatching on object messages work. In other words, in OO the meaning of words (such as "+," or "if") is entirely defined by the objects themselves, therefore the entire system is naturally extensible. Furthermore, the Modularity aspect of the Object Oriented model, as presented in the previous section, plays a key role in this characteristic. Each Object in the system is a completely independent module, this allows one to pick existing modules and easily abstract over them, by refining the object, its behaviours, or even its interface. The means for doing this vary, as does the pros/cons for each choice, with inheritance being the most common, but Traits, Mixins, Object Algebras, and other models of combining and refining objects exist. Surely many "functional" languages allow different forms of extensibility, dynamic dispatching and ad-hoc polymorphism: Type Classes in Haskell, Protocols in Clojure and Purr, Implicit Calculus in Scala (although Scala's semantics use objects heavily), Multi-methods in CLOS (I don't want to call Common Lisp functional, but...), Modules in ML, and so on, and so forth. But these features are somewhat separated from the core model of the underlying language, thus abstraction facilities on top of them are very different from the abstraction facilities for the core model semantics. For example, Type Classes in Haskell are second class, and it's not possible to abstract over them. Modules in ML (bar 1ML) are second class, and there's a special, second class construct for abstracting over modules called Functors. There's nothing to abstract over Functors. Protocols in Clojure are first-class and dynamic, but Protocols are a very different beast from regular functions, and you can notice that when importing a Protocol from a different namespace. Purr's Protocols are first-class, and they integrate well with Purr's module system, but there's (currently) no way of abstracting over them. Global uniqueness is also enforced, like in Haskell. On the popularity of Functional LanguagesI said I'd mostly ignore touching on this topic, but I've got a few words on some technical aspects that might have contributed for the lack of popularity of functional programming languages as a general-purpose programming tool. While it would be entirely possible for functional languages to incorporate all of the characteristics described above without changing their core computational model (Purr tries to incorporate many of these characteristics, while being a pure functional language at its core), there are a few things that are pretty much open research in PL that functional languages suffer from: Functional programs must be pure (i.e.: free of side-effects). This is a very difficult problem because all of the things we interact with are full of side-effects, and we want to control them in our programs. Existing FP languages use various less-than-satisfactory tools for this: Monads or CPS for sequencing actions (Haskell, Purr, PureScript, and most other Haskell dialects), Effect Systems (Clean, Koka), Algebraic Effect Handlers (Eff), Uniqueness Typing (Mercury), and possibly others I'm not aware of. Problem being these solutions are either actively being researched today (i.e.: we don't have a definitive answer for their practical applicability yet), or they are known to have various problems that make writing programs difficult (e.g.: it's not possible to compose Monads, and Monad Transformers are a less-than-ideal solution in Haskell); Describing changes in values over time is tricky because of the previous point. Things must be able to observe the changes of a value, but must do so without side-effects. There are several solutions proposed, which tackle different aspects of the problem, I am, unfortunately, not aware of any that doesn't suffer from limitations also present in the previous point. That said, FRP is a very powerful model, and Elm has made a very successful use of it for the domain of GUI applications; Since functional languages are less used, there are less readily-available libraries for solving problems people are interested in solving today, for many areas, which are otherwise available in mainstream languages, such as Java and C#. Clojure, Scala, PureScript, F#, and others solve these problems by sacrificing some of their semantics for interoperating with these existing libraries without hassle, which eases their adoption; Other things that factor in are lack of good materials (surprisingly, this one becomes more difficult when the language's popularity increases, see all of the bad tutorials on Monads in Haskell), lack of incentive (people don't see the value of throwing all of their things —that work today— away to start rewriting them from scratch under vague "it'll be better!" promises), lack of educational support (most colleges apparently don't even expose students to FP), lack of good tooling (although FP makes them easier to write in many aspects), lack of good ecosystems, and, of course, lack of popularity itself, which means they're much less visible, and much less likely to be picked as something to use for Your Next Big Project™, since you're not aware you should be considering them to begin with. In any case, Leo Meyerovich et al wrote extensively about why some languages are adopted, while others are not, and tried to provide an empirical basis for all of this social phenomena on what they've called Socio-PLT, although I have only read one of their papers so far — but it's all very interesting. ConclusionThis turned out more gigantic than I expected it to be. I am sorry. To sum it up, the Object Oriented model of computation may lead naturally to very desirable characteristics, such as Discoverability, Modularity, and Extensibility (as further refined in this article). While Functional languages may provide the same properties, they do not arise naturally from the model, so they have to be captured in external semantics tacked on top, such as Type Classes/Protocols/Modules. This is not inherently bad, but most of the existing languages don't really try deeply integrating these with the core model in order to achieve the characteristics presented here. Furthermore, while FP, as a model of programming, is very old, and very well-understood in academia, some of the required functionality for practical applications of this model in plenty of domains is either an open research question, or not very well supported by the existing language's ecosystems, at least not idiomatically in the language — one would need to provide their own functional wrappers. The other social aspects of programming language adoption end up making most people stick to existing, mainstream technologies, although the adoption of functional languages has increased a lot in recent years. 