What skills are needed for machine learning jobs?I am a learner sitting at home and learning linear algebra. Very interested in working in Machine Learning someday, but not sure: a) What technical skills are needed for an interview/job. b) Any relevant mandatory work experience. I have taken an initiative to at least start rather than just think about doing it so any suggestion/guidance would be very helpful and appreciated.
Many of these answers have given you a certain set of tools which have been commonly used at startups in the past. I think its important to note that over your 35+ year career, these tools will change completely. Therefore, its best to familiarize yourself first with the basic concepts and mathematics. Secondly, the ML field is much too diverse to understand dozens of different algorithms in any real depth. I think you should pick a few of the algorithms with the most future promise, and understand those very deeply. That said, there are a few basic things like Naive Bayes, SVM, Perceptrons, Decision Trees, that you should know well. Finally, folks from the startup / non-research world will tell you to focus on algorithms that are "getting long in the tooth" (e.g. SVM) and the Big Data database tools like Hadoop. Since you are starting out, I think you should focus on the architectures which seem most promising for the future: neural networks and SIMD/vector computing (e.g. GPUs). Neural network approaches have recently (<10 years) begun to revolutionize natural language processing, machine vision, speech recognition and many other fields. Because of their power, this is expected to continue. Thus, I would focus on learning and implementing such algorithms yourself with GPU acceleration, and tied into some distributed database. Here's a list of algorithms to consider: 1. Deep Belief Nets  or Stacked Denoising Autoencoders 2. Convolutional Neural Nets 3. Long Short Term Memory (LSTM) recurrent nets 4. Recursive Neural Nets (often used for NLP) 5. word2vec and related algorithms for learning words from their context Another very promising field is Reenforcement Learning, especially the Q-Learning work from Deep Mind. This is used when you have some delayed reward function (e.g. your score during an Atari game) and you can't directly calculate the gradient of the parameters in your network. After you get some familiarity with the above items, you may want to explore this area since it is very relevant to robotics and more realistically simulates how people or animals actually do most of their learning. -------------------- UPDATE: I've come to the opinion that, for the past year, we are starting to see tremendous progress in combining different neural algorithms into a single "deep" system for which the sum is greater than the parts. I expect that the most profound progress will largely come from this direction since the basic building blocks have been established. In part, this is enabled by pre-training the individual blocks before fine tuning the whole system, as well as faster computer clusters. (We will also continue to see progress in individual algorithms, however.) In other words, we are seeing LSTM combined with ConvNets and Multilayer Perceptrons (MLP) to do things like writing sentences describing images (Google/Stanford). Similarly, we saw an Atari playing network made of a ConvNet and MLP trained with reenforcement learning (Deep Mind). You could just as easily add to this list: feeding such composite networks word vectors trained from word2vec/GloVe/skip-gram. Or even a sentiment analysis layer trained with a Recursive Neural Network.  Because neural networks and backpropagation makes it easy to combine/stack layers in arbitrary geometries, and train the conglomeration as a whole system, they can scale to great capability. These hybrid systems, consisting of many different types of neural nets, connected in various topologies, pre-trained individually and fine-tuned together, will continue to demonstrate dramatic new capabilities. -------------------- Updated 2 Sep • View Upvotes