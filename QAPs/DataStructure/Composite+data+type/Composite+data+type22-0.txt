What are advantages and disadvantages of using Kiji framework(Which is built over Hadoop).?Will it have any impact on the running time?
The Kiji project, as it is currently, has two major goals: 1) make it much easier to develop applications on top of HBase, and 2) make it easier to build applications that do predictive modeling, especially applications that require real-time model scoring. Since all data stored in Kiji is stored in HBase, it's really only applicable if an application will be using HBase, although you could, in theory, write arbitrary MapReduce jobs with it. To achieve the first goal, Kiji provides a number of sub-projects for different purposes. Â KijiSchema is a schema management layer on top of HBase, and the core of the Kiji project. It provides things like row key hashing, which helps avoid hotspotting of servers and composite row keys which can be used to store different components of a row key in native formats (like integers in a native format, rather than an ASCII representation). Additionally, any data stored with KijiSchema is stored as Avro data, which gives it a compressed, binary data format that can store richer data types than the binary data that HBase stores natively. Kiji handles all of the serialization and deserialization of data, so that the application doesn't have to worry about it. KijiMapReduce provides a few layers on top of MR to do things like efficient bulk loading into KijiSchema/HBase, feature extraction, data enrichment, model scoring, as well as model training. For integration with applications, KijiREST provides REST endpoints to access and manipulate data. KijiScoring is a real-time component, which makes it possible to do things like feature extraction or model scoring in real-time as users are interacting with the application. KijiHive gives users a Hive interface to do data exploration or model development. KijiExpress is one of the more interesting projects, and is a Scala-based DSL, built on top of the Twitter Scalding APIs, which helps with data exploration, as well as writing more concise, complex jobs against Kiji. Some of the new development happening is around defining a predictive model lifecycle, from data preparation to feature extraction to training, scoring, and eventually easy deployment of a model into production. The goal is to cut down on the time-to-market for new models, by avoiding the paradigm of data scientists developing models in tools like R or SAS, and then having to have a developer translate those models into Java or some other application language. While I don't have much in the way of numbers to share on how much overhead Kiji adds, testing over at WibiData and with our customers seems to show that the overhead is pretty low, and (at least in my opinion) the benefits seem to outweigh the costs. 