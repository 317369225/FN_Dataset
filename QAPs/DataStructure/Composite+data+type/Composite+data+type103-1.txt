What is the most efficient way to sort 4TB on a single machine with 4GB of RAM?
We can use an External Merge Sort to efficiently sort large data sets when we have memory restrictions. In this particular case. Split the 4TB data set into 4GB chunks. Read each 4GB chunk into memory one at a time and sort it using a conventional sorting algorithm, such as Quicksort. Write each sorted chunk back to disk. Read the first 200MB of each 4GB sorted chunk into memory. These will be our input buffers. Totally, all the 200MB chunks will occupy 2GB of memory. The remaining 2GB of memory will be our output buffer. We perform an n-way merge on the 200MB chunks and store the result in our output buffer. When our output buffer gets filled, we write it out to disk. When a 200MB input buffer becomes empty, we read the next 200MB from the remaining part of the original 4GB chunk. When we've exhausted all our 4GB chunks and all the 200MB input buffers, we write out the 2GB output buffer one final time to disk and we should now have a sorted 4TB data set. src: External sorting 