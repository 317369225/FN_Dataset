How can I express a "class" (programming) in category theory?In programming we use classes to define objects through fields (data) and methods (behaviours). How this should be correctly written/expressed in mathematics/ category theory ? Is there studies/references on this particular problem ? What are the categories (names and properties) involved by classes ?
We can model object-oriented classes as F-coalgebras. This has practical applications: it's used by existing tools to model the semantics of object-oriented programs. It also gives us interesting insights into OOP, including a view of classes as reactive systems. The first thing we have to do is understand what a class is. What are the essential properties we want to capture formally? This is tricky because classes in different languages have different capabilities and behaviors. Perhaps the one defining property of an object is that it has some hidden, internal state: a this value. We can only interact with this state through its public interface as defined by its class. Modeling classes as coalgebras shines the spotlight on this particular aspect: the main structure of a coalgebra is that every operation it exposes takes the same input— this. To understand how this works, you need to understand what an F-coalgebra is. I wrote a longer explanation on StackOverflow, so here's a concise definition: given some functor F  , an F-coalgebra is a morphism of the form a→F(a)  for some specific a  . F  is the signature of the coalgebra: it determines what operations it has. In the context of a class, this would be a class signature—the public methods and properties of a class, but without an implementation. In Java terms, it's what you would get if you took all the public members of a class and extracted them into an interface. a  is the state space: all the possible objects in the class in terms of their internal state. A class combines the two by giving an implementation of the public interface defined by F  in terms of the private state defined by a  . The input a  in a→F(a)  is the value of this; the result (ie an element in F(a)  ) is an object with that internal state that you can manipulate in terms of F  . This is probably easier to understand with an example. Lets take a trivial class defined in pseudocode, a circle which internally stores a radius and position and allows you to move it and compute its area. class Circle public: position : (Int, Int) radius : Int area : Int move : Vector -> Circle private: pos : (Int, Int) r : Int Note how the public and private parts are separated for us. The public parts will get extracted into a signature F as a functor and the private parts will be a normal product (record) that stores the circle's internal state. For simplicity, I'll show you how to turn this into an F-coalgebra in Haskell—but you could translate this pretty directly to set theory if you wanted to model it logically. Now we render F as a type that takes a as a parameter. This type captures the public interface we defined above; when it needs to update the object (ie return a new Circle), it just returns a: data F a = F { position :: (Int, Int), radius :: Int, area :: Int, move :: Vector -> a } F is a functor that captures the class's public side—how it's seen from the outside, without the extra this parameter or its internal state showing. F is a functor because it maps any type a to F a, while preserving functions and function composition. In Haskell, we can automatically derive this fact (with the DeriveFunctor extension) or manually demonstrate it by specifying how functions are preserved: instance Functor F where fmap f obj@(F { move }) = obj { move = f . move } We have to transform the a into a b using the function that's passed in. The only instance of a in the actual type of F is in move :: Vector -> a, which we have to turn into Vector -> b by composing it with f. Now we need to implement the internal state, which I'll unimaginatively call A: data A = A { pos :: (Int, Int), r :: Int } The class Circle is then reified as a specific F-coalgebra. circle :: A -> F A circle = \ this -> { position = pos this, radius = r this, area = pi * (r this ^ 2) move = \ v -> this { pos = pos `translateBy` v } } If you're familiar with Python or a similar language, you know that we can think of methods as functions that take an extra this parameter. (Or self, as the case may be.) This is actually the same idea; with a bit of syntactic manipulation, we can verify that the type A -> F A is isomorphic to the following type: data FA = { position :: A -> (Int, Int), radius :: A -> Int, area :: A -> Int, move :: A -> Vector -> A } Informally, to go from this concrete type to the F-coalgebra, we just need to factor out the common argument in each case— this or self. So why is this idea useful? It might seem pretty trivial—or at least it did to me when I first learned about it! I was expecting something a bit more complicated. From a practical standpoint, it's useful because any formalization of OOP at all would be useful. We can use this formalization as a starting point to writing and verifying formal specifications of object-oriented programs. To me, however, this idea is interesting because it gives us a new perspective on OOP, what it means and how it relates to other ideas. As an aside, this is why I feel that mathematically modeling concepts has value even if you don't care about formal reasoning or proofs—by expressing something in abstract terms, we can find deep similarities with other concepts that do not seem related intuitively. Abstraction helps us think outside the box by abstracting over the boxiness :). One other place coalgebras come up is in studying automata and, more generally, reactive systems. A reactive system is, informally, one that changes over time, providing more output or changing states when given more input. Robotic agents, network servers and GUIs can all be seen as reactive programs. From this perspective, a class is a way of specifying a fancy state machine—the private values are the internal states and public methods are the inputs and outputs the machine has. An object is an instance of this specific type of state machine, merrily running along, taking input, changing states and producing output. Perhaps to others this view of OOP is not a surprise, but it was quite a revelation to me! (In hindsight, the idea fits really well with Alan Kay's original ideas about OOP.) A specific advantage of realizing this connection is that it lets us bring analytic tools originally developed for working with automata to bear on object-oriented programs. A particularly relevant idea is bisimulation, which defines a notion of equivalence between automata based on their behavior. Another interesting relationship which I'll mention in passing is to functional programming and algebraic data types from languages like ML. Algebraic data structures are closely related to F-algebras, the formal dual of F-coalgebras. (An F-algebra is a morphism F(a)→a  to a coalgebra's a→F(a)  .) In a slightly vague sense, functional programming and OOP shine a light on dual aspects of computation. (Both kinds of languages can express all programs, but make some more natural than others.) Further Reading "Objects and Classes, Coalgebraically", Bart Jacobs, is a good overview of modeling classes as coalgebras and reasoning about observational equivalence of objects with bisimulations. "A Tutorial on (Co)Algebras and (Co)Induction", Bart Jacobs and Jan Rutten, gives more details about coalgebras and their relationship to algebras. "When is a function a fold or an unfold?", Jeremy Gibbons, Graham Hutton and Thorsten Altenkirch, expands on the role of algebras and coalgebras in functional programming, particularly through their relationship to the higher-order functions fold and unfold. 