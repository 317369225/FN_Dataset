What are some limitations/disadvantages of functional programming?
Performance A big problem is with predictable performance. This means that most functional languages are not particularly good choices for soft or hard realtime systems or embedded computing. There are a few reasons for this, like higher reliance on garbage collection as well as different evaluation models (ie laziness). Garbage Collection Functional languages, by their very nature, tend to generate larger amounts of short-lived garbage than imperative languages do. While their garbage collectors tend to be optimized for this use profile, it still makes predicting and controlling performance more difficult. Laziness Laziness is an issue for predictable performance because it moves evaluation—ie the actual computational cost—from the place where a computation is defined to where its used. This makes the performance model of a lazy language less compositional. In a strict language, we know that the running time of a ⊕ b is simply the sum of the time it takes to calculate a, b and combine them with ⊕. With a lazy language, we do not know if a or b will actually be used by ⊕, we don't know if the whole expression a ⊕ b will ever be run at all and we don't know if parts of the expressions may have been computed already and are just sitting in memory. This makes idiomatic lazy code somewhat harder to analyze for performance. On the flip side, laziness makes your code more compositional in other ways. Edward Kmett wrote a good explanation of this and the famous "Why Functional Programming Matters" article by John Hughes gives a deeper overview. DSLs Now, just because functional programming as such isn't a good fit for realtime programming does not mean you should abandon Haskell for these tasks! Haskell serves as a strong language for hosting domain specific languages. This means you easily embed a low-level imperative language into Haskell, taking advantage of functional programming for making abstractions and metaprogramming but still getting the performance you need in an embedded setting. DSLs also make it easier to formally verify your program. This is very important for writing high-assurance code, which is a good fit for things like automating expensive or dangerous machinery. Galois uses this approach for several different tasks, like automating quadcopters with their SMACCMPilot project. General KnowledgeOne problem with functional programming is that it's simply so different from what you already know. This means that you have to re-learn a lot of what you already know in an imperative setting! This is something of a turn-off for certain experienced developers who are already comfortable with what they already know. This also means that some things are less well understood with functional programming than with imperative programming. Many algorithms and data structures are designed largely with imperative languages in mind, which makes it more difficult to implement them in functional languages like Haskell. Just think about what "pseudocode" usually looks like: it's just a simple imperative language. (As a cute side-note, this also means that standard pseudocode is actually not very expressive! When I was implementing unification for a simple Prolog, my Haskell code was neater and shorter than the pseudocode I was working from!) There are already good functional versions of many data structures and algorithms, so you're going to be fine for most common tasks. But if you go off the beaten path, you will probably have to put in some effort going from the imperative code and assumptions to passable functional code. For example, I ran into this problem when trying to implement a tree edit distance algorithm in Haskell: I could find normal edit distance code easily, but not the significantly more obscure tree algorithms. New ParadigmsI think your point about new paradigms falls into this section. It's a mix of both needing to learn new things and some things being less understood. However, while many of these things require a bit of learning, I think they provide significant advantages as well. Unlike many people would claim, many of these new abstractions are not just ways to get around being purely functional; they confer tangible advantages beyond just being functional. Persistent Data Structures Persistent data structures are a great example. They're not very common in imperative programming because most imperative programs use a lot of mutation. But they are not just extra baggage you need to use functional programming: they're actually a significant new way to write good code. In particular, these structures make it significantly faster to work with multiple immutable versions of the same thing which, in turn, makes writing correct multithreaded code simpler. They also make it much easier to save memory space by sharing as much of a data structure as practical. Normally, writing two trees that share a bunch of nodes would be rather awkward and error-prone. Doubly so if the trees are mutable! Consider this illustration from Wikipedia: Maintaining two interleaved trees like this by hand would be a real pain! But with persistent data structures, you get this for free. So yes: you do have to learn something new to do the same tasks functionally as with imperative programming, but you also gain new capabilities! Functional Reactive Programming FRP is yet another new thing to learn. But this is not so different from imperative programming where you would have to learn about event-driven programming and MVC to do many of the same things! Moreover, imperative UI programs tend to devolve into utter spaghetti code pretty quickly. Events and callbacks are the most common approach, but they're simply not a good way to model control flow. FRP offers a much higher-level, more declarative way to write the same sort of UI code. In my experience, it also makes maintainance and adding new features much easier. However, it's not all roses. FRP is an idea that's still being explored by the functional programming community. There are different approaches to it, with different trade-offs. There are also performance issues like space leaks in many common applications. Another problem is that bindings to UI toolkits like WX are often a bit awkward to use and hard to compile, largely because these toolkits were never designed with functional programming in mind. In Summary I think that's a wonderful summary of functional programming in general, actually. You get nicer, more expressive abstractions but they require you to learn new things, potentially sacrifice performance and often have some rough edges. I generally believe that the advantages to productivity and maintainability are worth the up-front learning cost and the increased difficulty in performance. This is especially true since languages like Haskell can be optimized pretty far if you really want to: GHC tends to be on par with Java on the Computer Language Benchmarks Game, for example. And even unoptimized code generally tends to run faster than the popular dynamically typed languages like Python. 