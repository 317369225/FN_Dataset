Why the current obsession with big data?
Unlike some of these answers, I am more sympathetic to the premise of the question, which is that there is undue emphasis on the size of datasets and size is not exactly the right metric.  That being said, I would say that the size of the dataset will often correlate with what I think is indeed the right metric, which would be the diversity/quality of the data. A large dataset of data that all has the same bias (systematic error) will not give you better insight into a question. Instead, it will give you a very precise measurement of your flawed answer.  For example, it doesn't really matter if you ask 100 teens or a million teens about the best movie of all time.  You'll still get an answer that discounts older movies no matter how many you ask.  Larger datasets will tend to include more diversity so you can control for this error.  Netflix's data includes all different kinds of people, so their algorithms can account for the bias that may come from potentially having more teens in their database.  But they can't say anything about the entertainment preferences of people who don't like to use the internet (or mail order dvds) and no amount of their data will help.  Twitter data has an even worse problem as the kind of people who tweet are even more unrepresentative.  I'd much rather have a smaller dataset of more representative users to answer questions that people often use Twitter for.  It's not just sampling that causes error.  Consider Facebook likes.  I believe that Texas A&M is the most liked college on Facebook.  What does that mean?  Since there is no dislike button, it's hard to even say that they are the most popular.  We also can't say whether it has a good alumni group, has popular sports, or is good academically, and the volume of data won't help us.  Instead, we need more detail. The gist here is that larger datasets are generally better datasets.  But there are lots of things that are more important than the size of a dataset, among them being sampling, diversity of measurement, and detail of measurement. For more detail: Better Data, Not Bigger Data - Thoughts from the Data 2.0 Conference or Nate Silver talks about "Putting Data Fidelity First" (ahead of data size) e.g. Conference Review: IA Summit 2011: Part II Indeed, the successes of Silver/people in the last election were a result of aggregating lots of different measurement and sampling techniques, which is far better than taking a single super-sized dataset that uses a single measurement and sampling technique. 