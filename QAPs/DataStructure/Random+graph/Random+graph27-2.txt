Why the current obsession with big data?
Answering this question requires some history. So please bear with me for a moment as we go back in time a little... Don't worry - this will all come together in the end! The "current obsession" with Big Data is not new. During the last 25 years there have been numerous periods of great interest in storing and analysing large data sets. In 1983 Teradata installed brought on Wells Fargo as their first beta site. In 1986 this software was Fortune Magazine's "Product of the Year" - it was exciting because it pioneered the ability to analyse terabyte-sized data sets. By the early 90's most big banks had all their data in a data warehouse of some sort, and there was a lot of work going on in trying to work out how to actually use that data. Next was the big OLAP craze. Cognos, Holos, Microsoft OLAP Services (as it was then called), etc. were what all the cool kids were talking about. It was still expensive to store very large data sets, so through much of the 90's Big Data was still restricted to bigger companies - especially in financial services, where lots of data was being collected. (These companies had to store complete transactional records for operational and legal reasons, so they already were collecting and storing the data - that's another reason they were amongst the first to leverage these approaches.) Also important in the 90's was the development of neural networks. For the first time companies were able to use flexible models, without being bound by the constraints of parametric models such as GLMs. Because standard CPUs weren't able to process data fast enough to train neural nets on large data sets, companies such as HNC produced plugin boards which used custom silicon to greatly speed up processing. Decision trees such as CHAID were also big at this time. So by the time the new millenium rolled around, many of the bigger companies had been doing a lot of work with summarising (OLAP) and modelling (neural nets / decision trees) data. The skills to do these things were still not widely available, so getting help cost lots of money, and the software was still largely proprietary and expensive. During the 2000's came the next Big Data craze - for the first time, everyone was on the web, and everyone was putting their processes online, which meant now everyone had lots of data to analyse. It wasn't just the financial services companies any more. Much of the interest during this time was in analysing web logs, and people looked enviously at the ability of companies like Google and Amazon who were using predictive modelling algorithms to surge ahead. It was during this time that Big Data became accessible - more people were learning the skills to store and analyse large data sets, because they could see the benefits, and the resources to do it were coming down in price. Open source software (both for storing and extracting - e.g. MySQL, and for analysing - e.g. R) on home PCs could now do what before required million-dollar infrastructure. The most recent Big Data craze really kicked off with Google's paper about their Map/Reduce algorithm, and the follow-up work from many folks in trying to replicate their success. Today, much of this activity is centred around the Apache Foundation (Hadoop, Cassandra, etc.) Less trendy but equally important development has been happening in programming languages which now support lazy list evaluation, and therefore are no longer constrained by memory when running models (e.g. Parallel LINQ in .Net, List comprehensions in Python, the rise of functional languages like Haskell and F#). I've been involved in analysing large data sets throughout this time, and it has always been an exciting and challenging business. Much was written about the Data Warehouse craze, the Neural Net craze, the Decision Tree craze, the OLAP craze, the Log Analysis craze, and the many other Big Data crazes over the last 25 years. Today, the ability to store, extract, summarise, and model large data sets is more widely accessible than it has ever been. The hardest parts of a problem will always attract the most interest, so right now that's where the focus is - for instance, mining web-scale link graphs, or analysing high-speed streams in algorithmic trading. Just because these are the issues that get the most words written about them doesn't mean they're the most important - it just means that's where the biggest development challenges are right now. 