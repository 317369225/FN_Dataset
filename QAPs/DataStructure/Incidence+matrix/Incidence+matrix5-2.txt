Graph Theory: What's the intuition behind a Laplacian matrix?
L=D−W is referred to as the combinatorial or unnormalized graph Laplacian.Whereas  [math]D^{\frac{-1}{2}}(D-W)D^{\frac{-1}{2}}[/math]is identical to the Laplacian of a graph [math]\Delta : \mathbb H (V) \to \mathbb H(V)[/math] [1],which is expressed as : [math]\Delta \phi := -\frac{1}{2}\text{div}(\text{grad}(\phi)[/math]  −div is defined to be the adjoint of the graph gradient. Note that laplace operator is also dot product of gradient and divergence of a field [ that explains the primary  name] .However,divergence and gradient are formulated differently here, than flux/volume at a point and direction of fastest growth, [2],as, unlike a field, the flow of [math]\phi[/math] does not happen throughout the volume the encloses the graph. The divergence(div) here , measures the net outflow of the  function [math]\phi[/math] at each vertex[3]and the norm of the graph gradient(grad) here , measures the roughness of a function around a vertex, and the p-Dirichlet form the roughness of a function over the graph. Whereas , the eigenvalues of the lapalacian of the graph tell the number of spanning trees that exist within the graph and how well connected a graph is among other aspects that become of interest in specific cases.e.g.It turns out to be better than Gaussian elimination when solving Ax=b [balance condition of flow], in terms of computational complexity. If we assume the vertices of a graph are sampled from some distribution, then the combinatorial graph Laplacian does not converge to the usual Laplacian when the sampling size goes to infinity unless the distribution is uniform [1][math]\mathbb H (V)[/math] denotes the Hilbert space of real-valued functions endowed with the usual inner product. [2]As detailed in Page on Microsoft [3]Note that if [math]\phi[/math] is symmetric, then [math](\text{div}(\phi))(v)=0 \text{for all } v \in V[/math] 