Does a radio transmitter use more power when many receivers are tuned to its frequency than when there are no receivers?
Imagine you draw a polar diagram of the signal strength around a transmitter. Essentially that diagram will give you lines joining points of equal signal strength, rather like contour lines join points of equal height. In an ideal world they are sort of circular, with the transmitter at the centre.   Now imagine I introduce into this area an aerial whose length is carefully calibrated to be a certain fraction of the transmitter's wavelength. You can see that, at the right length I can absorb energy from the incident signal. If I now do my polar diagram bit again, my plot will now no longer be circular because I will be losing energy where the aerial can be found.   In order to maintain a given signal strength in all directions I would have to up the power transmitted in the direction of the aerial.   This only applies to terrestrial transmission, of course you can hardly stack aerials behind one another when the signal is coming from a satellite.   It used to be very important and there is a classic case of a farmer whose dairy herd were used to being entertained by the Home Programme in their dairy shed as a result of the tin roof rattling against the nails. He was very close to Daventry. (Caution, apocryphal).   So the answer to your question is a sort of yes. 