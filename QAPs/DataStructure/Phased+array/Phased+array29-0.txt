What are some of the hot topics currently being researched in machine listening/audio processing?
I finished my work at CMU LTI about six years ago, and I don't follow computational audio very much any more. But I have listed a few computer music research topics that I remember: Automated music transcription and automated categorization/classification is still an open problem. This includes multi-channel (voice/instrument) segmentation in different acoustic environments. Emotion/expression - Synthesis and transcription in audio Automated/Machine accompaniment/error correction in real time (live performances) Fidelity restoration/denoising/compression are other projects in the area of stats signal processing People mix-and-match additional modalities (EEG signals or electro-mechanical actuators or lights..) with music processing to create interesting artifacts Tools for real-time audio processing to aid in MOOCs. For example automated generation of audio hyperlinking/triggers Instrument acoustic models/synthesis and design optimization There are the standard projects on scalable evesdropping/transcription algos as well. Making it real-time is another challenge that I think people are still going on about. There were many hardware-driven research projects based on phased array and aperture synthesis/beamforming techniques for speaker classification/identification/speech segmentation as well. Here are some links. https://www.lti.cs.cmu.edu/rsrch... http://www.cs.cmu.edu/~rbd/Â  Thanks for the A2A 