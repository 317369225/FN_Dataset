How would one use Python to read a file with floating numbers, compute their averages and print the averages?
Here's my answer: This is a very common exercise for novice programmers.  In general the first hurdle is handling the input (which is in text) and converting each item into a number ... and finding some means to signal the end of the input. The specifics about computing an "average" (arithmetic mean) should be almost trivially easy if you've learned the most basic arithmetic and looping constructs in the language. You've said that you're expecting your program to take a filename and read numbers from it.  This implies that you are expecting one number per line and that you're expecting that it could be a floating point (or "real") number. Here's a simple snippet of Python which can read a list of floating point numbers, one per line, from a file: #!/usr/bin/env python from __future__ import print_function def average(something):     pass if __name__ == '__main__':     import sys     if not len(sys.argv[1:]):         print("Must supply a filename", file=sys.stderr)         sys.exit(1)              numbers = list()             try:                     with open(sys.argv[1], 'Ur') as input_data:             for each_line in input_data:         try:             numbers.append(float(each_line.strip()))         except ValueError as e:             print('Warning: Unable to parse %s: %s' % (each_line, e), file=sys.stderr)             except EnvironmentError as e:         print('Error accessing file %s: %s' % (sys.argv[1], e), file=sys.stderr)         sys.exit(e.errno)     print(average(numbers)) This might not seem all that simple ... but it is doing quite a bit more than you might expect. The first line is a "shebang" line.  In Linux and other Unix-like operating systems (including on MacOS X) this is a sort of magic comment used by the system to find the script's interpreter (the magic only works of the #! are the first two characters of the file). If this file contained Perl code then we could replace "python" on that line with "perl."  If we wanted to use a specific version of Python we might replace "python" with "python3.4" or "python26" depending on how the files containing these versions were named on your system. The /usr/bin/env command in Unix searches your PATH and finds the named program, executing it in its own environment.  In this case we're only using the fact that it searches the path and the resulting environment should be identical to the one from which we started our script. We could replace the whole line with something like /usr/local/bin/python3 or /usr/bin/python or /opt/mycompany/python/bin/pypy (PyPy) is a special version of Python). However, using /usr/bin/env is a widely accepted practice in the Python community and makes most of your scripts more portable.  Most common scripts will run under any installed version of Python (though there are some caveats to that). This "shebang" (or "hash bang") line is just a comment so far as Python is concerned.  It's harmless to have such a comment in your source code when you copy this file to an MS Windows system, for example.  It's also harmless if you call some Python interpreter directly and pass your script's filename as an argument to it (as shown in your question).  However the advantage on Unix-like systems is that you can mark the script as "executable" (chmod +x $YOUR_SCRIPTS_FILENAME) and thereafter run it just like any other program installed on your system.  (This is common for all normal scripting languages under Unix-like systems.  So common that it's often not explained in documentation except in the most rudimentary tutorials). The next line of my example uses a special feature of Python.  When the developers of Python add new features to the language they sometimes choose to protect the programmers using it from certain surprising changes.  So the feature is added but disabled by default.  To enable these new features you have to "import" them from the special __future__ module.  In this case I'm enabling the use of print() as a function and over-riding the treatment of print as a reserved keyword with "statement" oriented semantics. If you're using Python 3.x all of this is irrelevant.  This feature is enabled by default starting in Python 3.0.  However, it was not the case in older versions of Python.  So to get this behavior in Python versions 2.6 and 2.7 we have to use this sort of magic import to enable it. Python, in general, is making a slow transition from its 2.x and earlier version to the new Python 3 standard.  The change in print (as a statement) to print() (as a built-in function) is one of the most disruptive and visible changes, especially to new users.  However with this line and one other minor change (which I'll explain later) this example code will run on Python 2.6 all the way through Python 3.4 and should continue to run on future versions of Python indefinitely.  (It will also run under reasonably recent versions of pypy).  To get this example working on Python 2.5 and earlier you'd need to make at least three changes ... and I'm not going to go into such details because Python 2.6 was released over six years ago.  Suffice it to say that you should have Python 2.7 or 3.x available to you as you learn how to program in the language today. I'm including this so that you (and future readers of this answer) can cut-and-paste my example into any reasonably recent and foreseeable future version of Python and have it work. The awkward thing about this change from Python2 towards Python3 is that all the prevalent examples on the 'net use the old syntax (and most examples online include print statements).  So that and some other minor things complicate the example a bit. In the next line I'm simply defining a function, taking one required parameter, and doing nothing.  I've left this function this way so you can write yourself, because I'm trying to explain how to safely read a plain text file and return a list of floating point numbers from it. Once you have that then you should be able to completely your homework very easily. However, by reading this long screed, you'll also have learned a bit about handling simple command line arguments, opening, reading, parsing, and closing files, and handling a couple of types of errors that you may encounter along the way.  Additionally you'll then know a bit about compatibility challenges when using Python 2.x vs. newer 3.x versions. These aren't the focus of computer science classes.  But they are practical issues that programmers have to work with ever day. The next line is a bit tricky.  It's not strictly necessary and, in this case, it's actually somewhat useless. In short it separates the portion of our Python code which would be execute while the file is imported as a module from the portion which should only be executed when we run this file as a script. Many programming languages, such as C, C++ and Java, define a fixed entry point (named main() which must be defined in any module which can be compiled into a program.  Files with no main() function can only be compiled into libraries (in those languages). By comparison many scripting languages don't have any sort of defined entry point.  They simply execute the code from the top through the bottom. Some of that code may serve only to define functions or classes without invoking them (like the def average() function in my example).  These parts of the code don't "do" anything (from a user's external perspective) they don't create files, print output, etc. (The effects are supposed to be all internal ... defining things and setting some initial and constant values, for example). The problem with most scripting languages is that any file can either be a script *or* it can be a library.  But it can't be used in both capacities without some extraordinary restrictions on how it's called (magic command line arguments or environment variable settings). In Python when you import a module then the special variable __name__ is set to the name of the module being imported.  (Additionally the Python import statement requires a "name" rather than a string or filename; this is a sort of complicated issue because this name is derived from the filename, or a directory name in the case of Python "packages" ... but suffice it to say that you have to used unquoted literals as package/module names for the import statement). When you run a script as a program then this special variable,  __name__, is give a special, reserved, value '__main__' ... the literal string "main" wrapped in pairs of underscore characters.  (As you may have surmised by now, Python uses this "double underscore" punctuation to signify a number of reserved or special names, for methods and built-in variables). So a line like if __name__ == '__main__': allows one to define functionality in a file which can then be used as a module or library for other Python scripts, and also define some behavior for the script's execution as a standalone program. (Incidentally the one other scripting language that I know of which implements a feature similar is Ruby). Once you defined a working average() function in this file then you'd be able to re-use it in any other script that needed to it.  With proper use every *.py file you create can serve as a module or an executable script.  When a module has no known utility for standalone use, then it's common to use the __main__ block to define a suite of tests, called "unit tests" which can instantiate objects and call functions defined above the __main__ line comparing the results to the programmer's expectations and assert-ing that they are correct). In the next line I import sys ... which is a standard library module that gives us access to certain pre-defined "system" level variables and some utility functions (such as exit()).  In this case I care about argv (argument vector) which is the list of command line arguments passed to my script, and the sys.stderr (the special file descriptor to which one properly writes error messages; usually just a duplicate handle to write to your terminal or command line window). This first if statement is checking to see if you've provided any arguments on your command line when you invoked the program. As mentioned sys.argv is the "argument vector" ... a name that's derived from the historical examples of code using the C programming language where the main() function was provided with an argument count (integer) and a pointer to a series of strings ... called a "vector" by programmers of that time).  Also for historical and practical reasons the first item in this list (vector) is the name of our program.  If you save this sample text of a file named 'foo.py' in your home directory on a typical Unix system then sys.argv[0] will be set to some string like '/home/myname/foo.py'. In this line of code I want to ignore that first argument (at offset zero in my list).  So I'm taking a "slice" of my argument list ... from offset 1 (the second item in the list) through the end. Now we come to a moment of truth, so to speak. In Python the following things are considered to be "true": True (a pre-defined value), any number other than zero, any non-empty string (including strings containing only blank lines and such), any non-empty list, tuple or dictionary, and, by default, any objects other than `False` and `None` In fact it's better and easier to define Python's notion of truth in terms of the specific list of objects and classes which are evaluated as false. It would be more explicit and academically rigorous for my condition to read: if len(sys.argv[1:]) > 0: ... but it's quite common for Python programmers to use Python's notion of "truth" for their condition handling; so it's worth learning early because you'll see such things in lots of code. The not operator, as you might expect, simply negates the boolean value of the expression that follows it.  (There's some odd stuff that you'll learn about later regarding "operator precedence" that you'll need to learn as well.  But not yet. In the next line I'm simply initializing a list of "numbers" with an empty list.  In many tutorials you might see this as something more like numbers = [] ... because the [] is a literal representation of an empty list in Python. I'm using this more verbose form for pedagogical reasons; but I tend to do that more often in my code these days as well.  It can be easier on the eyes when reading lots of source code quickly. The next part of this example is tricky and often not covered in the most basic tutorials.  I'm going to "try" to open and read a file. But what if the file doesn't exist or if I don't have permission to read it?  What if the directory doesn't exist or if the file is on some file server that's not accessible when I'm trying to run my script.  If the open() function fails I don't want to have my program just die.  I want to catch the error and handle it in some way that I can control. That's what try: does.  It introduces a block of code such that I can handle some exceptional situations. If you skip past the next half dozen lines of my example for a moment you'll see the corresponding except EnvironmentError as e: line. As you probably (hopefully) already know Python requires that the indentation of your code conform to its (semantic) block structure.  So all of this code from the import sys to the end of my example are within the if __name__ ... statement's "suite" (or block).  The six lines after that first try: statement are within my exception handling suite and so on. This EnvironmentError is one among many which are pre-defined by Python in a hierarchy of known "exceptions" (errors or other conditions).  In particular this handles a number operating system and possible hardware errors including OSError and IOError.  By catching EnvironmentError I'm able to handle all its children (descendents) including any custom exceptions someone might choose to define as subclasses under EnvironmentError or any of its descendants. The as e: part of that line merely gives me a name (variable) containing details of any actual exception which was caught.  I can do various things with this variable; but all I'm doing is printing its "string representation" in an error message, calling sys.exit() and passing the operating system's notion of the "error number" for whatever exception was raised (e.errno). This is all done if any (catchable) error was encountered while opening the file.  (In older Python code example you may see lines like except SomeError, e instead of the newer as e syntax.  That's another one of those pre-2.6 changes).  You could supply any valid name ... but e is very commonly used by Python programmers for referring to a caught exception. It's also common in Java and some other programming communities. In the next line I'm using yet another unusual feature of Python.  (Did I say this was a "simple" example?  Okay, perhaps I lied just a little.  But bear with me). In old Python code ... and in most programming and scripting languages ... you have to keep track of various resources that you're using in your code, and later you have to remember to release those resources.  For example when you open a file you have to close it at some point. Now it is the case that any decent operating system will automatically close your file when you program exits.  But if you open a lot of files without closing them you can exceed either the operating system's limits or the limits the OS imposed on your user account or your process.  Also your program runs for a very long time (perhaps as a service --- like a web server) then you'll need to be careful to release resources as your program completes its processing on them.  This applies to file handles, but also to things like database transactions, and file locks, network connections and various other things you might learn to use in the future. In the old days you'd have to call .close() on your file objects and various sorts of .release() methods on various other sorts of resources ... and you have to do this even if you encountered some sort of error (exception) while using the resource.  The old way of doing this would look something like: #!/usr/bin/python f = None try:     try:         f = open(somefile, 'r')     except EnvironmentError, e:         emit_error(somefile, e)         sys.exit(e.errno)     # do stuff with the file ... finally:     if f is not None:         f.close()  In order to ensure that the file was closed even if some error occurred anywhere in the process of using it. This is messy and verbose and many Python users over the years discussed cleaner ways of handling such situations.  So about 10 years ago Guido van Rossum (the creator of Python and still the primary decision maker regarding its development ... also know as the "BDFL" or "benevolent dictator for life" drafted a proposal and published it just as anyone in the Python community supposed is to.  That's through a "Python Enhancement Proposal" or "PEP"). In particular that was PEP 343: The "with" Statement which defines the concept, in Python, of a "context manager" protocol. This usage of the word "protocol" may be confusing because we're not talking about networking protocols here.  In this case we're talking about a set of standards for how different objects can interact in Python to implement a set of semantics.  Context management is one set of object protocols in Python.  The "iterator protocol" is another (which I'll barely touch upon later). The key point here is that the line with open(somefile, 'r') as myfile: creates a context in which I can use myfile while ensuring that it will be automatically closed (at the end of my suite or indented block of code). Many Python standard libraries and better quality third party modules will implement the context management protocol in their classes where it's appropriate.  You can read the PEP and look for specific tutorials on how to implement them in your own code as well.  Mostly you don't have to worry about them until you get to using things like databases transactions and threading or multiprocessing locks (mutexes, semaphores, and such). In this call to the `open(..., 'Ur') built-in function I'm using the "read-only" flag, indicating that I won't be modifying the contents of the file (and preventing me from doing so even accidentally when it's been opened that way).  Additionally I using a special feature of Python called "universal line ending mode."  Thats what the U is for. You'd think that there is nothing simpler, in computing, than opening a file, reading the lines from it, and processing them one at a time.  If you only work on Unix or you only work on MS Windows ... and you never work with files that have been touched by some other OS ... then working with text files is pretty easy. However, the world is not so simple.  There are at least four different ways to represent lines in a text file. The traditional Unix model uses a single "newline" character (hexadecimal ASCII character 0x0A, usually represented by the literal '\n' in Python, C, Java and most other programming and scripting languages). The Microsoft MS-DOS and MS-Windows family of operating systems, use pairs of characters (CRLF, carriage return and linefeed; ASCII 0x0D and 0x0A respectively).  (Yes, LF/linefeed is just an alternative abbreviation/name for "newline"). On the very old Macintosh operating systems (before MAC OS X) the text files used single CR (carriage return) characters) ... and you'll probably never encounter any of those in real-world application today but it's an historical note. The other form of line termination, one which you may encounter rather unexpectedly, is the one defined by the UTF-8 encoding of Unicode text. UTF-8 is interesting because it can represent all normal ASCII 7-bit printable characters mostly as themselves. However, sometimes you may encounter some program or system that insists on using the special sequence for Unicode's LS character (U+2028, also known as '\u2028' in a Python string literal, and which encodes into the three byte sequence 0xE280A8 ... or b'\xe2\x80\xa8' as a Python 3 byte literal). This might seem esoteric.  But I've had text silently converted into a UTF-8 encoding when pasting from Outlook on a Mac into a terminal window connected to a Linux system.  This can be insidious because all the rest of the file may look perfectly normal and many editors and file viewers will handle the line feeds transparently. So, the takeaway here is: in Python use the "U" flag when opening text files. It won't hurt on any files that are "normal" for your environment and it'll occasionally save you some hard to debug grief when you're getting files from elsewhere, including even just cutting-and-pasting in some cases. The next line of my example is: for each_line in input_data: ... (the `as input_data on the previous line simply gives my open file a name for me to use within my code, just as as e gave me a name by which I could refer to an exception in the other line I discussed earlier). This line introduces one of the two core types of loop in Python. In Python for loops are far more common than while loops because most of the container data types and classes in Python support the "iteration protocol."  That is they define a way to implicitly loop over their contents. In particular Python allows us to iterate over files line-by-line as I'm doing in this example. Then we have another try: ... exception block, this time I'm trying to convert the contents of each line into a floating point number. I know, from experience, that a failure in that conversion would raise a ValueError so I'm catching that, printing a warning and continuing on the the next line (implicitly). In the common case, where there was no error parsing the line, I'm appending any result to my list of numbers.  I'm also using the .strip() method on each line (string) to ensure that I'm not passing any extraneous line terminator or space characters before or after the number on that line. It turns out that this isn't necessary for the float() built-in function ... but in lots of other cases leaving the line terminator on strings read from files can cause other problems.  So it's here as a reminder.  If you want to strip only the line feeds from the ends of these lines then you'd use each_line.rstrip('\n') and any other leading or trailing whitespace will be preserved (which is often the desired semantics).  (Incidentally the '\n' literal will work even if working with other types of line terminator, when you're using the "universal line ending" mode on the file). That's it. If your program runs past that sys.exit() line after the outer exception handler than you have a list of floating point number which could be passed to average() function as shown on the last line of my example. You can implement that function in literally just a single line of about 32 characters. (Left as an exercise to the reader). That's not necessarily the best way to do this.  In particular it could be inefficient to built a list in memory and pass it around if we had a file containing millions or even billions of numbers.  A decent modern system with a few Gigabytes of RAM can do it ... but it's still slow and inefficient.  Another approach would be to change the suite in my loop and replace numbers.append(...) with a couple of lines to keep track of a running total and the number of file entries (lines) that have been successfully converted into numbers.  This will only consume a few dozen bytes of memory (the internal sizes of one float object and one integer object).  The "state" of my loop would take up only a tiny fraction of the program's memory footprint ... but building a list could consume many hundreds or thousands of times my program's base overhead. As you learn more about programming you'll find that there are "classier" ways to make this program more efficient.  (In particular you could define a class which maintains the running total and count as "attributes" and provides a method to return the current average as often as you like).  But that is also left as an exercise to the student. The main point I'm trying to make with this excessively long posting is that the stuff you have to do around your code can be quite a bit more complicated than the stuff your trying to do with your code. Computing the average of a list of numbers is literally only a single short line of Python code --- if you already have the list.  Getting that list from a text file ... and handling the most common types of errors in that process ... takes about a dozen lines of code involving a lot of concepts that your introductory tutorials gloss over and expect you to learn later. If I didn't care about portability and error handling I could get that list in only a few lines.  For example: #!/usr/bin/python import sys data = open(sys.argv[1], 'Ur') numbers = [float(x) for x in data] data.close() # ... or: with open(sys.argv[1], 'Ur') as data:     numbers = [float(x) for x in data] But that will die with an ugly stack trace if any line can't be converted to a float (including any blank line in the file) or if the file can't be opened, etc. To those who are voting your question down, and dismissing it, I have this to say: programming is hard enough to learn and most tutorials and classes only teach a rather sloppy set of what a programmer will eventually need to know in order to handle read-world issues in a reasonably robust way. Sometimes it's worth it to dive into the complexities and give an excruciating explanation of all those ugly details that the simple primers gloss over and the more advanced materials assume you've already learned. Perhaps an hour or two reading this will help some budding students understand how to do all that other fussy stuff that gets data into their program so they can focus on the parts of computer science that their trying to learn and, maybe, just maybe, some of the naysayers might read through this and remember how much crap we had to learn before we could do useful programming work and how much of those details we don't even think about any more. 