Why was Lisp the language of choice for AI research?
Asking why it was "the language of choice" I think starts off with a false premise. McCarthy formulated the research area of artificial intelligence before there was a machine on which to try it out. A lot of what computers became from the 1970s into the 1980s came out of his early work. McCarthy had seen a prior language that stored its computable elements in linked lists. He liked this idea, since he wanted exploration of how computers could establish relationships between pieces of information, and process both the information and relationships as part the discipline. My understanding is he developed the Lisp formalism from Alonzo Church's lambda calculus. At first it was just a theoretical concept. He didn't write the first implementation. One of his students did that from his design, and used the same concept of the prior language McCarthy had seen, of storing computable elements in a linked list structure. In addition, he wanted a machine that was not only interactive, but one on which people could collaborate. Batch processing would not do, but for the most part that's all MIT had. McCarthy didn't think it would be possible to conduct AI research punching Lisp code into punch cards, and then waiting hours or days for results. He wanted his students to try out ideas when they thought of them, and see results quickly. He wanted it to be an interaction between the human mind, and the "mind" of the computer. So he created his own concept of time sharing. It was inspired by the idea that when MIT's mainframes weren't processing data they were just sitting idle. Computer time was very expensive, so he thought, "Why not use the idle time to run interactive computations, and allow me and my students to interact on ideas?" So he developed a way to modify a batch processing mainframe to do time sharing. Rather than focusing only on a single task until completion, he made the computer look for times when it was idle. When it was, it would quickly swap session information (processor registers, and possibly some memory) to a storage device, and retrieve the same information for another session, give that session some computer time, wait for a pause, then swap, and so forth. The idea was the computer would be fast enough such that each person would more or less feel like they had the computer all to themselves, but it would allow multiple people to interact with the computer at the same time. He gave a public demo of his first time-sharing system at MIT in 1961, on the subject of "utility computing." McCarthy laid out a vision of large, centralized computers being dispersed in society, which would allow individuals and businesses to find uses for computing. He used his system as an example. A teletype was hooked up to his system, and the operating system was a Lisp runtime. This is where the American concept of the command line came from--a Lisp REPL! I think it's more accurate to say that the computing model of choice for AI at the time was an interactive system that stored and executed symbolic computable elements inside a data structure, and produced results as quickly as possible. The particular implementation of that idea that McCarthy, hence the field of AI, used just so happened to be Lisp. The field of AI held on to Lisp for a long time, practically keeping it in the "cage" of one discipline. I remember when I took CS in the late 1980s and early 90s, my professors called Lisp a "research language" that was only used in AI. It was stereotyped. It's only been slowly in the last 20 years that people have recognized Lisp's utility for other purposes. Updated 18 Sep 2014 â€¢ View Upvotes