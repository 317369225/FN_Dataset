Why was Lisp the language of choice for AI research?
(EDIT : 3/31/2015)   I don't see it mentioned elsewhere, but Alanzo Church devised the Lambda-Calculus to express algorithms in the 1950's.  He was working on theorems regarding computability (see Church-Turing Theorem).   Lisp is a very close implementation of the Lambda Calculus. Some languages, like C, are good for doing a huge collection of simple things very fast.   So a game, or an operating system like UNIX come out well in C. LISP, on the other hand, abandons speed and tight interaction with the hardware.   LISP is focused on solving very deep algorithmic problems.    So LISP trades speed and hardware access for : Minimal syntax : You can write the LISP syntax on a match book cover.   The language is really trying to get out of your way. Ease of analysis : The lack of side effects means that a LISP function serves a single, clear purpose : Take in some stuff - don't change it (immutability), pass back some new stuff - and do nothing else (no side effects.)   It's thus easier to be confident about a function's correctness (and to prove theorems about it.) Parallel friendliness.  Sure - LISP can be slow - and AI problems can be computationally intensive (think chess.)   However, the two features mentioned above - immutability and lack of side effects makes LISP easier to parallelize on supercomputers.   So while LISP may be 10x slower, the problems it attacks are so hard that a 100,000x boost is required.     Hardware can achieve this, exploiting LISP's parallel-friendly design. No distinction between data and code : Code is data and data is code.   So LISP can write LISP, and often does. There is also an historical reason : LISP is MIT's language.   The very bricks of MIT are coded in LISP.   MIT's been the center of AI research since the late 60's. (I know, I know, Stanford, Caltech, Harvard might object to that last :) ) Updated 1 Apr • View Upvotes