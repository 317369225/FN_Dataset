What is the difference between a compiler and an interpreter?
Originally Answered: What is the difference between a compiler and the interpreter?The answer used to be simple until, imitating Microsfot, Sun decided to muddy the waters by calling their optimizing interpreter a "Hot Spot Compiler":( So back in the good old days, it was simple: a compiler reads source code, converting it into machine code. A separate program then loads the machine code and executes it. Then linkers came along, and the picture changed a little bit: compilers no longer produced pure machine code output, they used an intermediate format that allowed the linker to replace placeholders with real addresses during or just before the loading process. Interpreters, OTOH, immediately convert pieces of source code into short sequences of machine code and execute them immediately. Or, more commonly, they have a "virutal machine" that uses the language primitives as its "machine code". Java is an example of this. Yet it actually combines both, doing a compile step to make a class file and then interpreting that on a virtual machine. Similarly, Pascal was also an example of this, (I say 'was' because later they came out with compiled Pascal), converting source code into pcode and then interpreting that. BASIC originally was always interpreted; even a line as short as 100 LET A = 0 would immediately cause machine code to be executed to allocate a variable A and put a zero there. So what does all this mean to the user of these languages? The first thing that comes to my mind is that languages that have separate compilation and execution, such as Java and C++, allow for type checking at compile time, which helps you catch errors earlier rather than later. Catcthing them early saves everybody time and money. Java will even let you do some type checking at compile time and some at runtime. In fact, if you are using Generics, this choice is forced on you because of "type erasure";) 