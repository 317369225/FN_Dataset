Why is type checking important in programming languages and how should one choose between dynamically and statically typed languages?I asked this question because , I don't know how type checking helps in production environment , because what dynamically typed language like python can do , can also be done by statically typed language like java. I have heard people talking about various trade offs but I don't know when to use which one. What will be the scenario in which one will be favored over another ?.
Type checking is useful because you can eliminate certain classes of errors before you run the program. For example, say you have a (dumb) function add1, that takes an int and returns an int that is one larger. Java style typechecking will guarantee that this function is only operating on ints. So before you run the program, you will catch any case where you call add1 on the wrong type, e.g. add1("5") will cause a compiler error. Types can also help the compiler optimize your code, by using machine instructions specific to the data type you are operating on. The more sophisticated your type system, the more work you will have to do to convince the compiler that your code is "correct," in the sense that it doesn't contain any type errors. C has a very simple type system that allows programmers to cast values (escape the type system) more or less arbitrarily. So it is easier to get a C program to typecheck, but the guarantees that it provides are not as strong. At the other end of the spectrum, there are dependently typed languages. In a language like this, you could declare the type of add1 like this: add1 : (n : Integer) -> (n + 1) Edit (more on dependent types): as  has been pointed out in the comments, the above type declaration is not  correct. I didn't want to go into too much detail, but I shouldn't have  sacrificed correctness for simplicity. As Matthew said, you cannot use values as types. What actually happens is that you index types by values, like this: Inductive my_nat : (nat -> Set) := | my_nat0 : my_nat 0 | my_natS : forall n, my_nat n. This is a definition of a type that we can use as a wrapper for the natural numbers. Then we can define add1 like this: Definition add1 (n : nat) (m : my_nat n) : (my_nat (n + 1)) := match m with | my_nat0 => my_natS 1 | my_natS n' => my_natS (n' + 1) end. Another (probably more obvious) way to write the type of add1 is like this: add1      : forall n : nat, my_nat n -> my_nat (n + 1) That is, the type of add1 actually guarantees that the return type is indexed by a natural number one larger than that of the input. And if the program type checks, you know that add1 is doing exactly what it is supposed to. But it can be a very big chore to convince the compiler that your code is correct (although in the case of the above Coq code, it is not). This is kind of a goofy example since the second constructor for my_nat will also accept 0, but it serves to make the point that I was going for. /Edit Untyped languages (e.g. python) take this tradeoff to the other extreme. You do not have to do anything to convince the compiler that your code is correct. This can save programmers quite a bit of time. But you will not be able to catch many errors until you run the program. If you're trying to decide on one or the other, that's a matter of personal preference. I don't know that there's a right answer. However, the common consensus is that type systems are useful for large software systems that need to be maintained for a long time, and for performance-critical applications. On the flip side, they tend to get in the way for short, IO-bound programs (also known as "scripts"). Updated 1 Dec 2013 • View Upvotes