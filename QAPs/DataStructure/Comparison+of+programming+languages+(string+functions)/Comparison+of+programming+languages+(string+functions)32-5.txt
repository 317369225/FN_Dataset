What is the difference between a compiler and an interpreter?
A real, physical processor has a very simple view of the world: I have a bunch of memory. It consists of a series of identical, numbered cells, each holding a number between 0 and 255. I have a program counter that tells me which cell contains the next instruction in the code I'm executing. Each time my internal clock ticks, I'm going to fetch an instruction from that cell and some number of cells after it. Each instruction consists of a number representing one of the simple operations I know how to do, followed by some other numbers explaining which pieces of data I should do it on. The operation might tell me to perform some math, or change some cells of memory, or change my program counter, or perhaps even do all three. Once I finish an instruction, I'll change my program counter to skip past the completed one, and then start on the next.This is relatively easy to implement in silicon, but it turns out that it's really hard for humans to write code for. This simple world where everything is in a numbered cell just involves too many finicky details for people to handle. They make mistakes: use the wrong instruction number, lose track of what's in a particular cell, try to use the same memory cell for two different things, try to execute cells that actually contain data or calculate with cells that actually contain code, all sorts of problems. And when something's wrong, you usually don't get an error—the processor just obliviously does the wrong thing, like a two-year-old who doesn't know better than to draw on the walls. So we invented programming languages. In a programming language, we can call things by name, not by cell number. We can make it clear what sort of thing each name is, and if we try to do an operation that doesn't make sense, the computer will stop us. We can organize our code into coherent, structured blocks that make more sense than the chaotic jumping around it looks like from the processor's point of view. But the processor can't actually run code like that—it can only run simple numeric instructions in cells. So how to do you get a textual program to run on a processor that doesn't understand it? One approach is to translate the programmer's textual code into the processor's numeric code. This is what a compiler does. It's desperately tricky, but doable, particularly for languages with relatively simple behavior. The other approach is to take advantage of a bit of fundamental computer science. You may have heard the name Alan Turing. He was an early computer researcher who, when not cracking Nazi codes to make sure the Allies would win World War II, managed to prove that any "Turing machine"—that is, any reasonably capable computer—could simulate any other Turing machine, no matter how differently the two were designed. All it takes is the right program. So if you can make one processor simulate another processor, why not design an imaginary processor that's perfect for your programming language? Maybe your processor calls memory by name, not numeric address. Maybe it knows the kind of data in each piece of memory. Maybe it organizes code with structured blocks, not chaotic jumping. Maybe it does other smart things, too: it might automatically delete things from memory that aren't being used anymore. It might convert text to numbers and numbers to text effortlessly. It might perform thorough safety checks to ensure the programmer doesn't make any dangerous mistakes. It might allow its memory cells to grow if they need to store more data than would normally fit. It might build in ways to organize and analyze data that would require lots of programming effort on a physical processor. The sky's the limit, and you can have it all on your simple physical processor: just write a program that simulates the ideal processor for your language. This is what an interpreter does. 