Why was Lisp the language of choice for AI research?
Much of Artificial Intelligence work requires speculative and experimental programming: quickly prototyping an algorithm, and evaluating with a down sampled data set before building a high performance implementation. At the time, Lisp was unique in providing a REPL (read-eval-print loop), data structure literals (even if for only a single data structure, the linked list), Garbage Collection, higher order functions, and the like. Some of the first IDEs existed for Lisp (e.g., the environments on Lisp machines). While Lisp was widely decried as slow in the previous decades, most modern Common Lisp implementations can be up to an order of magnitude faster than other dynamically typed programming languages (third to systems languages such as C and C++, and second to statically typed garbage collected languages such as Java and OCaml (programming language)). However, it did set the precedent that there's a legitimate role for languages which trade off performance and memory usage in favour of developer/researcher productivity. These days, many artificial intelligence and Machine Learning developers and researchers use environments such as MATLAB, R, and languages such as Python for speculative development. These tools have absorbed and popularized much of what Lisp pioneered. It should be noted that aside from higher order functions and Closures, if one looks at Lisp code from the 1980s and earlier, very little actual Functional Programming is to be found: loop/do constructs are used pervasively, mutability of cons cells is exploited all the time. 