Does the following implementation for finding the longest common substring within two strings work?
Yes, this algorithm works, but it is terrible. It is in every way worse than the naïve algorithm. You say that putting s2 into the hash map avoids having to traverse s2, but that is not true! You had to traverse s2 to put all the elements in the hash map! The naïve algorithm also traverses s2 exactly one time (discounting the s1 loop, which both algorithms have), so it is the same, except that now you've added a hash map. Initializing the hash map alone is going to take many times longer than just doing the simple algorithm (in C++). You could initialize the hash map with every possible sub-string of s2. That would make the lookup time for substrings O(1), but it unfortunately means that your hash map initialization time is O(n^2). It would take a very weird use case for that to make sense. The simple thing to do is to loop through s2 from [0..s2.size()-s1.size()]. Check whether s1 is a substring starting at each character, making sure to give up the moment the first mismatch is found. Simple, clean, and faster than your hash algorithm. This is the naïve variant, and works very well for all but very toxic cases. A more sophisticated algorithm would try and avoid those toxic cases where s1 is long and very repetitive, and where s2 contains a lot of almost-matches. Working well in this situation requires something much more sophisticated*, but it's so much work that even the standard library std::string::find function doesn't bother. * I would consider running something like LZW compression on the strings and then implementing the algorithm on the compressed strings. It's so hard to imagine a non-stupid use case, though, that I doubt anyone has ever bothered. 