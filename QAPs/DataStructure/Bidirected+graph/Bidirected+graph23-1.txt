How does the architecture of a network shape its function?
For feedforward networks the first thing that architecture, or topology, fixes is the number of inputs and outputs of a network. That restricts the number of functions that a network can implement. Another way that architecture fixes functions in feedforward networks is throught Cybenko's theorem. If you don't have a minimum number of neurons and layers you can't aproximate some functions. I also think that the question is too wide to answer anything more precise. For example, if a feedforward network don't have feedback, it can be used as NARX model of a system. 