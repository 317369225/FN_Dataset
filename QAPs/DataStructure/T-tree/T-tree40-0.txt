How are Haskell data structures represented so that they don't need to be copied every time I make a small change to them?
When you think Haskell you should not think in terms of mutable data structures. You should think in terms of data values. These effectively are immutable and persistent data structures. Only when you dig deep into a specific Haskell implementation you will eventually find that some of those values are represented internally in terms of mutable data structures. You may want to google "persistent data structures" for a general understanding of the concept of how this works. I'll answer your question more directly in terms of how they are represented in a Haskell implementation. The internal representation of data is, for the most part, as boxed values. Each boxed value is in fact a small block heap allocated memory and therefore it has a unique address which is what can be used to refer to that value. This memory contains a tag and zero or more references (addresses) to other boxed values. (note: actually not all data is boxed, so a boxed value in fact also contains zero or more unboxed data words). Let's look at your examples. When you mention records it is unclear if you mean algebraic data types in general or if you refer to Haskell record syntax. In case you refer to the latter, you should understand that it's just mere syntactic sugar. There actually is no such a thing as a record in Haskell: once you desugar your syntax it becomes just code that manipulates ordinary data types. You therefore cannot really do something like "update a single field". What you do is really creating a new value. The fields are just components of the data type, which are themselves values, and therefore are stored as references. Since these are all boxed you are both "copying" the "structure" and, at the same time, "not copying" the actual values. You are copying the references. You mention lists. Lists in Haskell enjoy special status and there are several syntactic elements that make working with lists more syntactically pleasant, but under the hood lists are just an ordinary polymorphic type with two constructors. One constructor has no arguments and represents the empty list (it's known as Nil in functional jargon), the other has two arguments, an element and a list, and represents non empty lists (it's known as Cons in functional jargon). Given a list and a new element you can trivially create a list with the element prepended to the given list: your new list representation is the boxed representation of a list using the Cons constructor. The memory representing the box has three words: a tag that witnesses the fact that you are using the Cons constructor, a reference (pointer) to the element and a reference (pointer) to the original list. One important thing you should remember, however, is that the above is not what happens when you think it does. Haskell types are in fact lifted types and evaluation is lazy. Therefore the actual representation of the new list that, probably, is generated is just an unevaluated closure, known as a thunk. This is itself represented as a box (internally it's just like any other value) which has an appropriate tag and references to a function and to its arguments. Only when you actually use that list, the think is forced (aka evaluated) and it's representation is overwritten with the actual representation of the list that I described above. Furthermore Haskell employs global cross module inlining and optimizations. A lot of data is in fact never built and never allocated at all. Many lists values (emphasis on value) actually represent loops, not data structures (emphasis on structure), and are therefore never represented as data: they become the corresponding loop code. A lot of data is only used once and is never allocated on the heap, it just stays in registers. Things are therefore not at all what you think they are, once you dig down to the gory low level details. There are several references you can read that explains things with much more detail than I did here. For the GHC haskell compiler you can read https://ghc.haskell.org/trac/ghc... but I warn you: it has so many details that you may get lost. It's probably much more valuable for you to study the graph reduction evaluation model as implemented by the spineless tagless g-machine, which is (in a more modern form) what GHC does. The old paper is Implementing Lazy Functional Languages on Stock Hardware: The Spineless Tagless G-machine (the link to the actual paper as a zipped postscript is on the right). It describes not only the evaluation engine but also what is needed in the data representation. For better understanding on how persistent data can have very good performance you may want to read Chris Okasaki's "Purely Functional Data Structures". 