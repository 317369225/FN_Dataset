Why do computers use base-2 instead of base-10?Decimal computers were once very commonplace, but why aren't they anymore? *Speaking as something with next to no knowledge of computer science.*
There is a trade-off between circuit complexity and efficiency. In older designs with discrete states: (detents on a mechanical system; electronic valves (tubes) with multiple anodes (triodes, pentodes - and decodes  then it made sense to use decimal. If the cost per unit were higher then the density of decimal (or hex!) might favor that. But the simplicity of binary and "transistors are simply switches" wins out. Some of the other answers are mistaken:  BCD is still base 2 (Binary coded Decimal - "binary" tells you it is base 2) There have indeed been computers that use Base 10: Babbage and WITCH are examples (see below) There have also been ones that use Base 3 (+,0,-) In modern electrobics it is still common to encode signals at multiple levels: although binary is used in logic, flash can use Base 4 or Base 8 (multi-level storege), and communications relies on multi-state digital - not just binary. But in electronics it is not that "we store bits as one or zero"  - it is cleverer than that. We can say "zero" is any voltage less than X, and "one" is any voltage more than X.    That makes the circuity much easier because we do not need to worry about analog precision. And we can use a comparator or saturing transistor clean things up. In a decemal system you would need much more accuracy (voltages 0 = 0 to X/10, 1= x/10 to 2X/10, etc); that requires good references, maybe temperature compensation, and more circuity. So  for binary the components can be simpler, the circuitry easier - and that makes it cheaper. Trinary (+,0, -) would be almost as simple and has been used. Ternary computer There is an interesting contrast / counter-example with digital communications. Historically this used binary - but now often uses Base 64 or Base 256. Think Morse code, traditional T1 lines or 2200bps modems. Binary on/off, high/low. But now we want higher data rates (more efficiency) we use multi-state signalling, multi-state levels. We go from binary to 4 levels to 16, 64 or even 256.  In this case the "QAM mapper" and "slicer" will look for signal not between 0 and X/10 but 0 and X/64, between X/64 and 2X/65 etc The increase in complexity is justified by the improved efficiency. But in computers that efficiency is not needed, so the simplicity of binary wins. The world's oldest working digital computer WITCH from 1951 is operational in UK. It uses decimal logic (dekade vacuum tubes with ten states). Restoring the Witch computer << BBC video Rebuilding the oldest working computer in the world  <<Quite a technical description Updated 30 Apr • View Upvotes