What are some technological things that even computer programmers do wrong?I will get things started. Kilobytes (KB), Megabytes (MB), Gigabytes (GB) are used incorrectly. These are human (base-10) numbers, so each represents 1,000. Computers use binary (base-2), so each should represent 1,024. The proper notation is Kibibytes (KiB), Mebibytes (MiB), Gibibytes (GiB). The same applies for bits.
You shouldn't say programmers can't make the difference between = and == and === because this statement will only be understood by the programmers who understand the difference ;). You should add the normal definition (equality, identity, congruence, stuff like that). So yes, because a large class of "programmers" are only coders (that is people who write code without thoroughly understanding what they are typing), many of them can't tell the different between the operators denoting the fact that two pieces of information represent the same thing (that is equality), and the fact that they are stored at the same memory address (more or less) - that is identity. Sometimes things can get even messier with different pieces of in-memory data being different, stored in different memory areas, but denoting the same persisted (database or filesystem stored) data. But this is the class of reasons there are so few really good programmers out there. 