How can I compute the average of a large array of integers without running into overflow?
You can switch to floating point, but you are likely to lose precision of the result. (X1 + X2 + ... + Xn) / n is equivalent to: X1 / n + X2 / n + ... + Xn / n but in programming this works only if each Xi is typecast to, say, double precision before division. The lost digits in the result will depend on the number of elements and the data array itself. From a practical point of view though, even an approximate result is sometimes better than no result. P.S. beware that the running average suggested by others is not average. It's just not the same thing. 