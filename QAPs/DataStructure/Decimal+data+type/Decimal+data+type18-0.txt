How is the floating point number stored in a 32-bit microcontroller memory?
I assume that you are asking about floating pointer numbers are stored in Microcontroller memory when using C language.           In C, there are 2 major data types.                        1. Integer                        2. Float       I had already discussed about Integer data type in the answer to the following question. What are the things you must learn in C?     Now lets us try to understand about float.                In float data type there are 3 types.                            1. Single float (float)                            2. Double float (double)                            3. Long Double float. (long double)               This data type is called float, because the decimal point will be moving (floating). The other data type is called fixed point, because the decimal point does not move. C does not support fixed point               let us take a number 15.875 this can be converted to binary as follows               15  =  8 + 4 + 2 + 1 =  1111            .875  = 0.5 + 0.25 + 0.125 = 2^-1 + 2 ^ -2 + 2^-3                So the binary representation of 15.875 can be 1111.111 which can be represented as 01111.111. The number is stored in the same way in memory. I am not going in depth. It may confuse you. Now let us see how the float is represented.               First let us see how much space is allocated for each type of float.                        1. float - 4 bytes - 32 bits                        2. double - 8 bytes - 64 bits                        3. long double - 10 bytes - 80 bits                First let us discuss about the float (single float)                              float number;                              number = 15.875.                Now let us see how this assignment statement works.                RHS - 15.975 = 1111.111                                        = 1.111111 x 2^3                                        (The decimal point is moved left 3 position)                          Now as per the standard 1. will be removed.                     111111 is called mantissa (significand)                             11(3) is called exponent                         Now let us see how to construct a 32 bit binary number using these values.       1 bit represent sign bit       8 bits represents exponent       23 bits represents mantissa      In this case, the number is positive, so sign bit is 0      In this case, the exponent is 3 , add 127 (exponent bias) we get 130                                                          = 10000010      In this case, the mantissa = 11111100000000000000000      so the 32 bit binary value of 15.875 is      0 10000010 11111100000000000000000 =  01000001 01111110 00000000 00000000  - 4 bytes stored in memory.     I had tried to explain with my ability. You can refer google for IEEE 754 standard.    In the case of double         1 bit represent sign bit     11 bits represent exponent (exponent bias is 1023)     52 bits represent mantissa.    In the case of long double       1 bit represent sign bit     15 bits represent exponent (exponent bias is 16383)     64 bits represent mantissa.     You can  check here, your conversions      IEEE 754 Converter 