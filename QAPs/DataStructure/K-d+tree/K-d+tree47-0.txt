Can someone provide side by side comparisons of a few operations done in functional programming vs imperative programming?
The term functional programming hardly means anything, so I’m just going to compare Haskell and Python. Many of these features are available one way or another in other languages with some ML heritage (such as SML, O’Caml, Erlang, F#, Scala) but most of what I like about Haskell isn’t as easy to do with the languages with LISP heritage (such as Common LISP, Clojure, Scheme, Racket). TL;DR - If Python is "executable pseudo-code" then Haskell is "executable pseudo-math" One thing that Haskell is particularly good at is embedded domain specific languages. A prevalent use case for Haskell is parsers and compilers, so I whipped up a simple example that I can compare to Python. Here's a subset of Python's fnmatch module, which translates a shell glob pattern to a regular expression which is then compiled to test if the pattern matches or not: import re__all__ = ['fnmatchcase', 'compile_pattern', 'translate']def compile_pattern(pat):    return re.compile(pat).matchdef fnmatchcase(name, pat):    """Test whether FILENAME matches PATTERN, including case.    This is a version of fnmatch() which doesn't case-normalize    its arguments.    """    match = compile_pattern(translate(pat))    return match(name) is not Nonedef translate(pat):    """Translate a shell PATTERN to a regular expression.    There is no way to quote meta-characters.    """    i, n = 0, len(pat)    res = ''    while i < n:        c = pat[i]        i = i+1        if c == '*':            res = res + '.*'        elif c == '?':            res = res + '.'        elif c == '[':            j = i            if j < n and pat[j] == '!':                j = j+1            if j < n and pat[j] == ']':                j = j+1            while j < n and pat[j] != ']':                j = j+1            if j >= n:                res = res + '\\['            else:                stuff = pat[i:j].replace('\\','\\\\')                i = j+1                if stuff[0] == '!':                    stuff = '^' + stuff[1:]                elif stuff[0] == '^':                    stuff = '\\' + stuff                res = '%s[%s]' % (res, stuff)        else:            res = res + re.escape(c)    return res + '\Z(?ms)' Here’s a similar algorithm in Haskell using attoparsec, which is a fast parser combinator library that ships with Haskell Platform (the equivalent to Python's standard library). In approximately the same amount of code I have implemented a tokenizer for the shell pattern language, and a compiler that creates a parser from those tokens. No need for regular expressions here: {-# LANGUAGE OverloadedStrings #-}module FNMatch (tokenize, compile, fnmatchcase) whereimport Data.Text (Text, unpack, singleton)import Control.Applicativeimport Data.Attoparsec.Textdata FNToken = FNString Text             | FNAny             | FNStar             | FNClass Bool String             deriving (Show)-- | Match a pattern against the given Text, including case.---- > fnmatchcase "FN*.hs" "FNMatch.hs"fnmatchcase :: Text -> Text -> Boolfnmatchcase = compile . tokenize-- | Tokenize a shell PATTERN for use with compile.---- There is no way to quote meta-characters.---- > tokenize "FN*.hs"tokenize :: Text -> [FNToken]tokenize = either error id . parseOnly p  where    p = many $ choice [fnstring, fnany, fnstar, fnclass, fnfallback]    fnstring  = FNString <$> takeWhile1 (notInClass "*?[")    fnany     = pure FNAny <* char '?'    fnstar    = pure FNStar <* char '*'    fnclass   = do      char '['      negateClass <- option False (pure True <* char '!')      c <- anyChar      chars <- unpack <$> takeTill (==']')      char ']'      pure $ FNClass negateClass (c : chars)    fnfallback = FNString . singleton <$> char '['-- | Compile @tokens@ to a function that matches the pattern-- on the given Text.---- > compile (tokenize "FN*.hs") "FNMatch.hs"compile :: [FNToken] -> Text -> Boolcompile tokens = either (const False) (const True) . parseOnly p  where    p = foldr go endOfInput tokens    go t next = case t of      FNString s  -> s .*> next      FNAny       -> anyChar *> next      FNStar      -> star      FNClass n s -> skip $ (if n then inClass else notInClass) s      where        star = next <|> anyChar *> star Yes, the above code has a handful of strange operators and it is using a library that you'd have to learn in order to truly understand what's going on, but the nice thing about Haskell is that for various reasons the compiler is able to give you these abstractions at very little cost. In Python, generally speaking, the more abstractions you pile on the slower it goes. In Haskell the abstractions can often be undone by the compiler and libraries can even provide rules for the compiler to do their own domain specific optimizations. Lazy (or non-strict) functional programming languages such as Haskell make it easier to re-use code. For example, if you want to select the smallest k elements in a list you can use a very straightforward implementation and still get linear time performance: Haskell: import Data.List (sort)smallestN :: Ord a => Int -> [a] -> [a]smallestN k = take k . sort In a language like Python, you can easily get the minimum of a list, but you're going to need another algorithm entirely in order to efficient implement smallestN. In this particular case, the heapq module implements this functionality: Python: from heapq import nsmallest You could say that the Python version is easier since the functionality already exists in the standard library, but you have to know it's there. Haskell tends to have a small interface with functions that compose well together, so there are fewer things to learn. Haskell's non-strict evaluation allows you to simply skip work that doesn't need to be done, so you can often write a general implementation (like sort) and there's very little advantage to writing special-case versions of the algorithms for performance. Another neat thing about lazy evaluation is that it makes functionality like Python’s generators redundant, because you can express control flow with data structures instead. This avoids the explosion of functions and syntax that you get in Python where you have list and iterable duals all over the place (list comprehensions/generator comprehensions, list methods/the itertools module, functions/generator functions). You just use lists, and this also frees you from needing functionality like itertools.tee because there are no side-effects, if you want to make a “copy” of the current state, you just keep a reference to that variable. Python: def ifibs():    a, b = 0, 1    while True:        yield a        a, b = b, a + b Haskell: fibs :: [Int]fibs = 0 : 1 : zipWith (+) fibs (tail fibs) I also find that implementing data structures is a lot cleaner in Haskell than in Python, due to pattern matching and abstract data types. Here's a k-d tree implementation in Python (from Wikipedia) that I've added a member search function to: from collections import namedtuplefrom operator import itemgetterfrom pprint import pformatclass Node(namedtuple('Node', 'location left_child right_child')):    def __repr__(self):        return pformat(tuple(self))def kdtree(point_list, depth=0):    try:        k = len(point_list[0]) # assumes all points have the same dimension    except IndexError as e: # if not point_list:        return None    # Select axis based on depth so that axis cycles through all valid values    axis = depth % k    # Sort point list and choose median as pivot element    point_list.sort(key=itemgetter(axis))    median = len(point_list) // 2 # choose median    # Create node and construct subtrees    return Node(        location=point_list[median],        left_child=kdtree(point_list[:median], depth + 1),        right_child=kdtree(point_list[median + 1:], depth + 1)    )def kdmember(tree, point):    depth = 0    k = len(point)    while tree is not None:        axis = depth % k        pivot = cmp(point[axis], tree.location[axis])        if pivot == 0:            return True        elif pivot < 0:            tree = tree.left_child        else:            tree = tree.right_child        depth = depth + 1    return Falsedef main():    """Example usage"""    point_list = [(2,3), (5,4), (9,6), (4,7), (8,1), (7,2)]    tree = kdtree(point_list)    print(tree)if __name__ == '__main__':    main() I find the Haskell equivalent to be much more elegant, the pattern matching in kdMember is particularly nice: module KDTree whereimport Data.List (sortBy)import Data.Ord (comparing)type Point = (Int, Int)data KDTree = KDTree { kdLocation :: Point                     , kdLeft     :: Maybe KDTree                     , kdRight    :: Maybe KDTree                     }            deriving (Show)-- Axis selector based on depth so that axis cycles through all valid valuesallAxes :: [Point -> Int]allAxes = cycle [fst, snd]-- Type system guarantees that all points have the same dimensionkdtree :: [Point] -> Maybe KDTreekdtree allPoints = go allAxes (length allPoints) allPoints  where    go _ 0 _ = Nothing    go (axis:axes) n ps =      -- Create node and construct subtrees      Just $ KDTree p (go axes ln ls) (go axes rn rs)      where        ln = n `div` 2        rn = n - ln - 1        -- Sort point list and choose median as pivot element        (ls, (p:rs)) = splitAt ln $ sortBy (comparing axis) pskdMember :: Point -> Maybe KDTree -> BoolkdMember p = go allAxes  where    go (axis:axes) (Just t) = case comparing axis p (kdLocation t) of      EQ -> True      LT -> go axes (kdLeft t)      GT -> go axes (kdRight t)main :: IO ()-- | Example usagemain = print $ kdtree point_list  where    point_list = [(2,3), (5,4), (9,6), (4,7), (8,1), (7,2)] The one thing that the Python code can do that the Haskell code does not is support arbitrary dimensionality with the points. This could be done with just a few more lines in Haskell by defining a typeclass to support that use case (to parameterize allAxes). There's a few other domains where Haskell has some serious advantages over Python and other imperative languages, such as parallelism and concurrency, but this answer is already way too long so I'll have to save that for another time :) Haskell very successfully avoids "callback hell" and scales very well to multiple cores for both concurrent and parallel operations. Updated 57w ago • View Upvotes