How can you build a data structure on an array that returns kth order statistics on subarrays in logarithmic time?
It's possible to solve this problem online with [math]O(n \log n)[/math] pre-processing time and [math]O(\log n)[/math] per query, and [math]O(n)[/math] space. [1] I will describe an easier version with [math]O(n \log n)[/math] space. # Given an array A, return the Kth smallest value in the range [L, R]Query(A, L, R, K):     if |A| == 1 return A[0]     Split the array A in 2 halves around the median         median = FindMedian(A)         A_low = array (v in A : v <= median)         A_high = array (v in A : v > median)         Associate each value with its position in the original array     p = # of values in A_low whose position is in [L, R]      if K <= p          return Query(A_low, L, R, K)     else                   return Query(A_high, L, R, K-p) Putting it this way, it is similar to the normal Kth order statistic. The way we split the array has nothing to do with the queries, so we can compute the splits just once and save it for all queries. There are [math]O(\log n)[/math] recursion levels each of which with [math]O(n)[/math] work in building arrays A_low and A_high, totaling [math]O(n \log n)[/math] time and space. Value [math]p[/math] can be computed with binary search, (# values up to R) - (# values up to L-1), but this would yield [math]O(\log^2 n)[/math] time per query. We can use Fractional Cascading here as each search in a query is done in a sublist of the previous and we are always searching for the same L and R. This allow us to search in [math]O(\log n)[/math] total time per query. Thus, each query is answered in [math]O(\log n)[/math] time for a total of [math]O(n \log n + q \log n)[/math] time and [math]O(n \log n)[/math] space due to storing arrays A_low and A_high. A very crude implementation assuming distinct values and without fractional cascading follows: struct Record {  vector<int> values, indices;  Record* low;  Record* high;  Record() : low(NULL), high(NULL) { }};int FindMedian(const vector<int>& v) {  vector<int> vec = v;  int mid = (vec.size()-1)/2;  nth_element(vec.begin(), vec.begin()+mid, vec.end());  return vec[mid];}int Query(Record& A, int L, int R, int k) {  if (A.values.size() == 1)    return A.values[0];  if (!A.low) {    int median = FindMedian(A.values);    A.low = new Record();    A.high = new Record();    for (size_t i = 0; i < A.values.size(); i++)      if (A.values[i] <= median) {        A.low->values.push_back(A.values[i]);        A.low->indices.push_back(A.indices[i]);      } else {        A.high->values.push_back(A.values[i]);        A.high->indices.push_back(A.indices[i]);      }  }  int left = lower_bound(A.low->indices.begin(), A.low->indices.end(), L) - A.low->indices.begin();  int right = upper_bound(A.low->indices.begin(), A.low->indices.end(), R) - A.low->indices.begin();  int m = right - left;  if (k <= m)    return Query(*A.low, L, R, k);  else    return Query(*A.high, L, R, k-m);} [1] "Towards Optimal Range Medians" on arxiv.org 