What is the point of doing machine learning, when you have something so robust as the nearest neighbour algorithm?What better justification/support/evidence can you give about your inference than saying there is(are) a point(s) already in the (indexed)dataset which is really close to your query point.
kNN IS machine learning. In many cases, it is competitive against or superior to other methods. I know some RecSys competitions were won using kNN. It is a super-effective classification tool if the number of examples per class is small. If you have 1-2 examples per class and thousands of classes, you cannot train any meaningful classifier. Yet, I saw examples where kNN could give you 80-90% accuracy on such a data set. The curse of dimensionality does exist, but, in practice, it is not as bad as it seems. First, hardly any data set is truly (i.e., intrinsically) high-dimensional. Second, sequential searching is not impossible. Third, sequential filter-and-refine using cheaper and less accurate distance is almost always a good option, even if other algorithms are no better than sequential searching. 