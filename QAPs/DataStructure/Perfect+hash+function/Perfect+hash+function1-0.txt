How can a perfect hash function work as a bloom filter alternative?
If I understand you correctly, you are saying: I have some (large, finite) problem Set (of "documents") (S) all documents are "stored" in an "array" D[] When would I choose a Minimal Perfect Hash Function over a Bloom Filter? (I changed the wording from n-cell to Minimal to be more clear) I think the crux of your problem is: IF my dataset ( S) doesn't ever change (no additions to S) can I use a Minimal Perfect Hash Function INSTEAD of a Bloom Filter. ...and the answer is YES this might be appropriate.  To create the Minimal Perfect Hash Function to for set membership queries: Read in all  D[] in S, and generate a Minimal Perfect Hash (assign each D to a slot D[0...D-1]), Organize all of your D[] Documents in S by their slot/hash (assigned by the Minimal perfect Hash Function (for simplicity lets say  the documents are Strings and they are all stored in a  String D[] where the index = slot and the value is the document contents as a string ) ...then (to do set membership queries) for some candidate document C use the Minimal Perfect Hash Function to calculate slot of C-> (MPH) -> c get D[c] and check is D[c] == C Now, let me point out some of the reason why you might NOT want to do this (and use a bloom filter instead): 1) if you simply CANT keep D[] all in memory, or access to D[c] takes a long time since for EVERY set membership query to have to read in D[c] and test the equality  (is D[c] == C?) Bloom filters, while less certain are ideal for membership queries... Minimal Perfect Hashes answer definitively "IF this value exists in S it must be located at D[c]", but that STILL means you have to check if C = D[c] 2) if each D in  D[] is big and equality checks take a long time (since again you are guaranteed to do an equality check for each query) (Bloom Filters allow you to provide the appropriate sizing and hash functions to make false positives/collisions RARE) 3) you can't use a MPH function if you allow additions to S 