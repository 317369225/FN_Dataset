Why Computer Programmers generally focus on Discrete Maths rather than Continuous Maths?Digital computers accomplish everything they do based on programs that are collections of instructions that make these machines perform operations in steps. Since the steps are discrete — and discontinuous — digital computers cannot perform  continuous truly continuous operations. We see this everywhere that digital computers are applied. For example, a digital camera is incapable of capturing a scene as a continuous two-dimensional function of colours. It must digitise the image, which means it acts on the image as if it were a rectangular array of dots, recording the colour for each dots in a two-dimensional array that it stores as the 'photograph'. Programmers wishing to work with these photographs must learn to work with arrays, which fit within the realm of discrete mathematics. The same kind of analysis applies to the computer programs themselves. One program might be able to process a photograph of a certain size within a time that is proportional to n 2   n2 where n  n is the width of the photo. Another is faster and can do it in time proportional to only n  n . Estimates of time required such as these usually involve discrete mathematics, although it might be necessary to invoke continuity to get limiting values. As a matter of fact, most of the time programmers count. Nothing more. Did this piece of my program do what it was meant to do k times or k−1  k−1 ? Will I need a two-dimensional array that's k  k on each side or k+1  k+1 ? But then studies of discrete mathematics makes it easier to discern the difference between things like sets, bags, Cartesian products, etc, all of which come up for some programmers on a daily basis. 95 Views · Answer requested by 1 person