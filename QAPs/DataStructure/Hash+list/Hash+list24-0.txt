What are the main applications of data structures?
Data structures exist to structure and organize data in a way that enables it to be searched in a particular way in less than linear time. Let's say you have a list of names. For a moment, imagine the list is physical. It's a sheet of paper, maybe a book if it gets large. The names on the list are in no particular order. How would you search for the name "Adam Smith"? You'd have to scan through the list and look at all the names. You have no other choice, since you don't know anything about where in your list Adam Smith may appear. That would be life without data structures. Simply looking through the list works fine when the list only has 20 names. But imagine if a citywide telephone directory were organized the same way! You'd never find anything in a practical amount of time. For all intents and purposes, the directory would be unusable. So, people came up with a different idea. They said, "hey, let's sort the names alphabetically." This enables an efficient algorithm called binary search to be used. You may think the name sounds fancy, but you already know how to do this. 1. Open the directory to its halfway point (open the middle page), and look at the name there. 2. You now know whether the name you're looking for comes before or after the name you see (unless you see it right there, in which case you're done). If before, your name is in the first half of the list. If after, your name is in the second half. 3. Repeat your search on the relevant half of the list. This structural change of how the names were organized has made it possible for names to be found rather quickly even in a very large collection of names. With every name we look at, we reduce the possible locations of what we're searching for in half. Mathematically, this means we can find a name by looking at about log 2 N  names, where N  is the total number of names. Note that searching for a name in the unordered list would have required looking at N  names in the worst case, and that log 2 N<<N  for large N  . The above is a very simple data structure. It's so simple that many programmers don't even think of it as a data structure. It would be called a "sorted array". Now, it turns out that while a sorted array is sometimes a good data structure, it has many shortcomings, so we're not done in our data structures journey! The most notable shortcoming is that you have to reprint the whole phone directory if you want to insert a couple additional names. Phone directories are printed once a year, and a new version is made at that point. But what if you needed something that's always up-to-date? Well, there's a way to structure data such that new data is easy to insert quickly. Programmers call this data structure a "tree" due to how some abstract representations of it look like on paper. There are many, many different kinds of trees. Here's the idea behind one type of tree called a B+ tree: instead of having the data sorted alphabetically, you have an index page that says something like: A - AW (not inclusive of upper bound): go to page 45 AW - BG: go to page 123 ... When you get to the specified page, there may be another index page further subdividing the range, until you get to a range so small that all the names fit on one page. We don't keep the pages completely full, so that when we need to write in a new name, we just find the page where it would belong, and write it in there. If a page gets full and we still need to add a name, we split it into 2 pages, each now half-full, and we modify the index page that got us there to reflect the change. Over time index pages can fill up too, and then we may have to split them too and modify their higher-level index pages and so on. Trees are some of the most fundamental data structures, but there are many others. Graphs represent entities (people, cities) and the relationships between them (friendships, has-a-connecting-flight). There's a lot of theory about graphs that allows us to solve interesting problems about them in a very abstract and general way. Heaps are like tournament trees (elimination brackets), with higher values (better players) dominating lower values (worse players) and appearing on top. The main advantage of heaps is that tournament-style elimination is fast to run (building a heap is fast) and you can very efficiently know the best players or the couple best players. Hash tables are data structures that calculate the correct space to store an object solely based on its contents. Imagine if a garage determined where it would park your car based on a mathematical calculation involving its license plate number, so that when you wanted to find your car, you'd repeat the calculation and know where it is. Range trees can efficiently search for all the points located inside a specified rectangle in the two-dimensional plane. Think of searching for nearby restaurants on a map, given your current location. Thanks for the A2A. Updated 10 Sep • View Upvotes • Asked to answer by Fariha Younus