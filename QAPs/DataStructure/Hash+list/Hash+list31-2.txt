Which database should I use for a killer web application: MongoDB, PostgreSQL, or MySQL?I'm working on killer web application, and I am really interested and worked with MongoDB. Is it a choice to choose MongoDB as a premier database? Or Is it better to use MySQL (with MongoDB/Redis as secondary)?
Originally Answered: What is the best storage solution for building a "news feed" - MongoDB or MySQL?To get performance and scale, a separate store specifically for the timelines is almost always a requirement. In actuality, the data store is really a secondary concern. In building an aggregation timeline, the primary architecture decision is when the fan-out occurs. Fan Out On Write ... is best if the timeline most resembles Twitter, a roughly permanent, append-only, per-user aggregation of a set of source feeds. When an incoming event is recorded, it is stored in the source feed and then a record containing a copy is created for each timeline that it must be visible in. Each timeline is essentially a materialized view of every event in the end user has visibility into. I'd basically only use a BigTable derivative for fan-out-on-write, as the data model fits this use case almost ideally. In BigTable, data is distributed among the a cluster by row key, and then individual records are stored as "columns" sorted by their column name. It's best to think of a row as a bucket and each column as a key/value pair in that bucket, stored in key-sorted order. BigTable stores are designed to deal with relatively unbounded numbers of columns. In the feed use case, each timeline is given a unique row key (like a username), and a column is inserted that represents each event, with the column name as a time-sortable unique ID, and the column value containing the event's data. In this schema, a timeline, containing potentially hundreds of events, can be read off a single node, and with just a few disk I/Os. The time-sorted ordering allows it to be efficiently paginated using a range slice operation. The append-only commit log means insertions are cheap and usually can be done at tens of thousands per second per node. My favorite BigTable implementation is Cassandra, but HBase is good at this type of thing as well. Cassandra can stay fully available for writes AND reads during a network partition. Additions or subtractions to the timeline are commutative, and can be easily resolved using techniques derived from Amazon Dynamo, so Cassandra's weakest consistency -- and therefore strongest availability and performance -- guarantees can be fully exploited. While perhaps MongoDB could be used in this manner, it has a 4MB document size limit, and must deserialize the entire document just to read a few columns. MongoDB is also a CP system, so a network partition event will, at best case, make some portion of the cluster unavailable for writes. In addition, you'll also have to "home-brew" a way to deal with event deletions and visibility changes. Since this system needs queues and workers to perform the fan-out operation, event deletions and updates to the list of source feeds for each timeline can be part of this background system as well. A higher level of consistency can be achieved by caching the mutations in something like memcached and temporarily performing the data scrubbing at read time, at least until the workers are able to get around to permanently mutating the timeline(s). Fan Out On Read The on read strategy is best if the timeline most resembles Facebook's news feed, in that it is temporal and/or you want dynamic features like relevance (the "Top News" feed on Facebook) or event aggregation. When an event is recorded, it is stored only in the source feed. Every time an end user requests their individual timeline, the system must read all of the source feeds that the end user has visibility into, and aggregate these feeds together. If you're doing fan-out-on-read, you can't really ever afford to go to disk, even if they're SSDs. All of the timeline data must be in memory, all the time. This means you'll probably have to monitor the size of the data set and actively purge the oldest data as the feed data grows beyond a safe threshold. The absolute best solution I can think of would be to build something on-top of an in-memory grid with distributed computation, like Hazelcast. For a half-way-decent implementation, and probably one that I'd choose, I'd go with a solution built on ElasticSearch, specifically if you want to provide any form of relevance, as this is sort of the sauce with Lucene-based systems. In ES, parallel write throughput is achieved by breaking the index into shards, and more read throughput can be achieved by replicating the index to multiple nodes. The shard count is chosen when the index is  first created, and the number of read replicas -- and therefore read throughput -- can be automatically expanded by bringing more nodes online. To ensure the system stays available during a network partition, I would build-out multiple clusters at separate data centers with identical copies of the data. Each new event is inserted into an MQ at the datacenter it originated at, with a fan-out of the event  in per-outbound-datacenter queues. Workers pull data from these outbound queues and insert data into the ES clusters running in each datacenter. The web application runs queries against it's datacenter-local ES cluster. 