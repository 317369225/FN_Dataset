What are the most important sort algorithms?It's all about trade-offs in performance. You have to be able to compare and swap elements, and all of that takes compute cycles and memory. All the best sorting algorithms compute with best-case/average-case time complexity O(n log(n)). When comparison and fully randomized swap operations are cheap, the Quicksort algorithm is the most popular, since it usually comes out the fastest in practice. The worst-case quicksort algorithm comes out as O(n^2), but it requires that at each recursive step the "key" (point for comparison) happens to be either the largest or smallest item in the subset to come out to n^2 complexity. But when random swaps are more computationally expensive, you might consider using a different kind of sort, such as a Merge sort. There are no random swap operations and consequently this can be performed on objects that are not randomly accessible (i.e. a linked list). The increased time compared to a quicksort comes from having to merge lists. If inserting an element requires little effort, but swapping takes substantial effort, and you expect the array to be fairly close to sorted (i.e. gets sorted often), you might consider using something like an Insertion sort -- actually, when you sort a deck of cards, you probably use a similar method. For a completely random array, its time complexity is horrible, but for a close-to-sorted set, its time complexity is awfully close to O(n). 