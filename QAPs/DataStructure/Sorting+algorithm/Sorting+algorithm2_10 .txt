In programming contests, which sorting algorithm is best?As there are many sorting algorithms, how can I determine which sorting algorithm is best? When I should use a certain sorting algorithm? I am using C++.There is no single "best" sorting algorithm. If there were we wouldn't bother using any other, and would only teach or learn any other to determine its relative flaws. There are certainly "good" or "bad" choices for a certain situation, but superlatives like "best" involves consideration of performance, memory-efficiency, input size, coding complexity etc. which differ between use cases. Even SelectionSort and other quadratic sorts have their place once in a while. Case in point, Adam Helps dumps on the humble BubbleSort, without acknowledging a key advantage; its best case, a nearly-sorted list, is fairly common in many scenarios, and causes the algorithm to approach linear complexity (moving only one or two items to their proper place). Most NlogN sorts like QuickSort or MergeSort can't naturally detect this condition; they perform the same number of steps even when the list is already in order. Some implementations of InsertionSort, also nominally an N^2 sort, are even faster on a list with only one or two out of place, and the algorithm can be made to approach linear complexity on linked-list implementations, where inserting a node does not require shifting all elements between the item and its proper place. SelectionSort is pretty much N^2 however you slice it (even with an already-sorted list), but it has its own advantages; it's an in-place sort, it's easily made stable (tie goes to the first object found), and it's very simple to code. For small lists (<10 items maybe), its overall behavior is practically indistinguishable from a more efficient sort, and it may even be faster than something like MergeSort which involves overhead of memory allocation. QuickSort is a common fave, and the algorithm of choice for Microsoft environments and runtimes for years. The strategy's pretty straightforward; choose a pivot value, move everything less than that value to the left and everything greater to the right, then QuickSort each side of the pivot as its own list. This sort has the potential to be wicked fast (hence the name; even among NlogN sorts it's fast), and it's easy to make it in-place by swapping values instead of copying them to new arrays. However, efficient implementations have relatively high source code complexity, and are not stable (two elements that evaluate as equal may not keep their relative order from the original list). Perhaps most damning is that QuickSort has a pretty significant Achilles' heel without an "ideal" solution; proper pivot selection. If, during any level of sorting, the pivot value chosen is the lowest or highest value in the sub-list, everything will end up to one side of it. The solution providing the most even divide at every step is to identify the median value of the list at each recursive step, but that practically doubles execution time; more efficient compromises include median-of-3 (choose three arbitrary indices from the list and use the middle value) and various dynamic-pivot strategies (Choose one pivot and do some reordering based on it, but as you scan the array, use those moves and comparisons to determine the true median value, and redistribute a second time with that pivot). These pivot selection strategies reduce worst-case performance on a random-list at the cost of average-case performance, and all of them are vulnerable to a purpose-built "QuickSort-killer" collection ordered in just the right way to take the maximum possible time given the implementation details (for instance, if the three indexes for median-of-3 selection are known, the list can be ordered so those three are always the three lowest or highest values at each stage). Since I mentioned MergeSort, it's my pick for a go-to sort algorithm in the general case nowadays. It's an intuitively-understood sort, a little easier to understand (and thus to implement) than QuickSort, TreeSort or HeapSort, and it's very easily parallelizable (QuickSort its too, but you get the benefit of additional execution threads quickly and for a longer time each than QuickSort). It's trivially made stable (ties go to the element on the "left" stack), and it doesn't have the Achilles' heel of value-based list segregation like QuickSort, nor the memory/processor overhead of building and digesting a node-based memory structure like HeapSort or TreeSort. So, its average-case performance is basically its best and worst case, and that performance is almost always very good. Its primary disadvantage is a minimum O(2N) memory efficiency; at the last step, merging two halves into the full sorted list, you typically have the original list which is in two sorted halves, then a second collection into which you're merging the halves and will copy back onto the original array. Parallelization further increases average memory use during execution because multiple pieces of the list are being cloned and copied at once, and can increase total execution time for small lists in certain runtimes and collection types. Timsort is enjoying popularity behind the scenes as the algorithm of choice for built-in collections and sorters in the Java and Python languages/runtimes. It's a hybrid of InsertionSort and MergeSort; it finds subsets of the full list that are already in order, and uses that to decide whether to use a simple InsertionSort (for small lists) or a MergeSort (for large ones), as well as to increase the efficiency of merging by reducing the number of comparisons made between elements on each side (if it's known that two or more elements on one side of a merge are sequential, the range of said elements on that side that is less than the elements on the left can be inserted in sequence without comparing each one). After all of this, the "best" sort from the perspective of the developer is the one you don't have to code yourself. Virtually all languages in common use today have some form of built-in collection sorting, and that implementation will have been peer-reviewed and performance-tested much more than you probably care to do to your own algorithm, so it should function in acceptable time for your own purposes. And here's the kicker; it's already written and tested; all you have to write and test is the usage, making sure the sort is performed the way you expect. 