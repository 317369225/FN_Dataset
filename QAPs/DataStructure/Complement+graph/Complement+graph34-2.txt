At what size does data become "big data"? And is the definition different depending on the industry/statistical test?At university we were taught that n > 30 is a good 'rule of thumb' for starting to see statistical patterns in data. In the messy world of R&D we sometimes joked that it just took two experimental measurements to see a trend in the data!Â  On a practical basis, when would you say that you had 'big' data in your field of work, and how much data would you consider appropriate to start making decisions...?
I think the word "big" data is a misnomer. I came across a great piece explaining big data in the book "Doing Data Science" by Cathy O'Neill and Rachel Schutt. http://shop.oreilly.com/product/... They basically say that talking about big data only as a function of database size is meaningless because it is relative to advancements in memory technology. 1 terabyte was a lot of memory a decade ago. Rather, it's relative to the current state-of-the-art computational power available to handle it. That was just from the size perspective i.e in terms of 'volume' of information. Big data can be classified using two other V's - variety (as in structured tabular versus unstructured text and audio log data) and velocity (logs / machine to machine comms). 