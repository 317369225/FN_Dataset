What are use cases for Spark vs Hadoop?
Spark together with Scala is a lot easier to for executing little programs than just plain Hadoop. This is especially convenient for people with development background who like to run "stuff" (ad-hoc queries) on data in hadoop/hdfs. This remove the need to know about the underlying hadoop layer and just think of it as data. Update: For those with a database background, there is a tool called Shark that provides a Hive-like SQL-like interface but with access to Scala MLlib capabilities. with Spark performance. Updated 24 Oct 2014 â€¢ View Upvotes