What is the intuition behind randomized algorithms and randomization in general?
IntuitionThe way that I think about randomized algorithms is that they take advantage of symmetry. Think about the algorithms you know. One exercise that I like to do is think about the question "What is the worst case input? What does it look like?" If you do this for every algorithm you come across, one pattern you will find is the following situation: Everything was going fine until you hit a fork in the road. Your algorithm made a heartbreaking choice somewhere along the line that screwed you. At that step the problem was symmetric; it was impossible to distinguish the good pick from the bad one. The intuition that I have for randomized algorithms becomes: If you just flip a coin at the fork in the road, you're better in expectation than you are currently. Why not take the plunge? You've got nothing to lose. ApplicationsSome examples off the top of my head where this comes into play: Randomizing the simplex algorithm for linear programs (the worst case is a "noisy" hypercube where you always are tricked into picking the wrong direction). Randomized Quicksort! Pivot selection is hard and you often make a bad choice with whatever pivoting rule you come up with. Break the symmetry by choosing uniformly at random! Random projections as a standard technique for high dimensional data problems. Bad examples for "big data" algorithms are usually when you have a massive vector, but only a few important coordinates. If the pattern is there, you can probably eliminate a ton of work by removing coordinates. Randomized data structures such as Hash tables, Skip lists, and Treaps. Here, we are taking advantage of the symmetry in the way the data is stored. Adding a coin flip increases our likelihood of picking the right access path.  More applications include many game theoretic and online problems. One is the online matching problem and the ranking algorithm. The requests for your load balancer are comin' in hot, you need to make a choice now! How do you guarantee that you don't do much worse than the optimum in expectation? Add a random choice. Break the symmetry in the requests. Sometimes your strategies in certain games have no "traditional equilibria". One example is the matching coins game. You have two players, each with a coin of sides heads or tails. They can each pick either heads or tails as their strategy. Player 1 wins if both faces match, Player 2 wins if they do not. If you write out the payoff matrix in this game, you will see there is no Nash equilibrium. This symmetry (this time in the matrix!) would lead you to believe that maybe the best strategy involves a coin flip. Many of these well studied games manifest themselves in fields like finance or computer networking (limited bandwidth, each player is an ISP and they have bandwidth as a limited resource, financial agents playing the trading game, etc.). ReferencesTHE book on randomized algorithms is Motwani and Raghavan:  Randomized Algorithms: Rajeev Motwani, Prabhakar Raghavan: 9780521474658: Amazon.com: Books I cannot recommend this book enough. This book changed the way I think about algorithms. SO much wisdom in those pages.   I also recommend these other general algorithms textbooks if you don't want to just dive right into the meat of the subject: CLRS: Introduction to Algorithms: Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest, Clifford Stein: 9780262033848: Amazon.com: Books K&T: Algorithm Design: Jon Kleinberg, Éva Tardos: 9780321295354: Amazon.com: BooksI also would recommend these course notes if you are looking to just get into it quickly: Page on Northwestern Page on Yale Again, I cannot recommend Motwani and Raghavan enough. TL;DR Buy Motwani and Raghavan. Everything you would ever want to know and more is in those pages. 