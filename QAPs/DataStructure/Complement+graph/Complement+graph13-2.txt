What are use cases for Spark vs Hadoop?
In the case of Spark in relationship to Hadoop, I would say it is that Spark and Hadoop complement each other instead of competing with each other. Hadoop is your uber-store of all of your semi-structured data within HDFS and it has the flexibility of Map Reduce so you can query the data.  It is the iron horse that is implemented first so it is possible to go to the next level in Big Data Analytics. Spark starts with the same concept of being able to run MR jobs except that it first places the data into RDDs (Resilient Distributed Datasets) so that this data is now stored in memory so its more quickly accessible.  That is the same MR jobs can orders of magnitude faster because the data is accessed in memory. It adds to that flexibility and speed with ability to write queries in Scala (as William noted), Java (like Hadoop), and Python.  Spark is part of the Berkeley Data Analytics Stack (BDAS) which also include Tachyon (an in-memory file system), Spark Streaming, and to be released as part of Spark 0.8 the ability to run graph algorithms.  As quoted by Reynold Xin in Spark: Open Source Superstar Rewrites Future of Big Data | Wired Enterprise | Wired.com, "Spark is the swiss army knife of Big Data Analytics" 