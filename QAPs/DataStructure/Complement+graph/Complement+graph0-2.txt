What is the intuition behind randomized algorithms and randomization in general?
I will explain this with the help of an example. One of the most used method is the Monte Carlo method. Basically, this method involves running simulations many times over to obtain the expected value or result. How would this help? Consider rendering a photo realistic image. A common method to do this is to "trace" the path of a ray of light from the each pixel of the camera (or eye) through the entire scene to figure out what objects it interacts with (this method is called Ray tracing). Now, one way would be to trace every single ray in every single direction that can possibly be generated. You can see why this might be a humongous task. Another way is to generate a ray and figure out what was the probability that this particular ray was generated (there are mathematical models you can use to figure it out). Then, you can simply weigh the contribution of this ray by its probability. Do this a few times and you can figure out the expected value. Of course, this is never going to be perfect but can you can always pick the number of rays you want to generate to get an expected error percentage. Much better than trying to generate every single possible ray. (Note : All this is a bit of a simplification, but correct) A lot of algorithms function this way, especially those have a huge search space. The trick is in using a subset of possibilities and figuring what is the probability they were generated and using that to figure the expected value of a certain computation, rather than going after the actual perfect value which would take ages to compute. 