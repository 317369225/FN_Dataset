How can I make my own OMR reader using image processing with C++ and OpenCV?
I'll answer with the following assumptions, 1. OMR sheet location and orientation is fixed in the image. 2. Location of the OMR boxes is pre known. (Manual storage of coordinates for one image, works for all). 3. Size of the boxes is fixed and always four boxes for each question. I'll suggest methods for each of these answers at the end. Steps: 1. Extract the box locations based on the manual coordinate inputs. 2. Divide the image into small images each contains four answers for the question. 3. Apply grey level thresholding to the small image to make it binary image. 4. Use labeling to get the centroid of the biggest area blob. 5. Centroid decides the answer based on nearest neighbour. Repeat for all the sub images with appropriate indexing to allow them to compare against key answers. Remedy for avoiding assumptions 1. Use auto orientation algorithm to get the omr sheet in rectangular form. 2. Use training based classifier to detect the answers region. 3. Change the centroid basic decision depending in the number of options. PS: if you looking actual open CV APIs to implement each of these steps,please let me know in comments 