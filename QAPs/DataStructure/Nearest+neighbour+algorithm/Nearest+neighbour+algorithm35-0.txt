What is better, K - nearest neighbor (KNN) or Support Vector Machine (SVM) classifier?
What is better? It depends. Which algorithm is mostly used practically? I'd say SVM, it's very popular. Now some comments about those quick answers: KNN has some nice properties: it is automatically non-linear, it can detect linear or non-linear distributed data, it tends to perform very well with a lot of data points. On the minus side KNN needs to be carefully tuned, the choice of K and the metric (distance) to be used are critical. As Michal Illich mentioned for many datapoints KNN has performance problems. If you are in a very low dimensional space you can use a RP-Tree or KD-Tree to improve performance, if you have a higher number of dimensions then you need an approximation to the nearest neighbors problems and whenever we use an approximation we have to think if KNN with the NN approximation is still better than other algorithms. KNN is also very sensitive to bad features (attributes) so feature selection is also important. KNN is also sensitive to outliers and removing them before using KNN tends to improve results. SVM can be used in linear or non-linear ways with the use of a Kernel, when you have a limited set of points in many dimensions SVM tends to be very good because it should be able to find the linear separation that should exist. SVM is good with outliers as it will only use the most relevant points to find a linear separation (support vectors) SVM needs to be tuned, the cost "C" and the use of a kernel and its parameters are critical hyper-parameters to the algorithm. So making something useful out of this mess: - if you have a lot of points in a low dimensional space then KNN is probably a good choice. - if you have a few points in a high dimensional space then a linear SVM is probably better. Most likely you will be in the middle of the road and that means that either algorithm can provide the best solution. Finally you asked about unpredictable situations, in that case I think either a SVM with a RBF kernel or a Random Forest are your best choices as they tend to perform quite well in average. Somebody will mention the NFL (no free lunch theorem) and say that if we don't know the data then we don't know which algorithm will perform better but that is only true if we consider ALL possible optimization problems, taking into account that most optimization problems are only a small subset of the whole then it is valid to say that some algorithms will be better than others in average so in such cases I'd go with a SVM or a Random Forest. Luis 