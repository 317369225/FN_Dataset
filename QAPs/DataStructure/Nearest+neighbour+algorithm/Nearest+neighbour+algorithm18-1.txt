Why is dimensionality reduction useful?
In terms of performance, having data of high dimensionality is problematic because (a) it can mean high computational cost to perform learning and inference and (b) it often leads to overfitting (http://en.wikipedia.org/wiki/Ove...) when learning a model, which means that the model will perform well on the training data but poorly on test data. Dimensionality reduction addresses both of these problems, while (hopefully) preserving most of the relevant information in the data needed to learn accurate, predictive models. As others have mentioned, data visualization and interpretation are also common uses for dimensionality reduction. Clustering, which is a form of dimensionality reduction, is often used both to understand the data by analyzing the clusters and to use the associations of data points to clusters as features in performing a predictive task such as classification. Finally, to clarify what Jeff Hammerbacher wrote, the point about improving performance also applies to predictive frameworks that are not necessarily strictly supervised (for example, semi-supervised). 