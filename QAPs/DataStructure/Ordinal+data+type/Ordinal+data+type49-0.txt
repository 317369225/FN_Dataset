What is permutation entropy?
Permutation Entropy (PE) is a measure for arbitrary time series based on analysis of permutation patterns. (Paraphrasing a Page on ic.ac.uk(Rapid Evaluation of Permutation Entropy for Financial Volatility Analysis – A Novel Hash Function using Feature-Bias Divergenceby Ren Lim) Also: [1411.3904] Autocorrelation type functions for big and dirty data series In some papers [10], permutation entropy of scale d uses patterns for sums of d consecutive terms of the xt , which makes sense if the xt represent a density function, like precipitation or workload on a server. This version is easily implemented by cumulative sums, adding x=cumsum(x) as first line to the program. (The reference [10] cited is for J. Amigo, K. Keller & J. Kurths (eds.), Recent progress in symbolic dynamics and permutation entropy, Eur. Phys. J. Special Topics 222 (2013)) One could equally well call it another form of cross correlation as to call it  another form of entropy. Permutation entropy is the Shannon entropy of the distribution of order patterns:H = − X π pπ log pπ . H can be defined for any level n, using the vectors (xt , xt+d, ..., xt+(n−1)d) and their n! order patterns π [8]. In practice we hardly go beyond n = 7. Used as a measure of complexity and disorder, H can be calculated for time series of less than thousand values since statistical inaccuracies of the pπ are smoothed out by averaging. All references and original papers seem quite new.  Instead of calling it an emerging topic, it might better be considered embryonic. Permutation entropy [8, 9, 10] has been used in physics [2, 11], medicine [12, 13, 14], and engineering [15, 16]. Now ordinal patterns [17, 18, 19] are studied in detail for big data. 