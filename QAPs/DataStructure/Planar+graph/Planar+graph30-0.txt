How can you run analysis on graphs located on multiple servers when you need the entire graph and not a subset of it?
This depends a lot on the type of graph you're processing, and the type of queries you're running on them.  There are some tools, pregel, MR, and other approaches like per-node hashed replication (little engines/SPQR from Telefonica).  But none of these are a panacea for distributed graph processing. 1. planar graphs. if you're working on sparse or planar graphs, there are lots of reasonable solutions. running metis on the data to do pre partitioning will make the data suitable for a parallel processing system. I still don't recommend mapreduce in that case. It's just not designed for graphs. you'll end up doing ridiculously short map phases, 1 for each hop you process in your graph query, and you'll waste more time sending metadata and doing mostly useless reducing rather than real processing.  SPQR should do better. 2. high density/social graphs. If you're working on social graphs, then there's not much hope in terms of a reasonable partitioning. Our work with lots of these graphs (and work done in industry) all show that real social networks (FB, linkedIn, and just about anything else that's not a blog or Q&A system) is not partitionable in any real sense. you lose more than you win, even with the best partitioning algs out there, e.g. metis.  This is why companies like linkedin have to resort to things like precomputing and caching graph results on a 24 hr cycle, and for quite a while just replicated their entire graph on humongo servers with ridiculously large main memory.  Their Giraph system, which is a takeoff on pregel-like BSP, is probably worth a look. 3. the above scenarios assume you care about near real time processing, i.e. OLTP-like.  But if you're google, where processing delay doesn't matter, and you've got massive amounts of data, then biting the bullet on MR makes sense, because they care more about processing throughput, so slow, per-hop progress on HUGE amounts of data is ok. 