Why do array indices start with 0 (zero) in many programming languages?Simple answer: 0 is the first integer, not one. Technical answer: An array is stored in memory as a group of adjacent objects, and the address of the first object is stored in the array variable. When you put, x [y], it's really, "give me the value stored at x + y * sizeOfEach." Since x is the address of the first item, y has to be zero or the first entry will get skipped. EDIT: Additionally, you use 0-based offsets in real life every day. How many miles away is your computer/phone from your face? Zero? Mine too. 