How do you map business problems to big data technologies? Has anyone seen a good taxonomy for doing this?
This is outside my area of expertise, and I am not sure I understand the question. With that in mind, for your consideration. (Also, have you considered going to a local public or academic library? Many academic/college libraries do give at least some reference service to non-affiliates…and perhaps some access to online subscription based articles…just call ahead and ask!) Two results from a Bing search…      map business problems big data taxonomy Big data architecture and patterns, Part 1: Introduction to big data classification and architecture Taxonomy's Role in Content Management Here are some results from Business Source Complete (a database which indexes business articles…some have links to full text of the articles..your local public library and/or academic library might have this)      Search phrases used                    (DE "Problem Solving") AND (DE "Big Data")                     "business problems" AND "BIG DATA" Record: 1 Big Data. By: Bergl, Skylar; Gertner, Jon; LaPorte, Nicole; Larson, Christina; McCorvey, J. J.; Miller, Nancy; Rai, Saritha; Rhodes, Margaret; Snow, Shone. Fast Company. Mar2014 Supplement, p15-15. 1p. 1 Diagram. Abstract: The article discusses innovation in the big data industry as of March 2014, presenting profiles of ten companies' products and services. Topics include the 3-D map visual analysis of Ayasdi, International Business Machines' (IBM) partnerships with cities, businesses, and institutions to solve problems, and The Weather Company's analysis of weather impacts on shopping trends. (AN: 94376450) Database: Business Source Complete Record: 2 Foresight as Dialogue. By: Mack, Timothy C. Futurist. Mar/Apr2013, Vol. 47 Issue 2, p46-50. 5p. Abstract: The author, president of the nonprofit educational group World Future Society, discusses methods for forecasting the future and developing prediction models, and offers tips for using traditional and adaptable techniques for forecasting. The value of questioning, analyzing data trends, and general statistical analysis, as well as big data, the reliability of quantitative and qualitative sources, and personal and organizational biases. Prioritization, government transparency and accountability, and problem solving with technological advances are also mentioned. (AN: 85194644) Database: Business Source Complete Record: 3 GoSCAN: Decentralized scalable data clustering. By: Mashayekhi, Hoda; Habibi, Jafar; Voulgaris, Spyros; Steen, Maarten. Computing. Sep2013, Vol. 95 Issue 9, p759-784. 26p. 4 Diagrams, 1 Chart, 12 Graphs. Abstract: Identifying clusters is an important aspect of analyzing large datasets. Clustering algorithms classically require access to the complete dataset. However, as huge amounts of data are increasingly originating from multiple, dispersed sources in distributed systems, alternative solutions are required. Furthermore, data and network dynamicity in a distributed setting demand adaptable clustering solutions that offer accurate clustering models at a reasonable pace. In this paper, we propose GoScan, a fully decentralized density-based clustering algorithm which is capable of clustering dynamic and distributed datasets without requiring central control or message flooding. We identify two major tasks: finding the core data points, and forming the actual clusters, which we execute in parallel employing gossip-based communication. This approach is very efficient, as it offers each peer enough authority to discover the clusters it is interested in. Our algorithm poses no extra burden of overlay formation in the network, while providing high levels of scalability. We also offer several optimizations to the basic clustering algorithm for improving communication overhead and processing costs. Coping with dynamic data is made possible by introducing an age factor, which gradually detects data-set changes and enables clustering updates. In our experimental evaluation, we will show that GoSCAN can discover the clusters efficiently with scalable transmission cost. [ABSTRACT FROM AUTHOR] DOI: 10.1007/s00607-012-0264-2. (AN: 90053031) Database: Business Source Complete Record: 4 Large-scale incremental processing with MapReduce. By: Lee, Daewoo; Kim, Jin-Soo; Maeng, Seungryoul. Future Generation Computer Systems. Jul2014, Vol. 36, p66-79. 14p. Abstract: Abstract: An important property of today’s big data processing is that the same computation is often repeated on datasets evolving over time, such as web and social network data. While repeating full computation of the entire datasets is feasible with distributed computing frameworks such as Hadoop, it is obviously inefficient and wastes resources. In this paper, we present HadUP (Hadoop with Update Processing), a modified Hadoop architecture tailored to large-scale incremental processing with conventional MapReduce algorithms. Several approaches have been proposed to achieve a similar goal using task-level memoization. However, task-level memoization detects the change of datasets at a coarse-grained level, which often makes such approaches ineffective. Instead, HadUP detects and computes the change of datasets at a fine-grained level using a deduplication-based snapshot differential algorithm (D-SD) and update propagation. As a result, it provides high performance, especially in an environment where task-level memoization has no benefit. HadUP requires only a small amount of extra programming cost because it can reuse the code for the map and reduce functions of Hadoop. Therefore, the development of HadUP applications is quite easy. [Copyright &y& Elsevier] DOI: 10.1016/j.future.2013.09.010. (AN: 95825494) Database: Business Source Complete Record: 5 Making sense of big text: a visual-first approach for analysing text data using Leximancer and Discursis. By: Angus, Daniel; Rintel, Sean; Wiles, Janet. International Journal of Social Research Methodology. May2013, Vol. 16 Issue 3, p261-267. 7p. 2 Black and White Photographs, 1 Diagram. Abstract: This article reports on Leximancer and Discursis, two visual text analytic software tools developed at the University of Queensland. Both analyse spatial and temporal relationships in text data, but in complementary ways: Leximancer focuses on thematic analysis, while Discursis focuses on sequential analysis. Our report explains how they work, how to work with them and how visual concepts are relevant to all stages of their use in analytic decision-making. [ABSTRACT FROM PUBLISHER] DOI: 10.1080/13645579.2013.774186. (AN: 86688805) Database: Business Source Complete Record: 6 The Path to Big Data Mastery. By: MAY, THORNTON A. Computerworld. 2/10/2014, Vol. 48 Issue 2, p32-32. 1p. Abstract: The author looks at how North America's banks are organizing their path to big data mastery and presents a 10-step pattern of behavior by the banks that seemed to achieve big data capabilities. He cites the need to decide to act, craft a narrative and access Type 1 smartness which he explains is the type of intelligence that can do unstructured problem solving. He warns that acquiring the knowledge and harnessing full value from big data is a cumulative process that takes time. (AN: 95292141) Database: Business Source Complete Record: 7 The Power Of 'Thick' Data. By: MADSBJERG, CHRISTIAN; RASMUSSEN, MIKKEL B. Wall Street Journal - Eastern Edition. 3/22/2014, Vol. 263 Issue 67, pC3-C3. 2/3p. 1 Color Photograph. Abstract: The article presents an essay adapted from the book "The Moment of Clarity: Using the Human Sciences to Solve your Toughest Business Problems" by Christian Madsbjerg and Mikkel B. Rasmussen on a type of big data the authors call "thick data." They describe how toymaker Lego and medical-technology firm Coloplast used insights gleaned from thick data to improve their businesses. (AN: 95030066) Database: Business Source Complete Record: 8 Towards Ultrahigh Dimensional Feature Selection for Big Data. By: Mingkui Tan; Tsang, Ivor W.; Li Wang. Journal of Machine Learning Research. 2014, Vol. 15 Issue 4, p1371-1429. 59p. Abstract: In this paper, we present a new adaptive feature scaling scheme for ultrahigh-dimensional feature selection on Big Data, and then reformulate it as a convex semi-infinite programming (SIP) problem. To address the SIP, we propose an efficient feature generating paradigm. Different from traditional gradient-based approaches that conduct optimization on all input features, the proposed paradigm iteratively activates a group of features, and solves a sequence of multiple kernel learning (MKL) subproblems. To further speed up the training, we propose to solve the MKL subproblems in their primal forms through a modified accelerated proximal gradient approach. Due to such optimization scheme, some efficient cache techniques are also developed. The feature generating paradigm is guaranteed to converge globally under mild conditions, and can achieve lower feature selection bias. Moreover, the proposed method can tackle two challenging tasks in feature selection: 1) group-based feature selection with complex structures, and 2) nonlinear feature selection with explicit feature mappings. Comprehensive experiments on a wide range of synthetic and real-world data sets of tens of million data points with O(1014) features demonstrate the competitive performance of the proposed method over state-of-the-art feature selection methods in terms of generalization performance and training efficiency. [ABSTRACT FROM AUTHOR] (AN: 96263434) Database: Business Source Complete Record: 9 Visualization Mosaics for Multivariate Visual Exploration. By: MacNeil, S.; Elmqvist, N. Computer Graphics Forum. Dec2013, Vol. 32 Issue 6, p38-50. 13p. Abstract: We present a new model for creating composite visualizations of multidimensional data sets using simple visual representations such as point charts, scatterplots and parallel coordinates as components. Each visual representation is contained in a tile, and the tiles are arranged in a mosaic of views using a space-filling slice-and-dice layout. Tiles can be created, resized, split or merged using a versatile set of interaction techniques, and the visual representation of individual tiles can also be dynamically changed to another representation. Because each tile is self-contained and independent, it can be implemented in any programming language, on any platform and using any visual representation. We also propose a formalism for expressing visualization mosaics. A Web-based implementation called MosaicJS supporting multidimensional visual exploration showcases the versatility of the concept and illustrates how it can be used to integrate visualization components provided by different toolkits. [ABSTRACT FROM AUTHOR] DOI: 10.1111/cgf.12013. (AN: 90243560) Database: Business Source Comp 