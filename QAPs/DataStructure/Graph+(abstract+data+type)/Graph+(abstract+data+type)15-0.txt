What are the differences between a Graph database and a Triple store ?
To Colin McEnearney's points, which I generally agree with: Short of Utopia, the RDF model also informs humbler open standards efforts such as Schema dot org, RDFa and JSON-LD. These are significant because of the substantial (often donated) code and knowledge bases of search engine/social networking companies and the leverage those bases offer. My impression is that Neo4j users (for example) tend to be tactically focused and not versed in semantics because they're not concerned with helping to build permanent shared knowledge bases essential to any form of public contextual computing. Those focused on less perishable, more widely sharable information (Wikidata  being an example) seem to have thought an awful lot about the RDF model and how to create practical, web developer-oriented instantiations of it. See What is the difference between Wikidata and DBpedia? and Denny Vrandecic's Quora answers. What's unfortunate about most monolithic graph DB efforts is that they seem to  perpetuate data feudalism and seem to work almost against the grain when the utility of graphs is so often derived from the ease with which they can be interconnected. What's interesting and more positive is how document and hybrid DBs (such as Mongo and OrientDB) can act as more of a tabula rasa on which you can build your graph structures. AllegroGraph becomes MongoGraph, for example, and in the process JavaScript gains the ability to do  joins. See MongoGraph: A MongoDB API to AllegroGraph. For that matter, graphs could live among other, less articulated structures (such as trees or hierarchies) in the same document. Whole repositories can consist of one document.That approach, particularly when underpinned by a Hadoop data lake with the ability to store files in their original, full fidelity form and also track the provenance, metadata, actions on and versions of files stored via HDFS (what the folks at Revelytix are working toward with Loom, for example--see Getting Started with Loom), would seem to lend itself to an unsiloed and thus less feudal result. Which in turn would lead to analysts and developers who don't have to just look for their keys under the lamppost because that's where the light is anymore. Business intelligence (or any kind of intelligence) thrives on a combination of web-scale aggregation of a variety of sources and the ability to hypothesize about, mine and build context dynamically during discovery across those sources, which is why we thought the RDF-based Urika appliance was worth pondering: See Discovering new questions to ask Also speaks to the latency challenges of graph DBs when it comes to large graphs. 