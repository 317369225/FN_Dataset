What are some actual projects data scientists have worked on?Given how much interest there is in data science, I was thinking it would be great if some data scientists could walk through a project they've worked on, what tools and analytical techniques they used, and most importantly, their thought processes behind each step of their analyses and execution, as well as what mistakes they made.
First, for some background... Product: mobile payments, direct carrier billing (buy something online using your phone number and the charge appears on your cell phone bill). Problem: people with prepaid accounts fail transactions for having insufficient funds. Possible optimization: send customers a text message after failing telling them to top up and try again. Is it effective? Seems like a great place for an A/B test. 50% of users will get the message. To analyze this test, we can't rely on simple conversion or revenue numbers. This is a highly targeted optimization and deserves a highly targeted analysis. The first step is to identify what metric to compare across the two groups: What percent of customers that fail for insufficient funds subsequently transact successfully? Great - if our text message works, more people will come back after topping up.Â  Immediately, we run into a few problems. Segmentation - new vs. returning customers. If a customer comes back 3 weeks later is it really because of our text message? So, we start by looking at adding "...within N hours" to the original question, and proceed to plot the resulting distribution for each segment (new, returning) and group (control, test) and see what we find. Hmm, that's strange. 30% of returning users succeed within 1 minute. How do so many people top up so quickly? After some more digging, we realize that there are two ways a customer can meet our success criteria: They top up their account and come back They buy something cheaper So again, we now ask the question twice, for each of those possibilities, to get a better idea of how our text message impacts customer behavior. We get an estimate of the uplift, and assign a revenue value to it. Then, compare that to the cost of sending the text message. Is a 2% bump really worth it? From here I can't really share exact implementation details, but the ideal solution is going to send the text message in some scenarios and not others, and to consider completely different optimizations based on what we learned. As for techniques, this is mostly SQL, Python and Excel. First, identify the transactions with insufficient funds failure. Run queries on that user to determine their segment and group, and when their next successful transaction was on the same price or higher, and on a lower price. Each of those queries is easy and fast, but you want to iterate across thousands or millions of transactions. So, use python to first find the transactions to iterate across, put them in a list, and iterate through that list to run the little queries. Each iteration, store the results. Round the time gap into minutes for simplicity. Be careful of users that fail multiple times - only count their first failure. Once you have results, use a counter to determine how many people from each segment/group/price bucket return in N minutes Write results to CSV Analyze visually and analytically in Excel - the data isn't too big anymore. Sorry there is no fancy machine learning or rigorous statistical modeling - our team is solving applicable business problems and making recommendations on a fast turnaround cycle. Once the A/B test is running, I'd expect this project to take 1-2 days (on top of everything else that is going on). I picked this example out of hundreds of analysis I've done at Boku over the last few years because it was relatively detailed, hopefully easy to understand, and doesn't give away anything too secret (you can figure out that we do this by using our service...). Hope you enjoyed! 