What are the advantage of binary indexed tree (BIT or fenwick tree) over segment tree?It seems like both segment tree can BIT can do same tasks. What are the areas or cases where BIT or segment tree, exclusively prove to be advantageous.
BITs are a more space-efficient version of segment trees. In a BIT, the extra data that a segment tree typically needs to hold in addition to the original array is stored within the original array itself, so that it essentially uses no extra space. However, you can only use a BIT in place of a segment tree when certain conditions hold, as described in detail below. Segment trees are more general. Part 1: The problem Segment trees are used to answer queries about properties of subarrays of a given array. Here are two sample problems: Given two indices i and j, what is the sum of the subarray from index i to index j? Given two indices i and j, what is the minimum of all the values between index i and index j? Generally speaking, let ⋅  be an abstract binary operator (such as + or min, but not limited to them), and let a  be the array, with its elements denoted a 0 ,a 1 ,...,a n−1   . Segment trees are used to answer queries of the form "Given i  and j  , what is a i ⋅a i+1 ⋅...⋅a j−1 ⋅a j   ?" Part 2: Segment Trees Naively, this would take O(j-i) time. However, suppose we accelerate the process by constructing a summary array S of size N/2. Let S i =a 2i ⋅a 2i+1   . In other words, if we want to evaluate a query on the range from 1 to 7, we would have  a 1 ⋅a 2 ⋅a 3 ⋅a 4 ⋅a 5 ⋅a 6 ⋅a 7   =a 1 ⋅(a 2 ⋅a 3 )⋅(a 4 ⋅a 5 )⋅(a 6 ⋅a 7 )  . The quantities in parentheses can be evaluated in one operation by looking at the summary array: we want a 1 ⋅S 1 ⋅S 2 ⋅S 3   . This is a speedup, but only by a constant factor. We're still going through roughly (j-i)/2 entries in the summary array. We get the idea to calculate a summary array of the summary array, to speed up that layer as well, then a summary of that summary, and so on until we have a summary of size 1.  Here's an example for the case of answering range minimum queries. Raw data: [2, 6, 4, 2, 7, 1, 3, 10] Summary level 1: [2, 2, 1, 3] Summary level 2: [2, 1] Summary level 3: [1] In  each level, the summary is computed by applying the binary operator (here the min function) to the two corresponding elements of the previous level. Now, we can break up the requested operation into a small number of chunks that correspond to entries in the raw or summary arrays. We have a 1 ⋅a 2 ⋅a 3 ⋅a 4 ⋅a 5 ⋅a 6 ⋅a 7   =a 1 ⋅(a 2 ⋅a 3 )⋅(a 4 ⋅a 5 )⋅(a 6 ⋅a 7 )  =(a 1 )⋅(a 2 ⋅a 3 )⋅(a 4 ⋅a 5 ⋅a 6 ⋅a 7 )  . Here, a 1   = raw[1] a 2 ⋅a 3   = summary1[1] a 4 ⋅a 5 ⋅a 6 ⋅a 7   =  summary2[1] We can prove that at most two values from each array need to be  accessed, and since each summary cuts the size of the data in half,  there are O(logN)  summary arrays. This means our query  time will be O(logN)  . Update operations involve updating  just one entry in each summary array, so updates are  O(logN)  as well. What must be true of our binary function ⋅  to allow the above decomposition into chunks ("segments") to work? The key property is that it must be associative -- without that, we could not have split the evaluation into the chunks we wanted. Both the min  and +  functions are associative, so we can do subarray sums as well with this technique. Even things like querying the product of subsequences of matrices could be done with segment trees, because matrix multiplication is associative. Part 3 -- From Segment Tree to BIT The sum function has an additional property we can exploit, and here's where BITs come in. Consider what the summary arrays look like for [2, 5, 3, 5]: Raw: [2, 5, 3, 5] Summary1: [7, 8] Summary2: [15] But here, we have some redundant info. Because +  is an invertible function, we could know 8, for example, from knowing 15 and 7! From here, we get the idea to store the summary arrays in-place in the original array. For every two values we're summarizing, we will overwrite the second one with the summary value. For example, after we store summary1 in the raw data array, it looks like this: [2, 7, 3, 8], because 2+5 = 7 and 3+5 = 8. The original values of 5 and 5 can be recovered by doing 7-2 = 5 and 8-3 = 5. We then store summary2 in place as well, getting [2, 7, 3, 15]. 8 can be recovered by 15-7. This data structure is more space efficient, because while a segment tree required us to store N+N/2+N/4+...+1<2N  values, we store only N values with a BIT, no increase from what we needed to just store the raw input. Note that to make this optimization, we had to have an invertible operator in addition to the associativity requirement. min is not invertible and hence is not subject to the same optimization. Updated 7h ago • View Upvotes • Asked to answer by Anonymous