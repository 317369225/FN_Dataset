What kind of graph theory is used in automatic garbage collection? How is it used?
the typical thing is just a DFS or BFS - basic idea is to walk the stack, find all objects reachable from there, then look at all objects that are fields of those objects, etc. until you've found all the reachable objects; then clean up all that aren't reachable. Two basic schemes: - mark and sweep (search for all reachable objects & mark them, walk over all objects and deallocate those not marked as reachable - another scheme (forgeting the name) is after finding all reachable objects, to copy them to a new space of memory, rewrite all the pointers to them.  Then everything that was allocated in the old space - reachable or not - is considered free memory.  Of course, this doubles the amount of space required. Of course there are more complicated schemes, but mostly those involve doing things like reference counting to clean up obviously unreachable objects (has trouble with cyclic data structures), and general performance hacks like trying to do work incrementally, maybe even trying not to consider long-lived objects for reclamation as often but making cleaning up temporary objects simpler.  There are a lot of tradeoffs and generally it takes a lot of testing in real code to know if a garbage collection has any serious problems. Updated 27 Jun 2014 • View Upvotes