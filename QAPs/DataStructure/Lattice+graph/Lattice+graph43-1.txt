What are some cool possible applications of the D-Wave quantum computer?
The D-Wave processor can be programmed if you have a problem that is a quadratic unconstrained binary optimization problem (QUBO). Think about how many applications of quadratic programming there are out there. Going from general quadratic programs to QUBOs just requires that you represent your problem in terms of binary decision variables and that you represent any constraints as cost terms in your objective function. A collaboration between D-Wave and Google has shown that we can do ensemble learning with quantum computing. They have a bunch of binary classifiers and the problem is to decide which linear binary classifiers are to be used, and this is the training phase of the classifier. D-Wave has collaborated with many, many other groups as well. Lockheed-Martin has been working very closely with D-Wave to do software verification for testing their avionics software. A group of biochemists at Harvard have shown a rudimentary formulation of protein folding. The NASA side of the new Google-NASA-USRA quantum artificial intelligence lab put out a little cookbook manuscript a while ago that showed the following problems as QUBOs (taken from How can quantum computing be used in space exploration?): Classification for planetary feature detection (quantum boosting for binary classification) Anomaly detection for space systems (monitoring systems) Data fusion and image matching (for remote sensing) Mission planning Diagnostics (fault tree analysis) Unmanned autonomous exploration (multi-UAV task assignment) Multi-label classification General clustering schemes for pattern recognition I've also been working on this problem for the past few months for some AI problems. So far, I have QUBOs for the Hopfield neural network (kinda easy since it's derived from the Ising model), support vector machines, and correlation clustering. I also keep a little list of things that could also be solved with D-Wave processors and QUBOs. The NASA manuscript showed how one can simulate circuits as QUBOs. Feed-forward neural networks can be seen as a type of circuit, so it may be possible to make that leap. There is an iterative algorithm for solving linear systems called the conjugate gradient method which is almost a QUBO. Lattice-based cryptography relies on the hardness of finding what's called the "shortest vector" in a lattice, but that may be possible to formulate in QUBO form. Recently something caught my eye while reading my ML book, and it may be possible to find parameters of a hidden Markov model by formulating it as a QUBO. Matrix reordering/graph coloring is a pretty natural possibility as well. I'm also working on what's called the "task-placement problem", which is mapping a distributed program onto a supercomputer's nodes so that communication is minimal. It's a very important problem in high-performance computing. Geordie Rose, founder of D-Wave, runs a pretty active blog where he's shown that he can do sparse coding for deep learning with the D-Wave machine as well. I recently went to a talk about power engineering and smart grids. It was a little over my head, but it basically came down to a graph problem. It was a complicated problem, but it may be possible to write it down in the proper form. So there are a lot of possibilities. One thing that is important to note is that these are all ideas only at this stage! You may find a QUBO, but that doesn't mean anything. You could be doing it the stupidest way possible, or it might not ever be possible to solve your problem well as a QUBO. The D-Wave machine is not a universal adiabatic quantum computer, but even if you did have a general AQC your problem still may not have good time and/or space complexity. Space complexity is a very big deal because of the limited availability of qubits right now. It's not clear how well these systems will scale with thousands or millions of qubits, and if it's even possible. If we ever did get to that point, we still don't know how well specific problem instances will scale either. Updated 71w ago â€¢ View Upvotes