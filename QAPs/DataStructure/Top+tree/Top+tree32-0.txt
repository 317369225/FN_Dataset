What kind of tree algorithm is the best for implementing a random forest and why?
I assume that your question is about the algorithm used to build individual decision trees in random forest. I will focus on CART and C4.5, which are probably the most popular algorithms for building decision trees nowadays. For random forest, the difference in the predictive performance of these two algorithm is very small. When building a random forest, hundreds or even thousands of decision trees are trained with randomly selected training samples and features. According to No free lunch theorem, one algorithm can perform better for one set of randomly  selected training samples and features, but can perform worse with other  sets of training samples and features. Hence, the difference in individual decision trees is "evened out" in the end. However, when there are categorical features that have many levels, C4.5 is preferred. The run time of CART increases drastically due to the way it searches for split on categorical features. For example, for a categorical feature with [math]N[/math] levels, CART needs to search through [math]2^{N}-1[/math] combinations. Thus, even when [math]N[/math] is not very large, e.g., 30, the huge amount of combinations takes VERY long time to search through and also makes inference (almost) meaningless. 