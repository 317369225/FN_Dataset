Where's the productivity in dynamically typed languages?
It is even worse than what you describe when you consider coming into a large and complicated  dynamically-typed codebase in a professional context where developers come and go and the original developers aren't around anymore. I worked on a content ingestion pipeline at Amazon that was written predominantly in Perl. Can't go into details for NDA reasons but basically the pipeline had a bunch of stages in which various transformations were done on a very large and complicated glob of a data structure that was passed along from stage to stage. In a situation like this, in a dynamic language where any variable can be anything, any change that you want to make requires you to be sure that everything that preceded your change is not invalidating your assumptions about what the content is going to look like at the place at which you make the change. Basically, every bug fix and every addition of a little feature becomes a research project in which you examine every piece of code that touches the data that you are going to touch to make sure that something somewhere isn't doing something crazy in certain situations; e.g., if someone 2 years before you were involved had thought, well in this case I need such-and-such in stage #4 so let me just change this array to a hash in stage #2 and I'll test for a hash in stage #4. This is what is bad about dynamically typed languages. Now, let me answer your question though... First to dispense with the common platitude: most people say dynamic-ness is  good for small simple things since you don't get bogged down by a type system when all you want to do is read a file and spit out CSV or whatever. I've never understood this attitude. Doing simple things is easy in statically typed languages too. I think this attitude just reflects the general fact that many people working in Python, say, these days are no longer guaranteed to also be proficient in C++, et. al., as in the past; that is, yes, it's hard to do simple things in a statically typed language if you aren't that great at the statically-typed language to begin with. I actually think dynamically-typed languages are good for doing certain kinds of complicated things rather than simple things -- basically dynamically typed languages are good for writing complicated but self-contained programs quickly. Let me give an example. I have written parsers for one reason or another three times in my professional career. The first time (1) I wrote one in C and rolled my own because it just had to parse expressions and using any kind of library seemed like overkill. The second time (2) at another job I had to write a much bigger parser in Java for an algebraic modelling language and again rolled my own because, at the time anyway,  libraries/tools didn't exist in Java. The third time (3) I was doing consulting for the company I had worked for in (1) and had to extend that work to parse a whole Turing complete language in C++ and I used boost::spirit. On (2) the way I did it was recursive descent. Since it was Java instead of having a set of n mutually recursive functions that do the parsing I had a set of n mutually self-referential "parser objects" that did the parsing. The parser objects formed a hierarchy and at the top level had abstract semantics like "Parse a sequence using this list of child parser objects", "Parse a disjunction using this list of child parser objects", parse a literal, parse the Kleene star of this child parser, etc. etc. And then to actually construct the concrete parser you would inherit from these things and compose them according to the syntax of the particular language. Now, think about what the parse method of the parser objects has to look like in an imperative statically-typed language. The parse method obviously takes a position in a token stream as input but what does it return? Take, say, the sequence parser, it has a has-a relationship with a list of child parsers which it runs in sequence, all of which will have output of some type and then if they all succeed the parse method has to polymorphically return an object of the output type given the set of outputs from the child parsers. In Java, this output type pretty much has to be some really dumb and pointless abstract base class that application specific objects will then all have to inherit from -- this is because Java's generics suck so bad that you really don't have a choice. In C++ you have a richer system of generics, you have C++'s much vaunted template meta-programming so you can do something more interesting and don't have to require the user of the abstract parser library to represent the concrete parser's output as a composition of objects inheriting from a single pointless abstract class. Doing this with templates is extremely complicated, but it can be done, and in fact this is what boost::spirit actually is. boost::spirit is the template-metaprogramming project that I just described above (plus a lot more and with the OOP hierarchy removed even from the parser objects themselves, I believe) -- and it is also one of the most opaque pieces of code that I have ever seen. I wrote another parser a few weeks ago, which I describe here: Snurtle,etc. I wrote it in Python. In a dynamically-typed language this entire issue that I am talking about above just goes away. There is nothing here that needs to be thought about much less designed. I think the whole parser including all the infrastructure I am describing above, took a day to write. That is what is good about dynamically-typed languages, Updated 96w ago • View Upvotes