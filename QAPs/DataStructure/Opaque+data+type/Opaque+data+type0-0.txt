What databases or persistent stores are recommended for storing large streaming data, such as from sensors?
The systems that I have seen / worked on that operate at this scale and have this kind of requirement tend to be a good case for a hybrid approach. I would strongly recommend tee'ing or "fanning out" the data from a streaming collection / transport system to both a CEP[1] system for realtime analysis and to a system like Apache Hadoop for storage and batch analysis. Use a horizontally scaling system like Flume to collect  streaming data from the sensors. Have Flume split the stream, sending one stream to HDFS for storage and later analysis (with something like Apache Hive, Apache Pig, or other tools on top of MapReduce that easily deal with this scale of data) and send the second stream to your CEP system of choice. This split delivery deals with either system becoming temporarily unavailable or lagging behind the other (hint: it won't be HDFS). This gives you a realtime stream that the CEP system can churn on without impacting safe delivery of data for long term storage and processing. Further, you may find (problem space dependent) that your realtime analytics can survive with a statistically significant sample of the data, allowing you to trade accuracy for more complex realtime analysis (which usually results in slower processing) all without disrupting long term storage and analysis (of the complete dataset). A growing number of companies are doing exactly this in various industries with success and it allows for the benefits of both realtime and offline analysis. Full disclosure: I work for Cloudera (company) and make a living from helping people build stuff like this. I still think it's the right architecture for this problem space. Good luck. [1] CEP - Complex event processing Updated 150w ago • View Upvotes