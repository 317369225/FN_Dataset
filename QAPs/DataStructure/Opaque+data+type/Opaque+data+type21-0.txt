What does the concept of Universal Grammar mean?
Summary Universal grammar (UG) is a linguistic theory, proposed by Noam Chomsky, that argues that the ability to learn language is innate, distinctly human and distinct from all other aspects of human cognition. Evidence The theory is grounded in a number of important empirical observations. Child Language The first is that children learn language at an exceedingly rapid rate. If you have a child, you've seen this first hand: Something seems to happen at around 2, where they magically acquire a vast number of the rules and generalities of their native language without explicit instruction and with only a limited amount of  specific types of trial and error. This last point is important: It's been noted that children on make certain types of mistakes, but don't make others. For example, when learning do-support, which is when you take a sentence like: (1) He wants to go to school. And you make it a question: (2) Does he want to go to school? Children do not make the mistake of learning a "put do one spot to the left" rule and instead always learn a "put do at the beginning of a sentence" rule even when all their input satisfies both. Based on this, it's been argued that there are some grammars humans can learn and some grammar humans can't learn, regardless of the input. These constraints on what constitutes a possible human language are part of UG. Formal Learning Theory Related to this empirical finding is evidence from formal math based on Gold's theorem as described in this wiki on Poverty of the stimulus. The basic idea  is that the input that humans (or computational systems) get while learning language leaves open a wide range of different linguistic systems that could generate that very input (it may even be an infinite number of models - I don't recall). This is similar to the more general scientific challenge, the Inverse Problem (Inverse problem, What are inverse problems?), where a finite set of data will always allow for more than one possible underlying model. UG is the proposed way of limiting the set of models to precisely the right one that represents the language in question. Critical Period Back to child language learning, there is also something called a Critical period - you may be familiar with the notion if you've heard that children can only learn a language fluently before the age of X (e.g., 7 years of age). If there is some ability that children have, that then abruptly disappears without the disappearance of any other cognitive ability, then we need to define that ability. That ability seems to be distinct from everything else in the cognitive system and that is claimed to also be evidence for UG. Non-human language Furthermore, an argument from comparative biology: No matter how much input they get, and no matter how smart they are, animals never learn a language as complex as humans'. Some argue that this difference is simply quantitative -- bigger memories, more fine tuned articulators, greater ability to think abstractly -- but for those that believe there is a qualitative difference between human language and non-human primate language, birdsong or dolphin communication, there needs to be something unique about the human brain. That, too, is evidence for UG. Typology Finally, the last piece of evidence comes from linguistic typology, or the study of the properties of human languages and how they do and do not vary. Linguists, foremost among them Joseph Greenberg, have observed that languages pattern in in very specific ways. Also known as Implicational Universals (Linguistic universal), these observations are of the form, IF a language has property X, THEN it also has property Y. For example, if a language is Verb-Subject-Object (e.g., kicks she the ball), then it will have prepositions and not postpositions. Why should these universals exist? Again, UG answers this question: there are aspects of the language faculty or the language learning faculty that extract a whole set of linked rules from a limited amount of data. In the example above, once you learn the word order, the location of adpositions is given for free. Implementation I won't get into too much detail here, but there are a number of ways of representing or defining what UG actually is. The discussion above, on typology, is the basic motivation for Principles and parameters theory (I'm not personally clear on how much of this persists in the more current Minimalist program). It is mainly for syntax and it defines grammar is essentially a bunch of (binary) switches - verb before object or object before verb?; subject before verb or verb before subject? - that require a bit of data to set, and then your language is defined. So UG is manifested as an innate (nature) set of parameters that your experience with language (nurture) then sets. These switches may each control a few different things about language and because there are a finite number of ways grammar may vary, there are a finite number of parameters. On the phonology side of things (sound grammar), UG is instead instantiated via Optimality theory, where there are constraints instead, and each language ranks them differently. The constraints similarly limit the different types of possible languages that can be generated. The ideal is to define the UG list of constraints such that any possible language may be generated, but none of the impossible ones. I know I'm getting into the weeds here, but I hope a few of these facts on implementation makes things a little more clear, rather than opaque. History The background and history of UG is fascinating and well-worth a full book. Indeed, we can start pretty much at any point in the past couple hundred (thousand? the basic idea of UG supposedly dates back to at least the early middle ages and Roger Bacon) years of language study and construct a captivating narrative arc, incorporating many of the luminaries of linguistics, psychology, neuroscience and computer science,  culminating with the advent of modern UG. I'll start over 100 years ago....in Russia <CURTAIN OPENS> Pavlov: Yo, yo, yo, we can comprehend all ma shorties (animals) as complex systems of reflexes. B. F. Skinner: Totes, dude. Check out this rat that I can make ride a bicycle. Maybe peopes work the same way. I'll call it Radical Behaviorshizzle (Actually true -- the radical part, not the shizzle). Hebb: My friends, my friends, check it: Neurons that fire together, wire together. Skinner: That solves it! We figured out human language! It's just a bunch of neurons firing together in response to stimulus. Almost a The Blank Slate! Willard Van Orman Quine: Fo' shizzle Chomsky: Um.... Skinner: What is it Norm? Lenneberg: Well, real shorties can't learn language after a certain age, and they still have brains that learn other things. Greenberg: Yeah! And and and.... look at all these patterns. So many patterns. Montague: Also, too, I note that all human languages exhibit an underlying core of meaning. Zelig H.: And ya'll see this here thing? Called a com-pyu-ter. Like thisa one here? An FSM (not flying spaghetti monster, but Finite-state machine). There are a couple here things in language that these here computers can't learn. I can't reckon' it out. John Searle: Yeah, mon. And dose, what you call dem, connections. Dat ain't deep. Dat ain't real meaning. Chomsky: It just doesn't add up. People are people, so why should it be, that we would all learn languages dis-tinct-ly. Instead, I propose something called U.G. 'Cuz language is universal, like fa-mil-y. Fodor: And this UG of which you speak. I can see that it is a module (Modularity of mind). Lakoff, Bates, Ellman, Everett &c &c: Um... <CURTAIN> Okay, that was pretty bad, but hopefully gives a sense of the vast scope of people, ideas and fields that this encompasses. I could keep going on and on with the list of who has influenced and been influenced by the idea of UG. This now ends your short break from the dry technical stuff, which will now re-commence: The Strong Form of UG Although UG is generally associated with Chomsky's theory of linguistics there are actually a few ways the more general notion -- that the human brain is specially wired to learn human language -- may be manifested. The strong form, again, as espoused by Chomsky, has changed, too, over the years, but the general gist is that UG is supported by a language organ, a part of the brain specifically associated with language learning and language learning alone. It seems that that area is Broca's area and Chomsky et al. believe it does a few things. First, if we look at human language and animal language, the only real qualitative difference is recursion (Marc Ettlinger's answer to In what sense is the term "recursion" used in linguistics?). So, UG and Broca's is all about recursion. Chomsky has also reduced his theory of syntax to a single operation called Merge (linguistics). It's sort of a general cognitive function, but I believe that it's supposed to be part of UG, too. Everything else is domain general cognition, sensation, perception, etc. The Weak Form of UG One  of my pet peeves in grad school was when people said, "I don't believe  in UG." To me, that throws away the baby with the bathwater. You can have a UG without all the Chomskian baggage: In contrast with his more powerful language organ, there is also the idea of UG as a more general system of learning mechanisms, perceptual and articulatory abilities, and so on. There are clearly commonalities across languages that derive, in part, from who were are as human beings - this much is uncontroversial in linguistics. So, we can also articulate a weaker form of UG that stil isn't quite the radical behaviorist blank slate. For example, no language has a glottal Trill consonant. It just doesn't make sense based on our physiology - there's no way we could trill our glottis that is distinct from just vibrating it as voicing, which would just make it a vowel. This is an example of UG in the weak sense -- the idea that there are innate constraints on what human languages look like that are due to our physiology, cognitive abilities and brain structure (absent a language organ). There are obviously a lot more examples I could include, many of which highlight how great humans are at learning language as compared to other species. As expressive as Kanzi is and as wonderful it is to think of animals as being not that different from us, what they do will never be the same as what we do when it comes to language. Thus sum total of these differences -- that, too, is UG. However, this highlights what some of the opposing evidence is against Chomskian UG. Contra UG - The Doubters There are a few arguments against the notion for a UG of the type proposed by Chomsky and friends. First, there is the question of how specific it is to language, as opposed to a UG that is essentially a unique combination of existing human cognitive abilities, like hearing, motor control, memory, planning, etc. Basically, the contrary view to the strong form is that we can explain grammar learning through more general cognitive constraints and that it requires nothing that is specific to language. If you're into tech, you can think of this as the Google theory of human language -- that the brain is just a massive data processor that actually can generate the grammar of human language simply from statistical generalization plus a few constraints that lead to things like hierarchy. This is what the the pdp lab has been trying to show for decades, using Neural network. I call it the Google theory of human language because when you take a look at Google Translate, it does an amazing job of translating languages using nothing but massive corpora and stats. But as highlighted by the Chinese room thought experiment, would we really say that Google Translate understands what it's translating? A second objection is that human language isn't that different from complex animal communication. Check out this paper on dolphin syntax, for example: Cognitive skills in bottlenose dolphin communication. The argument here is that it's only a difference in degree, not a difference in kind - that the UG of human language is no different than the "UG" of animals, just with a souped up carburetor, so to speak: more memory, a more agile mouth, and so on. A third objection is that, in the short time span that humans have been using language (on the order of 100k years), there is no way for evolution to have produced a language organ, or anything like it. (h/t Frank Heile). As with the two objections above, the conclusion is that language must be parasitic or epiphenomenal of all the other human capabilities developed over a more evolutionarily appropriate times scale of hundred of thousands and millions of years. A final objection is that as interesting as the observed commonalities are across languages, they aren't that, well, universal. Indeed, pretty much every universal that's been identified (e.g., no language lacks CV syllables; every language uses recursion), some counter example has been found. There's Tashlhiyt Berber, the language with words without vowels, there's the infamous Piraha case of who-knows-what is going on there with syntax. If I could point to one thing I've learned from doing typology, it's that every language is special in some way. Like a snowflake. Or a child. Point being, instead of hard and fast universals, it seems that we need softer constraints, which lend themselves more to these quantitative generalizations rather than a symbol-using organ. Note, too, that each of the pieces of evidence above has its own counter-evidence (e.g., a sensitive period for learning language rather than a critical period symbolizing no hard and fast deadline for learning a language natively). With all these objections in mind, along with the evidence presented up front, I hope a clearer understanding of what UG is is starting to emerge for you. Just like the Nature versus nurture debates in psychology, the debate as to what, precisely is Universal Grammar and what is not Universal Grammar will be a persistent question and a persistent source of novel and interesting research. Indeed, many of the questions in linguistics touch on the notion of UG in one way or another. For example, of my own work (shameless plug alert), I've tried to show that one of these linguistic universals that are part of UG may help in the earliest stages of language learning as an aid to word segmentation: Ettlinger M., Finn A. S., Hudson Kam C. L. (2011). The effect of sonority on word segmentation: evidence for the use of a phonological universal. Cogn. Sci. 36, 655–673. http://faculty.wcas.northwestern... tl;dr: So, the concept of Universal Grammar refers to the idea that we humans have a little special something inside our heads and bodies that enables us to learn this amazingly complex system we call language. It's something that we humans all share (Universal) but that we share with no other species and is specific to language itself (Grammar). Updated 86w ago • View Upvotes • Asked to answer by Adriana Heguy