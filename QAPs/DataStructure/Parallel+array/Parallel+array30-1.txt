Are all O(n) algorithms "Embarrassingly parallel"?
Generally not. Martijn de Vos points out that finding the maximum of a list is O(n) and that parallelism doesn't reduce the work done. It is possible to reduce the clock time for max of a list using parallelism, but you have to use a lot of processors. With at least n/k processors, the time becomes O(lg n): split the list into k element chunks and assign each chunk to a processor each processor finds the max of the k (or fewer) numbers it has (this is O(1) because it's determined only by k) half the processors hand off their result to the processor immediate before them and exit, and the other half repeat the preceding step (a tree reduction) using their own result and the result from their neighbor that just exited. After lg(n) reductions, the one remaining processor has the maximum.This still does O(n) operations, but it does it in O(lg n) clock time using n/k processors. This makes it an O(n lg n) algorithm in terms of total steps, which is actually worse than simply iterating the list. But, if you have enough processors, it's "faster" on the clock. Traditional raytracing (forward or backwards) is an example of an embarrassingly parallel task, because each ray traced is completely independent of the others and the only work the reduction step has to do is simply to serialize the independent results of each subtask. Such tasks will see a clock speedup factor of k (or nearly k) with k processors. 