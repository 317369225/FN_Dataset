What is the fastest algorithm to find the largest number in an unsorted array with multiple processors?
So here's an answer that you won't find in CLRS: It depends on your filesystem. Let's say that you have a Sequoia-class system with ~93k compute nodes and 1.5M cores.  Total DRAM available is 1.6 petabytes, so let's assume our array is at least that big and is sitting out on a disk somewhere waiting to be read in. Now let's assume we've screwed up and put the array on an NFS filesysem that's effectively serial.  The rate at which we can walk the array in DRAM is much, much faster than the rate we can get data off of the drive, so there's no point at all in using any more than a single core on a single node.  If we use a ridiculously overprovisioned filesystem (and network) we can have a read head per node and zero network contention.  If you want an exact answer, that's as fast as you can get it. In a more realistic machine you're going to have some number of parallel streams that is much, much smaller than the total number of processor cores.  Once you've maxed out those streams, adding more cores isn't going to make this run any faster. This problem is a nice example of the problem of data motion.  It takes a lot of time and energy to get bits into a processor core, and if all you're going to be doing there is one comparison and maybe one write, you have a massively inefficient machine.  The nature of the problem changes completely if the array is generated on the fly and each item in the array takes some number of milliseconds to generate.  Now you can put a million processor cores to good use. 