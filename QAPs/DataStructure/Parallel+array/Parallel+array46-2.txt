Will the first conscious AI be a distributed system or a single processor?
Nearly all current AI applications are implemented in a parallel way, now (except for consumer-grade stuff) -- basically, if it's an application of AI tech and it's sitting on a server somewhere instead of sitting on a dedicated hardware device, it's taking advantage of hardware parallelism. Hell, if you buy a new consumer-grade computer, it's very unlikely to be single-core anymore (unless it's a phone). There's a caveat here, though. There isn't really a business case for conscious AI -- conscious AI is an ethical bag of worms, in addition to being pragmatically inferior in every way to non-conscious AI (after all, solving the hard problem means you have taken a lot of time and money to produce something roughly equivalent to a person, and early models will not be economically preferable to what we already have -- an extremely inexpensive 2-kilogram sentient computer that runs on sugar and has the consistency of jello, which will happily work for ten or twenty dollars an hour for forty hours a week). There's an academic case against attempting genuine AI as well (see above, regarding ethics). So, somebody creating a genuine AI will probably be either outside the system (a brilliant programmer or group of programmers who are essentially unemployed), a renegade on the fringes of the system (somebody like Douglas Hofstadter, who has tenure and some funding to study consciousness, but who isn't really subject to much oversight because a lot of people think he's been barking up the wrong tree since the 70s), or someone who has gotten to the top fairly independently and doesn't care about the business case (if Sergey Brin left Google randomly and used all his time and money to persue the project on his own). Two out of these three scenarios involve limited funding, leading to limited hardware. 