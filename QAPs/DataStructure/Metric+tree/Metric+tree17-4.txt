What are the advantages of different classification algorithms?
It wasn't mentioned in the question, but Random Forests should almost always be considered and at least tried as well. Lately, I've seen SVMs and Logistic Regression picked over these by many of my acquaintances involved in machine learning (I'm guessing this has a lot to do with Random Forests not being brought up in Andrew Ng's excellent Machine Learning class on Coursera), but to me this is a mistake. Random Forests: 1. Almost always have lower classification error and better f-scores than decision trees. 2. Almost always perform as well as or better than SVMs, but are far easier for humans to understand. 3. Deal really well with uneven data sets that have missing variables. 4. Give you a really good idea of which features in your data set are the most important for free. 5. Generally train faster than SVMs (though this obviously depends on your implementation). More info at Random forests - classification description 