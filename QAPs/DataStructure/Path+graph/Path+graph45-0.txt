How does one implement Facebook Graph Search?
Facebook has an inherent advantage for implementing this type of architecture. Each person's profile is their own data partition and a scheduled reoccurring process, similar to a search crawler, becomes distributed per user in a network of servers similar to Google's MapReduce technology. The massively parallel computational power required for processing the relational data of more than one-billion Facebook users is calculated by a group of researchers and scientists who are responsible for determining the resource provisions, in terms of cost per unit, needed to safely meet the stringent performance requirements. Data centers around the world are acquired and resources are provisioned by calculating the compute demand for those geographic regions. As the per-user graphing processes extract a user's data from the membership system-of-record, it is transformed according to business rules outlined in the product requirements. For years Facebook has been working on its innovative "Graph API" technology which is outlined in the Facebook developer documentation. The semantic function of a search in the graph determines the template structure of the query, which is specific to the 'Action' and 'Object' types that are detailed in the developer reference. "Find friends who like apples" This natural language statement is reduced to a template query "{Aggregation:FRIENDS}->{Action:LIKE}->{Object:APPLES}" A set of pattern identifiers are predetermined using the semantic query language RegEx, which breaks down the natural language query into a template expression that resembles a path. Graph data architectures are based on the composition and dimension of linear paths. Those paths can be computed well in advance and scheduled based on master logistical resource provisioning. The logistical models have already been created in the parcel delivery industry and most likely Facebook would have paralleled their content logistics methodology to that industry (if not, then they should think about it). The navigation technology that was tailored for the parcel delivery industry is a very similar network graph of inter-connected nodes. The master planning and provisioning systems create and update route plans in real-time according to feedback and data collection out in the field. Probability and demand for parcels delivered to a clustered geographic region enable the logistical planning required to pre-compute the optimal path required to meet timing requirements of each package. By computing the possible paths in advance to a search query, each path can be cached and the results can be prefetched and delivered near instantaneously to the geographic region of the user's primary location. The transformed data sets for each user's profile are distributed as shards to facebook's worldwide data centers, letting you access that data optimally from anywhere in the world. Logging of performance utilization outlines possible deficiencies in the provisioning projections and models are constantly updated to ensure high availability without downtime. Ranking of search results is proprietary and usually a well-guarded  trade secret. Mark Zuckerberg outlined generally how result rank is  determined in the product reveal event. Relevancy weights would be  assigned by clustering users according to their mutual friends. By doing  this you can build a community graph in addition to a profile graph.  Denser clusters of friends gauge more relevant results, with blocking  conditions being applied to filter out the outliers, in order to keep  things tightly relevant. While I am just theoretically outlining how Facebook's graph search might work, I have no actual knowledge of their implementation. 