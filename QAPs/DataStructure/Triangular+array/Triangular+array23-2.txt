Suppose A is an NxN matrix whose entries are independent random variables with mean 0 and variance σ^2. What is the mean and variance of X = det(A)?
Think about this for a two by two matrix. If [math] A = \begin{bmatrix} a & b \\ c & d \end{bmatrix} [/math] where a, b, c, d are random variables as you describe, then [math] |A| = ad - bc [/math] Independence off all variables leads to [math] E(|A|) = E(ad - bc) = E(a) E(d) - E(b)E(c) = 0 [/math] (as Michael's clever proof shows: that approach did not come to me). The formula which expresses a determinant as a sum of products of elements could be used to generalize this, but you could also, now that the case for n = 2 is done, use induction and apply expansion of a determinant by a minor for the general case (note: I have not gone to that step, but it seems reasonable). For a product: note that for products of arbitrary independent variables we have (probably longer than needed work but worth seeing, I think) [math] \begin{align*}V(X_1 \cdots X_n) & = E((X_1 X_2 \cdots X_n)^2) - \left(E(X_1 X_2 \cdots X_n)\right)^2 \\ & = E(\prod_{i=1}^n {X_i^2}) -\prod_{i=1}^n \left(E(X_i)\right)^2 \\ & = \prod_{i=1}^n E(X_i^2) - \prod_{i=1}^n \left(E_i)\right)^2 \\ & = \prod_{i=1}^n \left(\sigma^2_i + \mu_i^2\right) - \prod_{i=1}^n {\mu_i^2} \end{align*} [/math] For r.v.s with zero mean and identical variance this simplifies to [math] \sigma^{2n} [/math] So, for the two by two case (and remembering a, b, c, d are independent) [math] \begin{align*} V(|A|) & = V(ad - bc) \\ & = V(ad) + V(bc) \tag{by independence}  \\  & = a^4 + a^4 = 2a ^4 \tag{Use the above result}  \end{align*}[/math] The problem, in my opinion, comes for larger matrices. If you have  [math] A = \begin{bmatrix} a & b & c \\ d & e & f \\ g & h & i \end{bmatrix} [/math] when you expand the determinant across the first row (which as good as any other), the summands will no longer be independent: if we use row 1 [math] |A| = a |A_{11}| - b| A_{12}| + c |A_{13}| [/math] and since this gives [math] \begin{align*} A & = \begin{bmatrix} a & b & c \\ d & e & f \\ g & h & i \end{bmatrix} \\ |A| & = a \left|\begin{bmatrix} e & f \\ h & i \end{bmatrix} \right|  - b \left|\begin{bmatrix} d & f \\ g & i \end{bmatrix} \right| + c \left| \begin{bmatrix} d & e \\ g & h \end{bmatrix} \right| \end{align*} [/math] you can see that covariance calculations need to be taken into account. (It probably isn't impossible, but it is more effort than I care to put forth right now. Hope something of this helps.) 