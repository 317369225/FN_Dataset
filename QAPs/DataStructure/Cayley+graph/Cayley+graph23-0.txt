What are interesting characteristics of graph databases that would incline you to buy one product as oposed to any other?I am refering to query language, high performance, good optimisation technology, out of core capabilities, administration tools, etc.
I don't know that there is any particular characteristic of the product which would incline me to buy one over another. I haven't worked professionally with any graph databases.  I suspect that some of the places where I've worked have had people performing graph queries through their SQL and some of their NoSQL databases; but none of those have made a compelling case for evaluation, let alone adoption, of a specialized graph DB system. That said I if I were tasked with such an evaluation my inclinations would be driven by the project's requirements, the development teams expertise and biases, my perceptions of the operational implications, and any management constraints (such as funding --- direct licensing cost, probability that we'd need to engage vendor professional services, and indirect TCO ... such as hosting or equipment costs). In other words it's not the characteristics of the products that drive my recommendations. The first question I would pose to the stakeholders in such a scenario would be: "RDF or generalized graph?" See Graph database and follow it's link to "tripestore" (mostly RDF) for the background on that question. It's possible that this is a false dichotomy.  But it seems worth asking that question to see what sorts of requirements and biases emerge as we clarify the question.  Is this project focused on creating an ontology (a relatively simple list of entity:attribute:value relationships) or is it more concerned with querying and traversing types of relationships over distances (social networking, for example). My next question would depend on what emerged from the first.  If the needs seemed like they might be satisfied by an RDF framework then I'd ask if we could do some sort of quick (perhaps disposable) prototype in RDFLib/rdflib (Python).  Otherwise I'd probably suggest trying Neo4j (Java, with numerous client APIs). Note that these suggestions are just starting points ... picked from the tables in those Wikipedia articles because I've heard about, and read about, those two products in the past.  In actuality we'd go through the tables and consider them down the line. The stakeholders would be challenged to find any other comparison charts or features lists, search for Slideshare and other presentations to advocate any alternatives which intrigued them as well as any "devil's advocate" presentations, 'blog, forum, or message threads to convince us not to waste time on the "default" product I've suggested. In their favor RDFlib and Neo4j are free, readily available, and seem to have minimal operations overhead on a small scale.  So, if those turn out to be sufficient for the project then we all win.  The trick is to ensure that the team can implement enough of a prototype with a sufficiently minimal investment of time and effort to learn some things that will be useful for the project as a whole. An advantage of Neo4j in this case is that it's used fairly widely ... so there should be plenty of available expertise for the long run if that is adopted. (As I was writing this I was able to install Neo4j on my Linode  by simply pasting in a sequence of just four commands into a shell  (Neo4j Debian Packages) and then running the neo4j-shell command and pasting in several examples from: - The Neo4j Manual v2.1.3 to confirm that it was working). 