What are interesting characteristics of graph databases that would incline you to buy one product as oposed to any other?I am refering to query language, high performance, good optimisation technology, out of core capabilities, administration tools, etc.
Honestly, graph databases reflect the insights and biases of their creators as well as the purpose they're intended for. My own bias is pro-semantic and pro RDF/OWL/SPARQL because I think solid data integration can't be done in a vacuum without domain modeling and a focus on semantic interoperability. There are ways to do domain modeling and tagging efficiently at enterprise scale with the help of crowdsourcing and  NLP assisted tagging. Now that being said, we have seen mostly non-semantic NoSQL databases deliver benefits via a lightweight data model, schema on read and an ad-hoc, data scientist approach to do just a bit of disambiguation for light integration. To my mind, that approach is warranted when the scope of your effort is necessarily narrow and the data are perishable and don't warrant any more careful structuring than that. Commercially, I've seen two camps--those who mainly ignore the W3C semantic web standards and go their own route on the more perishable side of the data continuum, and those who embrace the standards or at least pick and choose from them. Most developers tend to be in the former camp, which is why tools like Neo4j and Titan are popular. They are focused on solving tactical problems. I don't say that to disparage them--it's a very practical focus they have. Librarians, word wonks, data modelers and businesspeople who are open to semantics to solve thorny problems like enterprise-wide data integration or enterprise search are in the latter camp. Some of the most successful efforts along these lines have been in scalable knowledge graph or knowledge base development.  That's hard work that requires risk taking, leadership commitment and a thoughtful, informed approach, but it's where the relevance payoff is and the opportunity to blend "content" with numerically based data. Many people who work on knowledge graphs license RDF triple and quad stores once they get serious, and the triple and quad store vendors do a lot of training and consulting as a part of what they offer. Google Cayley is a recent open source graph database that's been designed with knowledge graph purpose in mind, and Google's been posting knowledge graph training videos. Most who are experimenting with databases are unaware what's happened with knowledge graphs and how they've been applied in publishing, ecommerce catalogs, libraries and information sharing environments generally in knowledge-intensive organizations. If you read the case studies at the triple and quad store vendor sites or take a look at my Semantic Web answers on Quora (https://www.quora.com/content?topic=2604&content_types=answers), you'll see the extent of these efforts. Most enterprise IT folks outside of KM lack an appreciation or awareness of what's being done here, but it is significant. The next phase of the knowledge graph should leverage social networking, and to my mind, the best social networking tools are based on rich graphs or RDF stores. There just aren't enough people who understand how to build relevant, interoperable, heterogeneous systems or have any interest in semantics, but social networking functionality and crowdsourced modeling and assisted tagging should be at the core of what's being called cognitive computing. That's the only way to incorporate a sufficient amount of human input into a machine-assisted process. 