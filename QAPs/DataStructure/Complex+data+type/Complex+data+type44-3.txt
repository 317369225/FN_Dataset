How does a computer distinguish a number and a letter or a string? I mean, let's say we have a bit sequence like 11110100 in anywhere in the memory. How does a computer know if it is a number or a string or a letter?
The computer itself doesn't really know. What does know, it knows from a cooperation between the programmer and the compiler or interpreter and the rest of the data on the machine. All the numbers in a computer are only symbols because something is also keeping track of what they mean. The programmer tells the compiler to use the numbers in the computer in a specific way when they write the program. It's up to the compiler, interpreter and programmer to keep track. On a basic level, the machine itself has a language to the numbers that it understands. At some level, all programs depend on the computer using that language to keep all the numbers available, keep track of where in the program it is, and know what it needs to do to change the numbers. Programmers build systems on top of the machine language which let them build more complex systems. Beyond that, all the programs are programs built on top of programs all the way up to what you see the computer do. 