What are the design, implementation and real world use/experience differences between Parquet, ORC and Trevni?There seems to be a rise of new file formats around the Hadoop ecosystem.  What are the strengths and weaknesses of each?  Why is everyone creating their own new format?  How are they better or worse than the historically popular RCFile?
I personally think all the column formats are a bit obtuse. I usually do not see much better compression or performance then a row orientated format, it takes considerable effort to columnar-ize your data. It seems like a few camps are pushing OCR and a few Trevni. It mostly boils down to AVRO/THRIFT/PROTOBUF wars, once people lock in on something they tend to care about the performance slightly less. After all once you make a company wide decision to use X, your more of less stuck with it for ever, then you end up copy-catting what you do not have in the public domain for the Y and Z products. IE hive-protobuf was inspired by hive-avro support. 