Computer Graphics: Are modern game engines threats to traditional renderers?
First, and most obviously, game engines and offline renderers are optimized for different radically different levels of complexity and programmability in the input geometry, textures, and shaders. Graceful degradation under extreme loads is a central concern in offline renderers because extreme loads on one axis or another are the rule not the exception in offline production. In games, artists expect to test and iterate on their content to keep it under the complexity budget afforded by the engine and hardware, while in offline production you only need to squeeze your final shot through the pipeline once before you move on. For this reason, while real-time content steadily improves in quality, the differences in geometry, texture, lighting and shading complexity can still be orders of magnitude. But beyond these and other reasons, game engines and offline renderers take input at very different levels of abstraction. Game engines are effectively scene graph APIs, which must be given high-level descriptions of objects and materials, in the model defined by the engine designer. The most successful offline rendering APIs—especially the RenderMan interface (RI)—are simpler, low-level representations akin to immediate mode real-time rendering interfaces like OpenGL and Direct3D, or PostScript. There is a long history of generic or universal scene graph APIs struggling to find adoption. The problem is not that scene graphs are bad, but that there are too many of them already—most existing tools and production pipelines will already have their own—and translating from one to another is far more awkward and problematic than translating from a scene graph down to a simpler, immediate mode-style representation like raw OpenGL, Direct3D, or RI. In these lower-level representations, the input is distilled down to a simple set of buckets of primitives, and the state under which they are to be drawn, including transformations and shaders. The shader APIs are also simpler and more primitive and composable—"given any point, what color should it appear to be" and "given any vertex, how should it be displaced"—than in a game engine, where the engine has its own semantics for how transformations are handled, how skinning and other deformations are performed, and how passes are composed together to create different shading effects (and therefore what can be done in each of these stages). In this way, game engines will struggle to find adoption in higher-end production not just because of limited feature sets or optimization for different complexities of input, but also because they require their input to be translated to a level of abstraction which is awkward at the end of a complex existing pipeline of other tools. 