What are the difficulties of implementing a physical based rendering engine like pbrt using ray tracing on GPU?
Well, one renderer that PBRT implements that was originally designed for GPUs (albeit a GPU from 1997 where fixed function pipelines were the only choice) is instant radiosity.  This involves a potentially lengthy pre-bake step to generate all the virtual point lights, but it is technically unbiased until you introduce little hacks to deal with certain artifacts.  There isn't a very large class of BSDFs that work very well with a small number of VPLs though and render time is linear with the number of VPLs.  You're essentially stuck with things that are close to Lambertian and if you have any purely specular interfaces, you still have to trace through the scene until you hit a diffuse surface.  The extension that seems fairly popular to handle more interesting materials is to generate an enormous set of VPLs and then apply something like LightCuts to determine which VPLs should be used to compute contributions for certain parts of the scene with little perceptual error.  This makes it biased as well though. There are works where people have ported MLT methods to the GPU.  PBRT implements Keleman-style sampling for this purpose.  One big issue is the time required to compute several reflections or transmissions for the entire path.  I have no idea how tools like OptiX scale for this purpose, but I think at its core, it is the tool to solve these problems. The new Unreal engine uses what they call sparse voxel octree global illumination.  The relevant citation is http://maverick.inria.fr/Publica....  I have not read it yet, so I can't answer any questions. I did not know about dynamic parallelism until you mentioned it, but, yes, this does seem directly applicable to the problem at hand due to its recursive nature.  It seems like this doesn't solve the problem of divergence though.  Basically, paths will terminate at different times.  If you look at it recursively or flatten it out to make it iterative, both involve kernels that will diverge, unless you use fractional absorption and group paths of length N together into the same kernel (which doesn't use dynamic parallelism in the end...or at least not in the way I'm thinking about it).  I suspect OptiX solves these problems for you though, but once again, I don't know how well. 