Is it okay for a beginner to take a lot of time to implement advanced data structures such as AVL trees or 2-3 trees? Frequently asked inRecently I tried to write a program involving AVL tree and I I took a lot of time. Though solved it eventually, I got frustrated because of time I took.
Yes, it's absolutely okay. In the beginning. If it took you, like, three hours to implement AVL first time, no worries. But if it takes hour after third time, you should look closely and understand why does it happen. I doubt that AVL implementation is enormous, so typing speed is probably not an issue. So, what can be the issue? Lack of understanding of what is going on. For example, if you have to memorize code lines or brute force which one works correctly, there is something wrong. Ideally, you should be able to instantly draw an illustration to any procedure you're writing. It's especially true for rotations - if you cannot show me what is the difference between big and small right rotations, you're gonna have a bad time implementing it. Cure: try to get better intuition about the algorithm you're implementing Bad architecture. Yes, I know that we are talking about classical algorithms, which are, like, 100 lines of code. And yes, I still insist that architecture here is very important. You should get rid of code duplication, use symmetry whenever possible and so on. No corner cases, very straightforward code, tons of assertions for all invariants - that's the kind of code that you have a chance to write bug-free (or debug fast). Reduce amount of code which require thinking. If you can implement something in terms of calling another functions - do it. E.g. there is no need to implement big rotation independently - big rotation can be expressed as two small rotations. Two lines of code instead of god knows how many. Additionally, you get another chance to check your small rotation: if it's wrong, there is a good chance that your big rotation will be wrong as well. More bugs in the program, higher chances spotting one of them. Lack of language knowledge, which can result in unnecessary boilerplate. For example, C++ has references and typedefs, which are very useful. You usually do not need to take pointer to something as a function argument - it's either output parameter (and you can make it reference in that case) or it's always passed as a pointer (and you can typedef it). Of course, there are cons for using references, but I don't think they apply to short algorithm implementations, which are fully performed by yourself. Let me give you an example. I want to insert value into binary search tree and do not care about balancing at all. Straightforward implementation can look like: void insert(node v, int value) { if (v->x < value) { if (!v->l) { v->l = new node(value); } else { insert(v->l, value); } } else { if (!v->r) { v->r = new node(value); } else { insert(v->r, value); } } }   node root = nullptr; void insertToTree(int value) { if (!root) { root = new node(value); } else { insert(root, value); } } God, that's a lot. And we have a lot of duplication, which looks necessary at first sight: we definitely have all the cases like 'tree is empty' and so on. It also looks essential for 'insert' to take existing node as a parameter. I'll get rid of this assumption and make 'insert' more general: now it can insert into empty tree too: void insert(node &v, int value) { if (!v) { v = new node(value); return; } if (v->x < value) { insert(v->l, value); } else { insert(v->r, value); } }   node root = nullptr; void insertToTree(int value) { insert(root, value); } That's much better. No duplication, two 'if' statements only, and there is single point of failure: 'insert' itself. Yes, SPOF is better than no-SPOF in algorithms, imho. Last, but not least issue I would like to recall is theoreical-oriented understanding. When you are trying to explain or prove something, it's often easier to split the problem into several cases and look at each one independently. Moreover, in theory we are free to do anything that does not affect asymptotics. No matter how hard this 'anything' is. Say, in some problems we can rid of duplicates in advance, in other problems we can assume that coordinates are from 1 to N. If you blindly follow these directions, you will get a lot of code, which ensures that all assumptions are correct. Which can be useless, because algorithm itself will correctly work even without some of original assumptions. They were here just to make the overall explanation and proof simpler. If you look closely at the code, you can find out that these some snippets look alike, this snippet can be replaced by standard 'lower_bound' with customized comparator, these extra case is handled correctly by following code because of... reasons (which are usually hard to explain theoretically without any code), and there is no need to handle is separately. By the way, both AVL and 2-3 has a lot of corner cases, afaik. I don't know how to implement them fast. Take a look at Treap (Wiki, Codeforces) if you need some self-adjusting binary tree and you really want to implement it itself - it's very straightforward and powerful. 