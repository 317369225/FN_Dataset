What are the difficulties of implementing a physical based rendering engine like pbrt using ray tracing on GPU?
Divergence and Occupancy are the main issues. Divergence is when different threads on the GPU want to do different things (roughly). In a raytracer there are many sources of divergency, even neighbouring rays can hit different surfaces, traverse space differently, and then at each hit be scattered differently, require different code to evaluate the materials of the surfaces they hit and so on. Occupancy is how many threads you can fit in a computational unit on the GPU (roughly). As a GPU hides stalls by switching threads if you have few threads you can't hide stalls well and things slow down. Techniques that require lots of information or state to work per ray/path are ill suited for GPU. That's why most GPU ray-tracing based renderers are simple path tracers, path tracing doesn't require as much state as bidirectional PT or MLT where you need to always keep the full path, not just the front ray and some accumulated values, in order to do connections and mutations. Of course both technical issues spawned a lot of research and algorithms around them, but fundamentally these are the main differences from a CPU raytracer. Another one is access to RAM, CPUs usually have more Ram and virtual memory so they can handle larger scenes, but that's something it's changing with GPUs looking increasingly like CPU on that regard. Last note, CPU raytracing also gets "hit" by divergence as it kills caches and CPUs also like to use vectors, but as their vectors are much less wide than GPU ones, it's less of an issue. 