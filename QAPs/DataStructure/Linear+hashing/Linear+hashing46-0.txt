What algorithm did you derive that you're most proud of?
Various line sweeps When there is a time series of entries coming in some order, one can introduce a sliding window of the past X minutes (or Y entries). Each entry is then split into two events: "appeared" and "left the window". A lot of statistics can be later computed based on just these two events. The code that computes the statistics is window-length-agnostic and thus can be branched out. Ref.: https://github.com/dkorolev/marv... Percentiles can be linearly combined Historically, statistic-based features are performing well. For example, "Does this airline ticket price belong to top 10% of observed in the past month" for airfare price prediction project we've been working on in Bing. It occurred to me that percentile is just a ratio of counters, and counters can be accumulated. In other words, if there are multiple dimensions: say, time frame ("one week") and the price (in dollars), the percentile of numbers falling under each simple curve on this plane can be easily computed using the inclusionâ€“exclusion principle with relatively little preprocessing and RAM requirements. Consistent hashing for load balancing. In Google I've solved a "hard" problem by sharding the load via consistent hashing. Each worker would figure out by itself whether certain entry belongs to itself and whether it should be processed. All it required was a distributed locksystem for notifications and a way to reliably tell which workers are currently live. Obviously, I'm not the person who invented it. But I did not know this idea has already been used for distributed filesystems when arguing why it is best to be applied to that practical problem we had. 