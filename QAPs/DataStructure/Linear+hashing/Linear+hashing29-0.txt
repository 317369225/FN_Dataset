In layman's terms, how does "compress, hash and displace (CHD)" perfect hashing algorithm work?
What is a hash table? A hash table is particular data structure that supports one major operation* - given a value, a hash table allows you to query whether or not the table contains that value (i.e., it implements a mathematical set). There are many ways to implement such a structure, but the basic idea behind most implementations is the roughly same. Given a value [math]x[/math] to query, a hash function [math]h[/math] is used to transform it into an hash value [math]h(x)[/math], which is a small non-negative integer. This hash value is used as an index into an array. In a perfect scenario (see next section) the value [math]x[/math] will be at this location in the array if and only if it is present in the hash table. For most hash table algorithms, things are not so simple, and there are additional steps to determine whether [math]x[/math] is in the hash table (see collision resolution). *Many implementations also allow you to insert values into the hash table (rather than requiring all values be presented as the table is constructed), and to delete values from the hash table. What is perfect hashing? For a given set [math]S[/math] of values, a hash function [math]h[/math] is said to be perfect if [math]h[/math] transforms every value in [math]S[/math] into a distinct integer. Equivalently, [math]h[/math] has no collisions. Perfect hash functions are important because hash tables that use perfect hash functions can be implemented as I described earlier, each value in the hash table can be stored at the index of its hash value. What is the CHD perfect hashing algorithm? Note: For the following I will omit all of the math involved in the analysis. For the proper treatment, see the actual paper. The description of the algorithm given there is not actually that hard to understand. The CHD perfect hashing algorithm describes an algorithm for building a hash function. The actual algorithm for hashing is as described above, simply apply the hash function and index into an array. Given a set [math]S[/math] of [math]n[/math] elements and an integer [math]m > n[/math], the CHD perfect hashing algorithm for constructing a hash function works as follows. An integer [math]r[/math] and a hash function [math]g[/math] are chosen where [math]g[/math] transforms values into non-negative integers less than [math]r[/math]. This hash function may map multiple values in [math]S[/math] to the same hash value, that's ok. A universal family [math]U[/math] of hash functions [math]f_1, f_2, f_3, \dots[/math] is chosen that transform values into non-negative integers less than [math]m[/math]. Roughly speaking, a universal family of hash functions is a sequence of randomly chosen hash functions that have no discernible relationship to each other (i.e., they're independent). // This will end up being our array of elementslet table be an empty array with m slots// This structure will end up describing our hash functionlet indices be an empty array with r slots// This is used for book-keeping. What hash values have we already used?let used_values be an empty setfor i = 0 to r-1  let bucket = the subset of S that g transforms into i  for j = 1 to infinity    let values be the set that results from applying f_j to the elements of bucket    if |values| = |bucket| and (values and used_values are disjoint)      for x in bucket        set table[f_j(x)] = x      add all elements of values to used_values      set indices[i] = j      goto end_loop  label: end_loop// This is our actual hash function.define f(x) =  let i = g(x)  let j = indices[i]  return f_j(x) Essentially, for each "bucket" of values that [math]g[/math] maps to the same hash value, we pick one of our hash functions [math]f_j[/math]. Our final hash function [math]f[/math] maps to the same values as [math]f_j[/math] on the inputs in that bucket. We choose the particular hash functions [math]f_j[/math] so that we'll end up with no collisions. It turns out that when you do this properly (instead of going through the buckets from [math]i = 0 \text{ to } r-1[/math], you should go in descending order by size of the bucket), this algorithm takes linear time. Furthermore, the indices of the hash functions you use end up being very small and are easy to store in a compressed format. 