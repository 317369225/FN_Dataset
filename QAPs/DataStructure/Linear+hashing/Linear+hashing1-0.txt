Can mmap() guarantee the data integrity on crash, if I store data chunks in 1/n of Linux PAGE_SIZE? or disk block size?
That's what msync is for. See: http://linux.die.net/man/2/msync You'll want to periodically sync on your log (which, if you're using a log structured on disk format, can be the data structure itself), to ensure that you can restore up to the last N transactions from the log. Note: I highly suggest not rolling your own on-disk data format and using something like BerkeleyDB or embedded InnoDB, which have had decades of software and QA engineering work. Basho's bitcask is another good alternative. It looks like a B+Tree (which BerkeleyDB, InnoDB are) or linear hashing (Bitcask) already solve your problem well. 