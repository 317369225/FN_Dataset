What is the best way to computationally estimate cardinality of very large sets?
I've done quite a bit of work on cardinality estimation for my last job and my employer was good enough to release the java library I wrote as an open source project.Â  Take a look at: https://github.com/oby1/mainstream. It currently includes implementations of Linear Counting, LogLog Counting, and Adaptive Counting, along with simple to use factories that choose the right algorithm depending on the expected cardinality of your data stream. To my knowledge, it is the only open source implementation of several of the online data stream estimation algorithms that is both thoroughly tested and in live use in large scale production applications. 