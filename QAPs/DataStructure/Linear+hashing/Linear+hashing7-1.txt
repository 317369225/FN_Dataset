What is the best way to computationally estimate cardinality of very large sets?
Only adding implementations story to Erik 's answer as he mentioned at the bottom of his answer Using an auxiliary memory of m units (typically, “short bytes”), HYPERLOGLOG  algorithm performs a single pass over the data and produces an estimate of the cardinality such that the relative accuracy (the standard error) is typically about [math]\frac{1.04}{\sqrt {m}}[/math]. This improves on the best previously known cardinality estimator, LOGLOG, whose accuracy can be matched by consuming only 64% of the original memory. For instance, the new algorithm makes it possible to estimate cardinalities well beyond [math]10^9[/math] with a typical accuracy of 2% while using a memory of only 1.5 kilobytes. The algorithm parallelizes optimally and adapts to the sliding window mode. HyperLogLog takes advantage of the randomized distribution of bits from hashing functions in order to estimate how many things you would’ve needed to see in order to experience a specific phenomenon. Source and examples below[1] It is well known that the cardinality of a large data set can be precisely calculated if the storage complexity is proportional to the number of elements in the data set. Requirements it addresses:  Given the scale and complexity of some Druid data sets (with record counts routinely in the billions), the data ensemble is often far too large to be kept in core memory. Furthermore, because Druid data sets can be arbitrarily queried with varying time granularities and filter sets, we needed the ability to estimate dimension cardinalities on the fly across multiple granular buckets. [1] Fast, Cheap, and 98% Right: Cardinality Estimation for Big Data http://algo.inria.fr/flajolet/Pu... 