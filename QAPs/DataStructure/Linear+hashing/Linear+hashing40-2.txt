Which data stream mining tools can handle Big Data?
DarkStar was built from the ground up for data stream mining.  And is currently being deployed in an environment to deal with over 3,000,000,000 messages a day. Yahoo's S4 takes the Hadoop paradigm and makes it event driven.  You may find that of interest. Contrary to popular belief, it's actually easier to do a lot of machine learning kinds of things on streams - it can be done in real time.  I spend a lot of my day focusing on exactly those types of issues.  For some insight, check out Jeff Jonas's blog jeffjonas.typepad.com. DarkStar, unlike S4 or DataSift (mentioned above), is a general purpose, distributed engine that incorporates 4 very important things: 1) Time Windows - the ability to look for things, or calculate aggregates, within time or length based windows.  Like, 'what is the average price of IBM over the last 10 minutes. 2) Pattern Matching - (not regular expressions) - the ability to describe a sequence of events, like, "Tell me when a user tweets about airplanes, but only after another user tweeted about 9/11 and only if the tweets are within 5 minutes of each other. 3) Continuous Query - once a query is submitted for evaluation, the results are returned continuously until you're not interested in that query any longer. 4) A Language - it's nice to have a language to tie all of this together.  Some products have simple DSL's that facilitate this, some don't.  DarkStar implements a Turing complete language for the manipulation of streaming data. There's a lot of research in this area - look for information/books on sensor networks.  You'll find the more advanced concepts described there with discussions about real implementations.  There's a lot of work coming out of Portugal lately. One interesting offering is Knime.  Or Weka.  You may be able to cobble something together using components from either of those offerings. This is an exciting area of research and application. 