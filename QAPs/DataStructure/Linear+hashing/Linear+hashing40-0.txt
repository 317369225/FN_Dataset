Which data stream mining tools can handle Big Data?
Ok, I think some sorting is necessary to sift through the different answers here. First of all, as Olivier Grisel has correctly pointed out, there exist quite a few online versions of algorithms like clustering and classification which can naturally work with data streams. Stochastic gradient descent automatically works with data streams, for example. Probably the difference between using SGD on large data sets and on data streams is that data streams can be non-stationary and you need ways to deal with that. Here is pretty good tutorial on this topic: ECMLPKDD12 Advanced Topics on Data Stream Mining There exist open source projects which implement this kind of algorithms, for example MOA - Massive Online Analysis http://moa.cs.waikato.ac.nz/ or RapidMiner http://rapid-i.com Â  Then there are software frameworks for scaling stream processing applications like Yahoo's S4 http://incubator.apache.org/s4/) or Twitter's Storm (http://storm-project.net/). But these are generally purpose frameworks which no built-in support for machine learning. You would have to do a fair amount of coding to make those work for you. Apache Flume is again a different piece of software which helps you to pipe stream data into a Hadoop cluster. But after that, you'd have to use a more batch oriented MapReduce approach to learn, so it's probably not sufficiently real-time. Complex Event Processing tools is another approach, which is basically something like SQL for stream data. But the focus is more on extracting statistics like running averages from your data, less on advanced machine learning. Finally, I'd also like to mention http://streamdrill.com, a real-time event analysis project I'm working on which let's you efficiently aggregate event activities over large item spaces efficiently. You can then build adaptive ML methods based on these statiatics, something we're working on right now. 