What is it like to do research in randomized algorithms?
I thought the research was difficult, but eventually one gets the hang of it (sort of, or at least leaves with an okay understanding, but then again, I'm not even in high school). I found out how useful randomized algorithms are and most of their application. Randomness, I learned, has proven itself to be a useful resource for developing efficient algorithms and protocols. As a result, the study of randomized algorithms has become a major research topic in recent years. My course explored a collection of techniques for effectively using randomization and for analyzing randomized algorithms, as well as examples from a variety of settings and problem areas. We covered: Basic concepts: probabilistic inequalities, the minimax principle, limited independence. Random walks: cover times, markov chains, resistive networks, mixing rates. Randomized approximation algorithms Hashing Linear-time minimum spanning trees and fast algorithms for minimum cuts Use of randomness in checking/verification Randomness in protocols Expander graphs, amplifying randomness. Randomized algorithms in machine learning. Number-theoretic algorithms On-line algorithms. Beyond randomness - quantum computation. I do programming on my robotics team, and we usually just stick to C, but from time to time I take online undergrad courses which involve research topics and various applicable tasks. I hope this helps! Live long and prosper! 