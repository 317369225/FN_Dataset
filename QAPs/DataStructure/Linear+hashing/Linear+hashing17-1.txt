What are some good resources for learning about dimensionality reduction? Why?
One could list a lot of seminal papers given the fundamental importance and breadth of this area. But in case you are looking for something that is 1. Holistic 2. Surveys a lot of literature in the area (and hence lists those important papers on KPCA, Eigenmaps etc etc) 3. Draws connections between these basic methods. This might be useful if you are new to the area and lack that broad view that might come with more experience. then I would highly recommend this survey by Chris J. C. Burges which was published asÂ  Foundations and Trends in Machine Learning volume: Dimension Reduction: A Guided Tour PDF here: http://research.microsoft.com/pu... But ofcourse there are many things that it misses. One of the many things - The use of Deep Neural Nets for non-linear dimensionality reduction. One example is the science paper by Ruslan Salakhutdinov and Geoff Hinton: http://www.cs.toronto.edu/~hinto... and the many other related methods using auto-encoders etc. These are in my humble opinion more useful (for atleast the task of dimensionality reduction) than many of the more famous methods such as Laplacian Eigenmaps, LLE, ISOMAP etc to which there is no straightforward out-of-sample extension (using Nystrom doesn't work well enough in my opinion). 