Linear Algebra: What techniques are used to optimize multiplication of very large matrices?
The first part of getting a efficient matrix-matrix multiplication is to have it efficient on a single processor. Now we need to distinguish between dense and sparse matrices. Sparse matrices are very hard to optimize: they are basically bound by the memory bandwidth. For dense matrices your can be clever. The best known algorithm was developed by Kazushige Goto and Robert van de Geijn. It optimizes for cache and TLB reuse and runs at a very high percentage of peak performance of a processor. Page on utexas.eduIf your matrix is large enough that it needs multiple processors, you then have to worry about parallel layout. Again some cases: For a dense matrix you can prove that you need to make a 2D partitioning. High performance linear algebra For sparse matrices from PDEs you can make a similar argument, but about the domain of definition of the PDE. Irregular sparse matrices, for instance from graph problems, need to be treated as a dense matrix where parallelism is concerned; the code local to each processor is sparse however. 