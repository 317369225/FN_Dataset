Given a volume consisting of a number of locations within a defined 3-dimensional space, and each of these locations is assigned some number, is there some obvious metric that can be applied that measures the complexity of the distribution of the measurements?
What you've described is a scalar field (I  think, at least that's what it sounds like you've described). A scalar  field is a single-valued function over space: f(x,y,z)  . There  are different ways to define the "complexity" of the distribution, so  you're going to have to more precisely define what you mean. Information entropy and Kolmogorov complexity are two such definitions. Neither can be computed exactly, but both are  approximated by standard data compression algorithms--the lower the complexity, the higher the degree of compression achieved. You can try  serializing your data and then applying a standard string compression  algorithm, or you can try looking at 3D point cloud compression algorithms, of which there are many. For example, Point cloud attribute compression with graph transform would be appropriate for sparse data that tend to lie on surfaces or  lines, whereas Out-of-core compression and decompression of large n-dimensional scalar fields would be more appropriate for dense data. 