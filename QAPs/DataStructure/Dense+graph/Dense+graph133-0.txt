What is the modularity of a community assignment on a graph or network? Why is it useful?
TL;DR: Modularity is a metric that quantifies the quality of an assignment of nodes to communities by evaluating how much more densely connected the nodes within a community are compared to how connected they would be, on average, in a suitably defined random network. Many algorithms for identifying communities in networks work by trying to optimize modularity. These algorithms have proven to be useful in analyzing networks in a variety of disciplines. However, researchers have also identified some conceptual and practical difficulties with interpreting the communities identified by modularity maximization. Long version: The rest of this answer is mostly quoted from a longer answer that I wrote about the Louvain Method of community detection. I've just made some minor edits and additions so that this makes sense outside of the context of that longer answer: Definition of Modularity One popular class of community detection algorithms seeks to optimize the so-called modularity of the community assignment. Modularity is a metric that was proposed by Newman and Girvan in reference [1]. It quantifies the quality of a community assignment by measuring how much more dense the connections are within communities compared to what they would be in a particular type of random network. There are two mathematical definitions of modularity that you'll frequently encounter. The first is the one used in the original paper on the Louvain method [2]: Q=12m ∑ i,j [A ij −k i k j 2m ]δ(c i ,c j )  Here, A  is the usual adjacency matrix, k i =∑ j A ij   is the total link weight penetrating node i  , and m=12 ∑ i,j A ij   is the total link weight in the network overall. The Kronecker delta δ(c i ,c j )  is 1  when nodes i  and j  are assigned to the same community and 0  otherwise. Consider one of the terms in the sum. Remember that k i   is the total link weight penetrating node i  , and note that k j 2m   is the average fraction of this weight that would be assigned to node j  , if node i  assigned its link weight randomly to other nodes in proportion to their own link weights. Then, A ij −k i k j 2m   measures how strongly nodes i  and j  are in the real network, compared to how strongly connected we would expect them to be in a random network of the type described above. The other definition of modularity that you'll see is the one proposed in the paper by Newman and Girvan [1]. They defined a matrix (let's call it B  , though Newman and Girvan used the symbol e  ), where B c 1 c 2    denotes the fraction of all edge weight in the network that connects community c 1   to community c 2   . They also defined W c 1  =∑ c 2  B c 1 c 2    as the total edge weight penetrating community c 1   . Then, they defined the modularity as: Q=∑ c [B cc −W 2 c ]  It's pretty easy to show that this definition is equivalent to the one from the first, but I won't write out the steps here. Modularity Optimization Algorithms Returning to the first definition of modularity above, the problem of modularity optimization can be thought of as assigning communities such that the elements of the sum that contribute are as positive as possible (remember that the delta function kills terms in the sum corresponding to pairs of nodes that belong to different communities). The problem is that you can have situations where it makes sense to put nodes 1  and 2  in the same community and to put 2  and 3  in the same community, but where A 13 −k 1 k 3 2m   is very negative, indicating that nodes 1  and 3  really shouldn't be in the same community. This is a simple example of a kind of frustration that makes the modularity optimization problem really hard. Indeed, the modularity optimization problem is actually NP-hard, and that has motivated searches for heuristic approaches that typically do a good job at finding high modularity community assignments with more scalable complexity. The modularity maximization algorithms that I'm aware of typically fall into one the following categories [2]:    agglomerative: where you iteratively group nodes into communities divisive: where you progressively remove links from the network, and the depleted network reveals good community assignments simulated annealing: where you introduce an artificial "temperature" and perform Metropolis-like Monte Carlo updates while gradually lowering the temperature. Here, you take −Q  to be the energy function for the system. The proposed moves can consist of both agglomerative and divisive steps [4] spectral: where an eigenvector of the so-called modularity matrix encodes the community structure.You can read about one popular modularity maximization algorithm, the Louvain method, in reference [2] or in my Quora answer on the method. My answer also includes a quick description of the original divisive method proposed by Newman and Girvan in reference [1]. You can read about other modularity maximization algorithms in references [3], [4], and [5]. Possible Pitfalls of Modularity Maximization Modularity optimization algorithms have found wide application across many domains. However, fundamental problems with these algorithms have also been identified. To close out this answer, I want to discuss some of these difficulties. Here's a quick introduction to two: The "resolution" limit: Modularity maximization is known to have trouble detecting small communities in large networks. My answer on the Louvain method contains an example of how modularity optimization ends up merging small communities into larger ones that are less reflective of the true underlying community structure. The "degeneracy" problem: There are typically an exponentially large (in network size) number of community assignments with modularities close to the maximum. This can be a severe problem because, in the presence of a large number of high modularity solutions, it's (a) hard to find the global maximum and (b) difficult to determine if the global maximum is truly more scientifically important than local maxima that achieve similar modularity. Good et al. showed that the different locally optimal community assignments can have quite different structural properties.These problems are discussed and studied at length in reference [6]. The authors of that paper concluded with this cautionary note about modularity maximization: "...modules identified through modularity maximization should be treated with caution in all but the most straightforward cases. That is, if the network is relatively small and contains only a few non-hierarchical and non-overlapping modular structures, the degeneracy problem is less severe and modularity maximization methods are likely to perform well. In other cases, modularity maximization can only provide a rough sketch of some parts of a network's modular organization." References [1] M.E.J. Newman and M. Girvan. Finding and evaluating community structure in networks. Phys. Rev. E. 69: 026113 (2004). [2] V.D. Blondel et al. Fast unfolding of communities in large networks. J. Stat. Mech. P10008 (2008). [3] A. Clauset, M.E.J. Newman, and C. Moore. Finding community structure in very large networks. Phys. Rev. E 70, 066111 (2004). [4] P. Pons and M. Latapy. Computing communities in large networks using random walks. Journal of Graph Algorithms and Applications. 10: 191 (2006). [5] K. Wakita and T. Tsurami. Finding Community Structure in Mega-scale Social Networks. arXiv: 0702048 (2007). [6] B.H. Good,  Y-A de Montjove, A. Clauset. The performance of modularity maximization in practical contexts. Phys. Rev. E 81, 046106 (2010). 