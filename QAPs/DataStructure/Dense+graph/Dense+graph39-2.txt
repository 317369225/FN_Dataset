Graph Theory: What's the intuition behind a Laplacian matrix?
L=D−W is referred to as the combinatorial or unnormalized graph Laplacian.Whereas  D −12  (D−W)D −12    is identical to the Laplacian of a graph Δ:H(V)→H(V)  [1],which is expressed as : Δϕ:=−12 div(grad(ϕ)   −div is defined to be the adjoint of the graph gradient. Note that laplace operator is also dot product of gradient and divergence of a field [ that explains the primary  name] .However,divergence and gradient are formulated differently here, than flux/volume at a point and direction of fastest growth, [2],as, unlike a field, the flow of ϕ  does not happen throughout the volume the encloses the graph. The divergence(div) here , measures the net outflow of the  function ϕ  at each vertex[3]and the norm of the graph gradient(grad) here , measures the roughness of a function around a vertex, and the p-Dirichlet form the roughness of a function over the graph. Whereas , the eigenvalues of the lapalacian of the graph tell the number of spanning trees that exist within the graph and how well connected a graph is among other aspects that become of interest in specific cases.e.g.It turns out to be better than Gaussian elimination when solving Ax=b [balance condition of flow], in terms of computational complexity. If we assume the vertices of a graph are sampled from some distribution, then the combinatorial graph Laplacian does not converge to the usual Laplacian when the sampling size goes to infinity unless the distribution is uniform [1]H(V)  denotes the Hilbert space of real-valued functions endowed with the usual inner product. [2]As detailed in Page on Microsoft [3]Note that if ϕ  is symmetric, then (div(ϕ))(v)=0for all v∈V  