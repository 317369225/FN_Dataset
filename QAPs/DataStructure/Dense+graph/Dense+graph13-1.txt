Is O(n^2) the lower limit for any graph algorithm using an adjacency matrix as the DS?
Any graph property that depends on the existence or non-existence of all the edges in the graph, or any constant fraction of the edges in the graph, will require Ω(|V| 2 )  time to perform on a graph represented in an adjacency matrix. Informally, if an algorithm claims to decide such a property in o(|V| 2 )  time, then it could only have examined o(|V| 2 )  of the entries in the adjacency matrix. We could design two graphs that are the same at these entries, but one has the property and one does not, guaranteeing that the algorithm will answer incorrectly for one of the graphs. For example, graph connectivity is a global property that depends on every possible edge in the graph. If an algorithm does not examine some entry of the adjacency matrix, say the entry for an edge between vertex 3 and 7, then we can design one input that contains two connected components separating 3 and 7, and another that is the same, but with an edge between 3 and 7. The first graph is disconnected and the second is connected, but the algorithm will either accept or reject both inputs because it cannot distinguish them. This is why adjacency matrices are usually used for representing dense graphs (those with Ω(|V| 2 )  edges). On such graphs, |V|+|E|=Θ(|V| 2 )  , so adjacency matrices can be as efficient, asymptotically, as other representations. 