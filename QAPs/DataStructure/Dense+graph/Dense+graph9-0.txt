What is the threshold of queue size at which a Fibonacci Heap becomes a good priority queue?Fibonacci Heaps provide a great asymptotic time complexity for a priority queue implementation but they are hard to implement and have poor time constants.  Ignoring the annoyance of implementation, at what point is a Fibonacci heap a better priority queue than other heap implementations?
Despite their elegance in theory, I haven't yet found any situation where Fibonacci heaps help in practice.  If anyone else has, please provide details as I'd love to see such an application. In terms of theoretical running time, Fibonacci heaps only help if you do many decrease-key operations.  If you are just using standard priority queue operations like insert and remove-min, it doesn't make any sense to go with a Fibonacci heap.  Perhaps the most common situation involving many decrease-key operations is Dijkstra's shortest path algorithm on an n-node, m-edge graph, which runs in O(m + nlog n) time using a Fibonacci heap but O(m log n) time using a standard binary heap.  For this difference to be noticeable at all, especially given the extra overhead associated with a Fibonacci heap, you need a very large and also very dense graph.  Unfortunately, nearly every large graph in the real world is also quite sparse.  I've never been able to find or create a single example graph on which the Fibonacci heap implementation wins.  For example, you might try running Dijkstra on a fully-dense random graph that is "implicitly" created by choosing random edge weights (allowing you to make n quite large, since you never need to actually write down the edge weights), but even then, you can prove that due to the use of randomization, Dijkstra with a standard binary heap takes O(m + nlog^2 n) expected time, making it still generally win on running time in practice. 