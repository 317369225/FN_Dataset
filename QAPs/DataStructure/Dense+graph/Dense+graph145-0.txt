How important is machine learning to what Palantir is doing?I've seen video demos and played with Analyze the US, but can't tell if machine learning is important to or even applied at Palantir. Palantir looks to me like a graph exploration software. Isn't it?
In Matt's earlier answer to this question, he wrote that “Palantir doesn’t do much ML…yet.” That was true in late 2012, but things have changed. As the company has grown and expanded into new domains, machine learning has become absolutely central to the work Palantir is doing with many of its biggest customers. As a member of Palantir’s machine learning team, I wanted to write an updated answer that sheds some light on how and why Palantir is concentrating and scaling its machine learning capabilities. The primary driver of Palantir’s focus on machine learning is its expanded footprint at commercial enterprises. These businesses are trying to discover creative new ways to leverage their existing data to: Generate new streams of revenue Improve operations Protect themselves against risk In many cases, the customer’s existing data was not collected for any of these three purposes. (Much of an organization’s useful data is simply a byproduct of specific business operations—what we sometimes call “data exhaust.”) And in all cases the problems themselves are fundamentally ambiguous—there are no straightforward, fully automate-able ways to monetize transactional data, diagnose supply chain inefficiencies, or identify and stop fraud, insider threats, or unauthorized activity (e.g., rogue trading).   Palantir has found that machine learning methods are especially effective at removing friction between business stakeholders, users of our products, and their data. When the friction is gone, our customers can more easily use their data to realize new business outcomes.   We are actively building machine learning capabilities into our core products, as well as deploying these enhancements against problems in health care, law enforcement, and other areas.   Connecting top-down and bottom-up analysisPalantir’s customers know they have a lot of micro-level data that they haven’t tapped. They want to leverage it to tackle macro-level problems. But it’s not always obvious what the “right” level of granularity is for an underspecified problem. Should a user be looking at entities? Categories? Clusters? In highly ambiguous contexts such as these, users need a way to identify patterns of local relationships, trends, or anomalies that have some meaningful global consequence. The question isn’t “Do we want top-down or bottom-up analysis?” but “What’s the right resolution for this problem?”—and in some cases “Just what is the problem, anyway?”   Machine learning provides ways to identify and surface structure at various resolutions in a unified way. By unifying analysis on multiple levels, it becomes easier for analysts to quickly scope out a problem, identify possible factors of interest, and estimate what the RoI of tackling the problem might be.   This is especially valuable to us in the face of dynamic use cases or adaptive adversaries, where analytical unification via machine learning gives analysts the flexibility and dexterity to work with their data in evolving ways.   Lead generationAs my colleague Yael wrote in her answer to “How will you improve the Palantir Gotham platform?, ” automated and semi-automated analysis is becoming a more important area of focus for our product team. In particular, automated lead generation is now a major component of many use cases, such as detecting healthcare provider fraud or unauthorized trading. Here, semisupervised learning works alongside rule-based business logic to triage data and event streams, pointing analysts towards known-suspicious behavior, anomalies, and unexpected change points.   From a product perspective, lead generation allows analysts to focus their attention on a manageable set of high-signal data so they can cover more ground quickly. Over time, collected explicit and implicit feedback both improves the lead generator and enriches the data.   We’re still never going to make a “find terrorist” button, but it’s becoming much easier to use machine learning for lead generation—to build a “find suspicious bank transfers” button that surfaces suspicious cases for further investigation by human experts.   Integrating legacy dataIntegrating disparate data into a unified analytic environment is a critical first step to deriving insights from it. But data integration is especially difficult when customers are trying to leverage their legacy data—including their “data exhaust”—against novel problems. Higher impedance between the dataset and the use case makes data integration more complex.   For example, one of our customers is a retailer that wanted to optimize its inventory to improve its demand forecasting and reduce wastage by using insights from its sales data. This data comes from a database designed for sales transaction record keeping, so information critical to the problem (e.g. which shipment an item was a part of, an item’s expiry date) is often missing or sparsely documented. Useful metadata, such as the product categorization hierarchy, were modeled in a way that was optimized for procurement rather than demand forecasting.   In situations like this, machine learning can help in several ways.   Entity resolution and data enrichment: We use machine learning to perform entity resolution, which allows us to jointly leverage multiple datasets that weren’t designed to be joined, construct canonical identifiers based on noisy information, and identify natural hierarchy. Entity resolution not only facilitates better integration of existing data, it can also enrich existing data with new datasets or algorithmically inferred structure and characteristics. In some cases, automated entity resolution even helps us detect and fix errors in source data, like when a record with missing/incorrect/out of date information is correctly resolved with another record containing the right information.   We only employ automated entity resolution, however, where it’s appropriate (e.g., when some false positives are acceptable). Whenever the costs of false positives are intolerably high, as is often the case in the public sector, users review and resolve entities manually.   Value Interpretation: Customers often want to integrate data into Palantir, but are missing adequate documentation on the meanings and types of each field. This can be problematic—an arbitrary integer field with a cryptic name could be a code (categorical variable), a rounded continuous value (e.g., monetary amount), a count, an identifier, a phone number, a postal code, or something else. Until its true type is de-obfuscated, the data can’t be correctly identified and used by higher-level logic.   While humans are good at recognizing possible meanings of data, machine learning helps us perform value interpretation at scale. The result is that users can get off the ground with less upfront effort.   What makes machine learning at Palantir differentThis section is my shameless plug to anyone who’s read this far.   As an engineer on our machine learning team, I get to work with new kinds of data on a regular basis across a variety of domains. I personally have worked on problems in health care, consumer credit, law enforcement, insurance, energy, and more, and each customer’s data and perceived use case is different.   To me, this is an opportunity to find structural similarities among many superficially different problems, and develop algorithms and tools for solving the underlying problems. This also enables some amount of rigor—anything we develop can be assessed and refined in multiple environments with different datasets and assumptions.   I also see this as an opportunity to add value quickly. Our customers are some of the most significant institutions in the world, and we are exposed to their most critical data problems. Most of our customers have never successfully deployed effective machine learning at scale before, so our initial efforts often make a big difference.   If you’re interested in learning more about what we do, feel free to ask here or shoot me a message.   Our team is relatively small, but we’re actively hiring. If our work sounds interesting and you’re up to the challenge, we’d love to talk. You can apply/submit your resume here. Updated 7 Jun 2014 • View Upvotes