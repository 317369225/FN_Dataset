How is the size of a hash table determined? How should optimization be done for it to be fast?
It sounds like you have a general idea about the characteristics of data you're going to be storing in your hash table. Given this information, if you want to optimize for this data set, you should write your program using different sizes for the hash table, time the implementations, and pick the fastest one. You have a large-ish data set, so maybe start testing in intervals of a couple thousand. You should get a nice inverse-bell curve. Find the data point that's lowest on that graph (lower time = better performance) and "zoom in" on that region, using smaller intervals of a couple hundr... (more)