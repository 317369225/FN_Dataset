Why do array indices start with 0 (zero) in many programming languages?Arrays starting at zero have nothing to do with hardware representation of arrays. It has to do with math operators. I'll try to illustrate this by making actual computations to access an array element. Assume you wanna make a Sudoku solver. To do that, you have to handle rows and columns computations, but also 3x3 regions in a 9x9 array. Assume you want to identify a 3x3 region by its upper left corner (lowest row index, lowest column index). Now the value in the upper left corner of the 3x3 region is accessed like this: Array[ x / 3 ][y / 3]; //array starts at 0 or Array[ (x / 3) + 1 ][(y / 3) + 1]; //array starts at 1 This is because, as you surely know, the integer division operator truncates the result so that it outputs an integer, for example: 1/2 = 0. Now you want to do the same kind of access, but you're not sure that x is contained within the boundaries of the array (let's switch to a 1-dimensional array): Array[ (x % length) / 3 ]; //array starts at 0 or Array[ ( ((x % length)+1)/ 3) + 1 ]; //array starts at 1 Which one do you think is easier to read? Starting arrays at 0 can also sometimes make things easier when you try to think of how the physical memory is handled, and surely that may be another reason why C does it. However as much as I love C (and I really do), it's not the only language out there, and higher-level languages such as Java or Go also starts their arrays at 0. Arrays often start at 0 in programming languages to make index computation compatible with "high-level" mathematic (at least basic arithmetics) operators. 