What is the fastest algorithm to find the largest number in an unsorted array?While Ken Alverson's answer about parallel answers is probably the best algorithmic answer, and Tim Farage's answer is probably the most literal interpretation of the question.... let me give the most pragmatic answer. Why pragmatic? Because I'm in operations and I actually live in the real world. In the real world I can perform this search in zero seconds, or even a negative amount of time. In your career, you will never actually come across the need to do this kind of search in total isolation. Algorithms don't exist on their own. They are used in the real world. The real world involves processes, people and teams. There will always be some externalities (seemingly unrelated stuff) that you can leverage (take advantage of) to get better results than either Ken's or Tim's answers. Some examples from my career as a system administrator: 1. The list of numbers will be small and any algorithm will be "good enough". "Small" in today's world could be a 10 million integers. You'd be amazed at how fast a modern Intel processor can loop through 10 million integers. If you only need to do this search once per day, that amount of time will be insignificant. STOP WORRYING ABOUT SPEED UNTIL YOU KNOW IT IS A PROBLEM! O(N) might just be fine I can't tell you how many times people have come to me saying "we need a BIG DATA EXPERT" and after some discussion I learn that their "big" is only 10G of data. I can load 10G of data into the RAM of a Dell server that I can buy on the credit limit of one of my credit cards. 2. The search can be hidden by doing it in the background. If the search takes too long, see if you can get the array earlier in the process so you can do the search in the background. Maybe there is a title screen to be displayed, or a user interface to render. Can you get the array before that is rendered so you can sort in the background? Look at the big picture and ask all involved how early you can get the list. I was once in a situation where the array was available at T+4 and we had it sorted by T+6. A developer improved the algorithm and now we had the data at T+5. I got access to the array at T+0 and had the data ready at T+1. That's like having a timemachine compared to the v1.0 software! 3. Don't search at all! As you are building the list, keep track of the largest value you see. Now you know the largest number in O(zero). Go talk to the person and demand that they do this. If they won't budge, talk to their manager. What fucking passive-aggressive asshole is asking you for the largest value in THEIR data anyway? Oh, they can't maintain a "largest value" variable because they're also doing deletes and updates to the list? Ha! If you are, then they shouldn't be storing it in an unsorted array because those updates will be better if they use ANY OTHER data structure; and any other data structure will have a way to find the largest value more efficiently than O(N). 4. Take advantage of repetition. Yes, the first time you see the list you might have to default to a linear O(N) search. However the data doesn't disappear after that. It is probably used for other things, updated, and revised. After those changes you need to find the largest value again. There are a slew of opportunities here. Can the updates be tracked for "biggest value"? Is the data later put into a tree or sorted? Do you need the exact answer or can you use an estimate based on past data, improving the guess with each repetition? I once saw a process with 5 steps. Each step was done by different team. Each team began by sorting the data. If the first team sorted the data and retained the sorted data for future teams, the time spent sorting would have been improved 5x! OMG IT REQUIRED PEOPLE FROM ONE TEAM TO TALK TO PEOPLE OF ANOTHER TEAM! OH THE HORROR! PLEASE PLEASE! DON'T MAKE ME BE A HUMAN! I WANT TO BE A CODER THAT LIVES IN ISOLATION! No you don't. You want to be a human that lives in a community that develops awesome processes that are driven by software. So if this question was a homework assignment... the answer is O(N): do a linear search through the list and examine every single item. If this question is an honest request... put down the keyboard. Get off your ass and walk down the hall. Talk to all the people that are involved and figure out what real need is and re-examine whether the "largest value" is actually needed, how it is needed, and whether the entire process can be improved by looking at it end-to-end. Get out of your silo. Talk to people. You'll always get better results. Update: 5. I once was in a situation where it turned out the max() was needed to allocate memory. Why not allocate the amount based on the last time you had a similar dataset and grow/shrink the memory allocation when done? Turns out, the max value was a constant, so by asking the question the programmer came up with an entirely different way to do things. 6. Find out if a LATER step needs the data in sorted order. Volunteer to sort it at your step so that you can get the max value by simply picking the last element. Now the algorithm is O(n log2 n) [or whatever] which is bigger than O(n), but the entire system is faster. 90.9k Views  View Upvotes