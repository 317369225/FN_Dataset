How do I find sum of all subsets of a range in an array?Given an array A of N elements and Q queries of type [ l, r ]. Print the sum of each subset in the range { A[l], A[r] }. For example: A[]= { 1, 2, 3, 4 } and [ l,r ]= [ 1, 3 ] then print sum( 1 ), sum ( 2 ), sum( 3 ), sum( 1,2 ), sum( 1,3 ), sum( 2,3 ), sum( 1,2,3 )This question best fits the application of Segement Trees imho. It runs in time complexity of lgN per query and space complexity of O(N). So,if you have to perform M queries on this array of size N, then it will run in O(MlgN). EDIT: Finally, if you have to find the summation of all the subsets in a range, then you can find the total sum of the range and multiply that with the number of times an index will be present amongst the subset(s) of the range. The reason for multiplying is as follows: if we have to sum every subset, then any index in that range will present equal number of times. I leave it to you now, to find the total number of times an index will be counted amongst all the subsets of the range(as I'm a little occupied at the moment and am unable to get that now :p ). The problem with doing it with dp is, is that it will run in O(N^2) time complexity, as well as the same space complexity. Binary Indexed trees too can be used, but I generally find that to be an overkill even in most competitive coding challenges. Do check out this excellent blog for learning more on segement trees: A simple approach to segment trees 938 Views  View Upvotes