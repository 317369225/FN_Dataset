Why is it problematic that JavaScript arrays are implemented as hash tables?
I suppose you mean the fact that arrays are semantically hash tables that just happen to have integers as keys? Well, this would mean they still have O(1) access, but that's a larger "1" than the one that is just some integer math and a bounds check. There would also be the amortized cost of resizing and rehashing, whereas AFAIK normal Java arrays have a fixed size. But the reality is that this is true only for sparse arrays: console.time('sparse write');var sparse = [];for (var i = 0; i < 100000; i++) {    sparse[i * 100] = 1;}console.timeEnd('sparse write');console.time('sparse read');var sum = 0;for (var i = 0; i < 100000; i++) {    sum += sparse[i * 100];}console.timeEnd('sparse read');console.time('dense write');var dense = [];for (var i = 0; i < 100000; i++) {    dense[i * 1] = 1;}console.timeEnd('dense write');console.time('dense read');var sum = 0;for (var i = 0; i < 100000; i++) {    sum += dense[i * 1];}console.timeEnd('dense read'); On my computer this results in: sparse write: timer startedsparse write: 119.1mssparse read: timer startedsparse read: 20.54msdense write: timer starteddense write: 2.23msdense read: timer starteddense read: 1.38ms More on Performance Tips for JavaScript in V8 - HTML5 Rocks 