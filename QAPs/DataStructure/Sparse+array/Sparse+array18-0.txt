JavaScript (programming language): Are Javascript functions like map(), reduce() and filter() already optimized for traversing array?
It depends on the VM. They are as optimised as any other code in v8, the difference is that the algorithm used by map(), reduce(), and friends is very different from the for loop most people use for iterating arrays, because people ignore that arrays in JavaScript can have holes (i.e.: any array can be sparse, so its length does not reflect the number of elements that array has). Why isn't Array.prototype.filter() fast? As an example, let's look at v8's implementation of Array.prototype.filter, which is implemented in JavaScript¹: https://github.com/v8/v8/blob/73... Reading that code, you'll notice that there's a comment saying that v8 can't really make the code efficient, and that's due to the semantics in Array.prototype.filter. The function accepts sparse arrays, so the implementation has to look at whether some index is present or not in the array (line 1158). This particular verification, just like verifying if a key is present in an object, is slow. Furthermore, functions passed as arguments to filter() are not guaranteed to be pure, and they take the original array as argument, so nothing prevents you from writing: xs.filter(function(element, index, array) {  delete array[~~(Math.random() * array.length)];  return true;}) The possibility of these side-effects makes it difficult for things to be optimised, so things take a more conservative approach in order to make your program run as fast as possible while still maintaining the correct behaviour. Can Higher Order Functions like filter() be fast? You'll also notice that the code that you see in Array.prototype.filter() is not the same code people usually write in a for loop for iterating over the array. So comparing the performance of a for loop with that implementation of Array.prototype.filter() is comparing apples to oranges — you're not doing the same thing. So, to make sure we're comparing the same thing, we'll reimplement map(), and then write the equivalent of that code using a for loop: // The mapfunction map(xs, f) {    var ys = [];  for (var i = 0; i < xs.length; ++i) {    ys[i] = f(xs[i]);  }  return ys;}function inc(a) {  return a + 1;}map(xs, inc)// The for loopfunction forloop(xs) {  var ys = [];  for (var i = 0; i < xs.length; ++i) {    ys[i] = xs[i] + 1;  }  return ys;}forloop(xs) Now both functions do the same thing. We can proceed to check if v8 treats both of these in the same way. This can be done by just analysing the intermediate representation that v8 uses when compiling. Vyacheslav Egorov, one of the people working on the v8 compiler, wrote a tool called IRHydra (http://mrale.ph/irhydra/2/), which can be used to analyse this IR. For the example above, v8 will output thousands of lines of assembly code (see 0-map.js  and 0-for.js), which we can load in IRHydra. The preamble of both functions is very similar, with the difference that `map()` takes 2 parameters, whereas `forloop()` takes one. Likewise, `map()` needs to check more values, but this is just a check before the actual looping, so it doesn't really have much of an impact: The pre-loop part has the code to allocate the new array, and it checks the objects to make sure we're still under the same assumptions for which this code was optimised (so if you passed a String or Object to map() or forloop(), that would violate the CheckMaps, and make v8 recompile that function or deoptimise it). The interesting part is the loop, however, and if you look at the loop for `map()` and the loop for `forloop()`, you'll notice that they have roughly the same instructions! v8 figured out that it was safe to inline the function that was passed to `map()`, which made the two pieces of code the same (note the lack of function calls in the `map()` version, and the `Add` instruction in the same place): Can I know the performance without all of this? “But that is a lot of work!” You might say. “Can I somehow predict how my code will perform without doing all of this?” No. You can not. The only way to know how something performs in modern JavaScript VMs is by carefully profiling it, and if you really must, looking at the internals of the VM. Now, the previous section was entirely about v8, while modern VMs achieve similar performance, they do so through different kinds of analysis and optimisations, so what works well for v8 might not work so well for SpiderMonkey, or JSC, or Chakra, or Nashorn, or any other VM. Profiling your real application in each platform you want to support is still the best way of getting a helpful feedback on its performance, and deciding what to do to address any performance issues you might have. Micro-optimisations don't matter! As Mattias Petter Johansson said in his answer to this question, micro-optimisations don't really matter for real-world code. Better algorithms do. In fact, the speed up in the benchmark section, compared to Array.prototype.map, was achieved by having a better algorithm. However, this better algorithm doesn't work well with JavaScript's semantics. That is, while it's faster, it's also wrong, because it fails for sparse arrays, and array-like objects! A human could very well determine that that particular algorithm is the right one for their application, because they know what kind of data they're dealing with. The compiler and the language's standard can not do that, so you end up with the overhead-y version that is in the standard library to support all of these other use cases. Furthermore, it's not clear that Array.prototype.map() is the bottleneck in your application. You can only know what's worth optimising by carefully profiling your code. And if Array.prototype.map() is slow in a hot path of your code, maybe Array isn't the right data structure for your use case. For example, if you're testing for collision, using a QuadTree would cut the amount of objects you need to compare against by a large amount, whereas using an Array would require you to check every object against every other object (not just the ones near it). Conclusion Yes, modern JavaScript VMs can optimise things very well, and that means that Array.prototype.{filter, map, reduce, ...} are all as optimised as possible, while still being as general as possible. So, they are fast enough for any application that actually requires them. The performance of those functions isn't going to fix the problems of using the wrong algorithm or data structure in your application, however. Always revisit your algorithms and data structures before doing any other optimisation. ¹: Self-hosting the standard library (that is, writing the JS VM's standard library in JavaScript) is a common thing among modern JavaScript VMs, and that lets the standard library get the same optimisations that are applied to other code (function inlining works, for example), without having the overhead of talking to the native layer. Updated 15w ago • View Upvotes