How to dynamically set the number or reducers in hadoop mapreduce job?upon a little more reading of how mapreduce actually works, it is obvious that mapper needs the number of reducers when executing. each map task will generate as many output files as there are reduce tasks configured in the system. each output file will be targeted at a specific reduce task and the map output pairs from all the map tasks will be routed so that all pairs for a given key end up in files targeted at a specific reduce task.what can be done, is based on the number of bytes/records in the map task input file, dynamically set the number of reducers.  the measure of map task input and reduce task input (map task output) can be very different, but that seems to be the best educated guess there is.