What are the best academic papers in computer science? Why?
I can’t speak for computer science as a whole, but I can list some of my favorite papers in my area, programming languages. This list is clearly biased toward older, foundational work. Peter Landin (1966), “The Next 700 Programming Languages.” (In less than eight pages, Landin introduces several important concepts and anticipates several decades of programming languages research. He builds an equational theory for the pure fragment of a higher-order programming and explains why imperative features break the theory. His language includes “program points,” a control feature that anticipates the J operator and call-with-current-continuation. Not quite as important, but sort of interesting, is that this is the first appearance of the off-side rule for significant indentation, which was adopted by Haskell and misunderstood by Guido van Rossum.) John Reynolds (1972), “Definitional Interpreters for Higher-Order Programming Languages.” (Reynolds shows why meta-circularity doesn’t really constitute a definition. A naïve meta-circular interpreter fails to specify the evaluation order, because the evaluation order of the object language is simply inherited from the metalanguage. Instead, the interesting features of the object language need to be defined in terms of better understood features of the metalanguage; for example, he uses defunctionalization to interpret higher-order functions without using higher-order functions in the metalanguage. He then shows how continuation-passing style can be used to specify the evaluation order of the object language without depending on that of the metalanguage.) Barbara Liskov and Stephen Zilles (1974) “Programming with Abstract Data Types.” (Liskov and Zilles suggest that programmers should be able to use more types and operations than a language designer would see fit to include in a language, and thus propose abstract data types as a way to increase software reliability.) Dana Scott (1975), "Data Types as Lattices.” (Scott uses the “universal” domain [math]P\omega[/math] to construct a denotational model of the untyped lambda calculus. The key feature is that the domain is isomorphic to its own continuous function space, and continuity is equated with computability.) Gerald Sussman and Guy Steele (1975), “Scheme: An Interpreter for Extended Lambda Calculus.” (In trying to understand the “actorness of actors,” Sussman and Steele implemented Scheme, an executable form of the untyped lambda calculus. Along the way, they noticed that actors are closures and that message send is invocation. They show how Scheme’s minimal primitives can neatly express a variety of control structures, and introduce proper tail calls. It’s worth reading Steele and Sussman’s follow-up LAMBDA papers as well.) Luis Damas and Robin Milner (1982), “Principal Type Schemes for Functional Languages.” (This is the foundational paper for type inference. Damas and Milner give, for the lambda calculus extended with let, a type system in which every term has a principal—that is, most general—type scheme. They then give a sound and complete algorithm for finding principal type schemes.) Andrew Wright and Matthias Felleisen (1992), “A Syntactic Approach to Type Soundness.” (Wright and Felleisen give a new technique for proving type soundness that is both easier than earlier approaches and applicable to a wide variety of language features. They explain how to give an operational semantics that is amenable to their technique and give several examples of how to model different language features using this style of semantics.) Updated 98w ago • View Upvotes