What are some interesting theoretical limits?
There is a number of limits on parallel computation. For example, if you agree that parallel computing units (CPU cores, logic gates, etc) have at least some minimal size/volume, that communication between them cannot occur faster than the speed of light, and that they are embedded in a d-dimensional space (d=2 or 3), that gives rather strong limits on speed-up from any sequential program. If the sequential program takes T(n) steps, then a parallel version in d dimensions needs at least (d+1)th root of T(n). So, using 2D, you can speed up T(n) to cubic root of T(n). This may sound surprising because books on parallel computing claim exponential speed-up for matrix multiplication, fast Fourier transforms, etc with enough processors (usually as many as data items or maybe that many squared). Turns out, if you have to stay in 2D or 3D, such (asymptotic) exponential speed up is impossible. For more limits along these lines and for details, see I. L. Markov, ``Know Your Limits: A Review of `Limits to Parallel Computation: P-Completeness Theory'''  IEEE Design and Test, January 2013.http://web.eecs.umich.edu/~imark... Updated 39w ago • View Upvotes