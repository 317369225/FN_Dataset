In what cases is Java slower than C++ by a big margin?
Todd has mentioned some of the optimizations available to the JVM that are not easily available to a C/C++ compiler. These include easy whole program optimizations and constant folding at runtime. Imagine a program that takes in a 100 flag options but uses only 1 constant flag after the program has started. The JVM in theory could discard all the code for the 99 other flags and inline the propagate the one constant that is used. The JVM has a great default NUMA aware memory allocator, which works better than most malloc implementations. So if your program does satisfy the "weak generational hypothesis" Java can give really good performance. Further there are many off-heap libraries that use sun.misc.Unsafe to keep your data free from the tyranny of the garbage collector. Of course you then face some of the perils of manual memory management but Java makes it possible to have a mix of off-heap (not GC'ed) and on-heap(GC-ed) data. Why then would the JVM not be the obvious choice for performance sensitive data? My answer lies in the lack of predictability. Here are a few reasons: Garbage collection - Even though "new" is a simple "bump the pointer" allocation, collecting garbage is not free unless most of your data dies young. Only a few JVMs can deal with massive heaps. You get unpredictable pauses because of this. So if you are building a server with lots of persistent but largely inactive connections, all the long lived data will cause unpredictable pauses. There are people who pride themselves on their knowledge of how to tune the GC. There are hundreds of GC related flags, a combination of which might very well give you good performance, but this lack of predictability is not an option for some businesses. Concurrent GC threads are not free and at the very least pollute your cache. JIT compilation - JIT compilation in Java is supposed to be able to do mythical things. Eliminating and inlining virtual calls, runtime constant folding, whole program optimization etc sound wonderful. This does affect predictability though. First of all you have a sophisticated compiler running concurrently with your code. This is not free. The JVM also decides when your code is hot, and when to compile it. Though you can control certain settings, this is not a very predictable thing. Usually the JVM optimizes methods that run quite a few times - lets say the default is ten thousand times. What if you have a 100 paying customers who use a certain API and tens of thousands of free customers who use another API. The JVM will happily optimize the free API calls, leaving your paying customers with a poor experience. Optimization of course is also not free. GCC and other C/C++ compilers take an extraordinary amount of time to do some of the more involved optimizations. So the JVM has to constantly juggle the priorities of better but more expensive optimization and start up time. This limits the kind of optimizations it usually does. Operationally this is painful too. Java servers need to be warmed with an accurate load for optimizations to take place, before being opened up to user traffic. Otherwise the first few thousand requests could give terrible interpreted mode performance. This is difficult to do and if your traffic changes you pay with unpredictability through deoptimize/analyze/optimize cycles. Both JIT compilation and garbage collection make use of safepoints in the HotSpot JVM. This leads to some nasty issues like perfectly good threads seemingly pausing, waiting for some other thread to arrive at a safepoint. This is a source of jitter. Though C/C++ programs don't face such VM induced jitter, they face similar jitter from the kernel itself. The runtime also limits some optimization possibilities which are not jitter related: i) Memory layout: Inability to control memory layout is a big problem for high performance software. The kinds of tricks one has to employ to avoid problems like false sharing in the JVM are just insane. Structs of structs and arrays of structs are really important for certain applications. Creative uses of sun.misc.Unsafe notwithstanding, Java just doesn't easily let you have the type of control that C/C++ does. Depending on your program this might be a big deal. For programs that can have most of their data structures laid out as arrays of structs, this can lead to an order of magnitude difference in performance numbers. So while math in Java might be close or as fast as math in C, sequentially iterating over arrays of structs in C is way way way faster than iterating over an array or ArrayList of similar objects in Java. Further once a garbage collection occurs, these objects which might have been allocated close to each other due to Java's bump the pointer thread local allocation, might unpredictably move far apart. There is nothing unique about Java here though. Iterating over an array of pointers to randomly allocated structs in C will be similarly slow. With modern CPUs the gap between processor speed and main memory speed keeps widening. Writing cache efficient data structures is usually a better bang for the buck than most optimizations one can do to reduce the number of processor instructions. Anecdotally I have seen more than an order of magnitude improvement by changing some numeric kernels in Java by to use C like memory layouts. I only changed the underlying data structures to be similar to the ones I'd write in C using the Unsafe package, all the algorithms remained the same. So if you are willing to write C like code in Java, you can get close to C like performance. But just because you can doesn't mean you should. It's incredibly verbose and error prone to use hand written structs in Java. I'd never do it if I had a choice. ii) The VM tacks on data to your objects in order to manage them. Thus fewer objects fit in cache, and cause performance issues. This is probably a minor issue though. Random access into more bloated objects is not much slower than random access into more compact ones. Though again with the control you get in C, it's easy (with some thought) to align your data structures so that you can ensure that a random access brings into a cache-line all the data that you do need. For streaming access though, if Java did manage to get arrays of structs some how, the extra bloat would probably not slow it down much. Streaming access is just so fast that a few bytes tacked on to every object would matter very little. iii) The JVM is built with the explicit goal of working on many platforms. Thus it usually doesn't expose the low level platform-specific instructions/facilities available to native code. For example: You cannot use the x86 PAUSE instruction in your busy-waiting code in Java. You also don't have access to vector instruction sets like SSE/AVX/AVX2 etc without resorting to JNI.  JNI besides being very ugly also has a performance cost. Anything that is not implemented as an intrinsic in the JVM just won't be as fast as an equivalent in C++.This pretty much rules out the use of pure Java for  competitive applications that do CPU intensive but repetitive array processing. Examples include game engines or image processing kernels. Again anecdotally I've seen 2-4x improvements in some workloads from using SIMD libraries. This is not very usual though and for most business applications that are heavy on conditional logic, there would be marginal benefits (if any). In spite of all the seemingly inferior things I pointed out, the JVM is a very capable platform for high performance code especially on servers with plenty of resources. Mixing your own simple garbage collected code with high performance libraries (http://lmax-exchange.github.io/d... ,  https://github.com/OpenHFT/HugeC... etc) can lead to easy to read code that still performs quite well. Further if proposals like ObjectLayout by giltene and mjpt777 can make it to the Java standard, Java will finally get rid of it's biggest performance weakness - lack of optimized memory layouts. Updated 57w ago • View Upvotes