What's the most time and space efficient algorithm to find the repeated phrases in a document?
Assuming that you have a good enough definition of 'phrase'. Then, as others have mentioned, just hash the phrases, counting them at the same time. Here's some python code that does just that: from collections import defaultdictdef repeatedPhrases(text):    phrases = defaultdict(int)    for phrase in text.split(';'):        phrases[phrase] += 1    # Return the phrases with 2 or more counts    return [k for k, v in phrases.items() if v>1] This is roughly O(2N), with N being the number of phrases, and assuming a typical hash lookup speed of O(1). A slight improvement would be to split by generic punctuation instead of by just semicolon. Another improvement would be to return the list of repeated phrases sorted by occurrence, in which case you'll need to sort the hash by value. You could also return a tuple with the phrase and the number of occurrences, and let the user to (eventually) do the sorting. If your definition of phrase is more complex, like in "a phrase is everything from one(or two) word(s) up to the next punctuation sign", as mentioned there are more efficient implementations, which account for the repeated phrase prefixes, like using a Trie. 