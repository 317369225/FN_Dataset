What's the most time and space efficient algorithm to find the repeated phrases in a document?
I would use something called a "DAWG" (Directed Analytic Word Graph) as described here: Page on cmu.edu . This can reduce the size of the representation of all the phrases to find over a "trie" (also described on the page) pretty significantly. When you have your DAWG of all the phrases to consider, it's simply a matter of traversing the string from left to right, and using the DAWG to confirm when you have a new phrase or not. Â  Treat the DAWG as a finite state machine, and the string as the tape. Start a new finite state machine with the DAWG again at every letter you pass, and read off the letters for already running machines. Terminate a machine if the next letter does not correspond to an edge, otherwise traverse the edge. Also, keep a tally for each phrase. Whenever you reach a node that is double-circled in the DAWG, backtrack the string with the DAWG and see what word you built. The space needed would require you to keep at least as many states for each DAWG machine as the longest phrase (since they must terminate by then), as well as the DAWG itself, a tally for each phrase (indexed in some way), and the string itself (since you have to backtrack. You can truncate the string as you realize that you don't need to backtrack after a certain point, but that's probably not worth the effort.) I think this algorithm is pretty fast. Let P be the length of the longest phrase, and let L be the length of the string. This should run in about O(LP), since you have to keep up to P state machines running at the same time, and you have to update each machine for each letter of the string. 