What's the most time and space efficient algorithm to find the repeated phrases in a document?
Okay, I'll assume phrases are period-space or period-newline separated, or that you have a way of knowing how to split phrases. And that the data is coming stream-like, or is treated like such. So, you are reading one character at a time, starting from character 1. I'll also assume the language is relatively low-level (C-ish) and you don't have access to dictionary types and need to do all yourself. Initialise a buffer (a memory space) where you will be storing the phrases as you process them. Start reading char-by-char and storing them in the buffer, until a new phrase signal (i.e. current char is space or newline and previous one was period.) When triggered, hash using a fast hashing algorithm (MurmurHash3 for instance) and store a structure hash-phrase-count (for speed ups you can create a lookup table for the hashes instead, so there is no need to traverse the whole struct, easing a little on CPU caching.) Before storing, though, check the hash index to see if this phrase is already there, if it is, increase count. Repeat. If you have  a dictionary type (or a map type) so you can do whatever["a long string"], usually the indexers are already hashes, so most of the work is already done for you. The advantages of doing it with hashes is that hashes are (in general) shorter than sentences, and a fast algorithm like MurmurHash3 (if properly implemented for strings, or with the strings properly formatted for hashing) won't really loop through the strings many times. So you can easily save lookups. A simple example of where a naïve algorithm would fail is a document where phrases are something like: This is phrase A. This is a phrase B. This is a phrase C. In such a case, a naïve algorithm needs to compare each phrase to almost all characters in all previous phrases. When hashing, you first hash (which almost could be done at the same time that the data is fetched) and then compare hashes, which statistically are likely to be completely different, so in such a bizarre instance you'd only compare the first few digits of the hash before moving on. Okay, now for the other problem with overlapping: how exactly are we supposed to split phrases without knowing the separator? In this specific instance it's more like you are wondering how many repeating sub-sequences are in your data. This is harder, actually similar to what Run-length encoding algorithms do, in some sense. Hope this helps somewhat 