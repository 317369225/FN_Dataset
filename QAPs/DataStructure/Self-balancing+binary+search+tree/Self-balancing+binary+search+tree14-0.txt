What's the most time and space efficient algorithm to find the repeated phrases in a document?
A2A: To improve a bit on Jacob's answer, the most efficient way would probably be to use a hash map that maps phrases to integers. In that case it's O(1) time to look up each phrase in the hashmap, O(1) time to add a new phrase to the hashmap (assuming the hashing function takes approximately constant time), and O(1) time to increment the integer value that an existing phrase is mapped to. Thus, for N phrases you only need O(L) time and O(L) space; I can't think of any way to get a better efficiency than that. Edit: In response to your updates, I think you should first parse the document by spaces, which will give you an array containing one work in each slot. Parse each phrase you want to search for similarly so that you can isolate each word (I'm assuming you don't care about spacing in between words). Take the first word of each phrase, and store them all in a hash set. Then, as Scott suggested, go through the array containing your document word by word, and check if each word is in the set containing the start of a phrase. If it is, store the index of that word in a hash map. This hash map should map words to linked lists so that if a word appears multiple times, you can store each index of its appearance in the linked list. Once this is done, go through each phrase and look up the indices of its starting word in your hash map. You can then go to that index in your document array and easily check whether or not the next few words in the array follow your phrase or not. Time Efficiency Rundown: I'll use L as the length of the document Parsing the document and phrases: O(L) Storing the first words of the phrases in a hash set: O(N) Searching through the document for occurrences of the first word of a phrase: O(L) Going through your hashmap to see if the phrases match the document: O(N*k) (slightly higher if you have long phrases) Thus, depending on the relation between the length of the document and the number of phrases you have, your time efficiency is going to be either O(L) or O(N*k). In terms of space efficiency, you're not storing that much more than the already existing document and list of phrases, so that shouldn't be an issue unless you have really massive lists in relation to your memory size. 