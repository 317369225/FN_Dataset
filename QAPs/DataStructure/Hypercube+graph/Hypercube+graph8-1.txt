What does it mean by the statement, 'neural networks are universal approximators' in a mathematical intuitive sense?
In an intuitive sense that if you have a function in the form of a list of inputs and outputs there is a Neural Network that given those inputs will approximate the outputs very well. This can be any function from "n" to "m" dimensions. A quick example would be to approximate sin(x)*cos(y). In this case your input has 2 dimensions and your output is a real number. If you train the NN with several values of x & y and the expected output the NN will learn how to predict the result of the function without even knowing what function it was. Here's a graphical example: y=0.2 + 0.4x^2+0.3*sin(15x) + 0.05*cos(50x) And how a NN will approximate this function using different number of hidden units: Luis. 