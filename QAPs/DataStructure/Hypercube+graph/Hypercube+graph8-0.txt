What does it mean by the statement, 'neural networks are universal approximators' in a mathematical intuitive sense?
Consider the set of all continuous functions which are defined on the unit hypercube (i.e. the unit square in two dimensions, the unit cube in three dimensions, etc.).  Call this set C. Given two functions in C, it is possible to define a metric which calculates a notion of distance between them.  For example, if you have [math] f(x), g(x):[0,1] \rightarrow \mathbb{R} [/math], you could define the sup (short for supremum distance): [math] d(f,g) := \sup_{y \in [0,1]} |f(y) - g(y)| [/math].  This calculates the maximum vertical spread between the graphs of the two functions f and g. Consider the set of functions of the form [math]F(x) = \sum_{i=1}^N a_i \sigma(y_i^T x + \theta_i) [/math].  As you vary the parameters in this expression, [math] N, a_i, y_i, \theta_i [/math], you sweep over all the functions which can be the output of a 2 layer neural network.  Call this set of functions NN. Stepping back, suppose you had a subset of functions D,  that were very good at approximating all the other functions in C.  You might formalize this idea by saying that for any element f of C, you can find an element g in D which is very close to f.  Mathematically, for any [math] \epsilon > 0 [/math], and any [math] f \in C [/math], you can find a [math] g \in D [/math], such that [math] d(f, g) < \epsilon [/math].  The choice of g will depend on the particular f and epsilon.  Sets with this property are called dense.  Dense is a good choice since the subset D seems to fill up all the space in C, like air filling up a balloon. So, the theorem on neural nets being universal approximators.  Go back to the set NN.  One can prove that NN is dense in C.  Given an arbitrary function, you can find a neural net output function that is arbitrarily close to the function at all input values. Finally, it should be said that  this property of neural nets is not something mystical about them.  Many classes can have this property.  In particular, if you replace the sigmoid function [math] \sigma [/math] with any other bounded, increasing function, the density result is still true.  On some level, it is not that hard for a subset of functions to be dense inside of C. Updated 39w ago • View Upvotes