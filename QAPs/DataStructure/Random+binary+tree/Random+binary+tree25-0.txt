What is the algorithmic complexity of this digital search tree?
The worst case time complexity for each operation on a digital search tree is not actually [math]O(k)[/math]. In your analysis, you forget that it takes [math]O(k)[/math] time to compare two strings, where k is their length. As a result, each operation is actually at worst [math]O(k \cdot min(n, k))[/math], because the height is at worst [math]O(min(n,k))[/math], where n is the size. This worst-case scenario occurs when all keys have a long common prefix. If you assume the input is completely random and only store pointers to the keys, the average case for each operation is actually [math]O(\log n)[/math]. This is because the expected height of a randomly built tree is [math]O(\log n)[/math]. Once you assume the input is random, though, the runtime of most string algorithms becomes meaningless. For example, the naive string searching algorithm on random input is expected time [math]O(n)[/math], but it should never be used in practice because the worst case is [math]O(n^2)[/math]. In this case, real world data often has matching prefixes, hurting the performance. For example, if I have 32-bit integers but only insert integers below ten million, all the keys will have several leading zeroes in common. Thus, if the keys are long, you should use a trie instead of a digital search tree. Tries have depth of at worst [math]O(k)[/math], except only perform one comparison instead of [math]O(h)[/math] comparisons per operation. And yes, this particular field is fairly well known and has been very well studied since the 1970s. Here's a somewhat interesting paper that compares the performance of a digital search tree against standard balanced binary trees on integer keys: Page on toronto.edu. A similar analysis could be done on tries vs. digital search trees, though the former should prevail in most real-world situations where the keys are nontrivially long strings. 