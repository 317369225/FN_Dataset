What exactly is a Huffman coding tree?
Huffman's algorithm is used to generate optimal variable length encoding. What do I mean by that? Whenever we want to receive or transmit information ,we want to do it in an efficient way. So first, how do we represent information? Claude Shannon proposed a way of quantifying information. [math]I(data)=log2(1/p_{data})[/math] where [math]p_{data}[/math] is the probability. This expression gives us the number of bits required to convey the information. A Coin flip Suppose I flip a coin and I get heads,  the number of bits required is [math]log_{2}(1/(1/2))[/math] Which is 1. which tells us that i need only 1 bit to inform if its heads or a tail.(0 or 1) A Card drawn from a deck. Suppose I want to tell my friend that I have drawn a heart. [math]log_{2}(1/(13/52))[/math] is 2. I reveal to him 2 bits of information which is enough to convey the 4 possible suits in a deck. There are two types of Encodings Fixed Length Encoding Variable length EncodingIn fixed length encoding all the letters/symbols are represented using equal number of bits. Fixed length encodings have the advantage of random access.Since every letter contains equal number of bits, if I want to see what the 4th letter is I would skip the appropriate amount of bits.Fixed length encodings work well when all the possible choices have equal probability of occurring. In languages,for example English some letters occur more frequently than others. Hence it would be very inefficient to use lengthier bit representations for letters that occur very frequently. But there are certain problems we face when we try to represent a frequently occurring "e" with a "0" and rare "z" with a "110". Take a look at the below table:  ​ ​ ​ ​ ​ The first row is fixed length encoding where all the symbols are represented using equal number of bits. The 2nd and the 3rd are variable length . When we try to decode the encoding  of ABBA in the third row  which is " 0 1 1 0"  they could mean : "ABBA"-->0 1 1 0 "ADA"-->0 11 0 "ABC"-->0 1 10 This kind of encoding is wrong since it is ambiguous To avoid such ambiguity we need a binary tree representaion. ​ ​ ​ ​ ​ The above image shows encoding with a binary tree. we start at the root every time we finish decoding a letter. Suppose I ask you to decode "1100101",you would start at the root and traverse the binary tree until you find a leaf. This encoding gives us the answer "ABBD". Suppose you are given certain symbols and their probability of occurring. ​ ​ ​ ​ ​ Huffman coding gives us a method to build a binary tree for the letters in the table above. The Algorithm is as follows: The Huffman Algorithm has a "bottom-up" approach, that is we start by adding  the leaf nodes of the tree . The algorithm states that we should start  with the symbol with the lowest probability(which have the highest amount of information and thus require more bits). So we start with the letter with the lowest probability,which in this case is U(0.09) and A(0.11). ​ ​ ​ ​ ​ since we added the two leaf nodes to the bottom their root will have their probabilities added together which is 0.2. the next  is "I" ​ ​ ​ ​ ​ The next is E and O...so the final tree looks like.. ​ ​ ​ ​ ​ The left branch is arbitrarily chosen to be 0 and the right 1. so if we wanted to encode "AEIOU" it  would be "001110110000" I hope this helps. Source:-http://computationstructures.org... 