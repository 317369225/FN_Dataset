What's the best way to solve the "multiple indexing" problem in functional programming?
Let's start by taking a look at exactly what the "multiple indexing problem" is: the idea is that we want to have multiple views into a single collection which allow us to find and update elements. In the linked blog post, the imperative solution is just to use multiple hash-maps. Here's the example code: >>> val1 = []>>> val2 = []>>> index1 = {1:val1, 5:val2}>>> index2 = {"pepijn":val1, "ben":val2}>>> index2["pepijn"].append("foo")>>> index1[1]['foo'] So where does the impedance mismatch with functional programming come from? I see two issues. The first is that the two indexes depend on each other implicitly, through mutable state. One of the core tenets of functional programming is avoiding hidden dependencies this way, so we'd have to make it explicit somehow. The other issue is that the pattern relies on every single element having a unique identity (ie pointer) provided by the language. In functional programming, values do not have an identity, which is very important for uniformity and regularity: you can always substitute equal values for each other¹. So we would also have to make this implicit identity explicit somehow. These issues actually lead to limitations even in the mutable hashmap pattern. The problem is that the two indexes are only connected because they contain the same mutable objects. This falls apart if you try to use this pattern to work with value types like integers or Python tuples—since you can't modify those in place, any changes in one index won't be implicitly reflected in the other. Moreover, even with mutable objects, you can't add, remove or replace elements from the indexes without manually synchronizing the two. (Try adding a new key to index1 in the Python example to see what I mean.) So the functional solution would just be making the implicit explicit, and then wrapping that up in a nice abstract type. Each time you use an index, you would get it from the type instead: index2 multiIndex ! "pepijn" instead of just using index2 directly. This just makes the relationship between the multiple indexes explicit, which makes it possible to use them in a persistent way. Internally, I would use a system of Int tags which, again, is just making the implicit explicit: the imperative version also has a layer of indirection like this, but it's done using mutable references instead  integers. This has the nice property that we can also add and remove using any of the indexes, with the rest still synchronized between them. We also have the usual advantages of persistent data structures, like easily being able to store old versions and keep track of history. Hopefully this gives you a new perspective on the problem and explains why the functional approach needs to be more explicit. Right now I don't have the time to actually implement it, but I think I'll do it shortly. I'll write up my whole design process on my blog, since I think this is actually a great case-study for thinking functionally. I'll also look into how we can extend the functionality of the abstraction once we've established it—for example, we can get a simple but surprisingly flexible query language on top of the indexes by using lenses and traversals, which is well worth exploring. Thinking Functionally For more specific use-cases like the Fibonacci heap, I would probably create a data structure similar to what I described but specific to that algorithm. It would be designed to suit the specific use case and likely optimized in a different way, but the core idea would still be the same: I would make the identities of nodes and relationships between them explicit instead of relying on the explicit identity from the mutable reference provided by the language. Of course, it's not actually clear that this is the best approach to implementing something like a Fibonacci heap at all. I believe that you could take advantage of laziness to avoid the whole indexing rigmarole, implementing the Fibonacci priority queue in a neater way. (This is obviously more natural in Haskell than in Clojure!) I'm not sure about the exact details, but it looks like there's an existing Haskell package like this you can look at (Data.Queue.FibQueue). Better yet, you'd just use a data structure designed for functional programming, like asymptotically optimal Brodal/Okasaki heaps from the heaps package. The same is actually true of quadtrees: we can take advantage of laziness and zippers instead of trying to jury-rig references into our tree. Conal Elliott has a great article about representing infinite quadtrees lazily, which is probably a good starting point. Laziness is awesome. A very important take-away from these two examples is that functional and imperative programming are fundamentally different. Solutions to the same problems often take different "shapes" in the two, so perhaps the multi-indexing problem isn't actually what you needed to solve at all! Functional programming is not "imperative programming but less"; in a language like Haskell, the solutions are often orthogonal to how they would be done in an imperative language. Unfortunately, this also means that you often cannot rely on your existing experience with imperative programming and instead have to learn new things, liking thinking with laziness. So in the end, the real solution is often not maintaining multiple indexes but instead thinking functionally about the problem and coming up with a different solution. footnotes ¹ This ultimately boils down to what many people call "referential transparency", although that term is somewhat controversial. Being able to rely on this makes your code far easier to think about: you only have to worry about what a value *is*, not about where its *from*. 