★What is a good distribution to use for simulating a training set for supervised classification?
Here is a utility function to generate an (input) artificial dataset of configurable n_features and n_samples where you can control the linear correlation profile between the features: most of the variance can be explained by `effective_rank` equivalent features. You can also add a "fat tail" of correlation that shapes the rest of the variance:     https://github.com/scikit-learn/... To summarize, this generator lets you control the shape of the singular values of the dataset that is generated: low effective rank means highly correlated features. You can then reuse it to build a supervised dataset (in this case for linear regression) by choosing a random ground truth model with n_informative < n_features regressors (the remaining features will be considered noise except for the correlation of the features) as done in:     https://github.com/scikit-learn/... To build a supervised binary classification dataset, just threshold the y_train and y_test arrays to some arbitrary level `a`.     y_train[y_train < a] =  y_test[y_test < a] = -1     y_train[y_train >= a] =  y_test[y_test >= a] = 1 One note though: this dataset will be linearly separable. For SVM with kernels and multi-layer neural networks it would be more interesting to build a ground truth model based on n_centers Gaussian RBF vectors for instance to introduce non-linearities. To make this even more interesting you could make those basis vectors lie in a low dim manifold of a much higher dimension space using the Q of the QR matrix of random matrix to project to randomly the higher space without breaking the pairwise distances.    Embed Quote