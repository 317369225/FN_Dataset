★How can one improve a classifier (random forest), when there is no overfitting + optimal parameter selection but performance on the test set is much lower than on the training set?
I'm going to assume that since you didn't mention your data was temporal, then you don't have seasonality. I'm also going to assume that you can't just "get more data". It also seems like you're most interested in trying to get your random forest to work, not in creating some harebrained throw everything at the wall ensemble (btw, there's literally zero rationale for stacking rf and svm). For fun lets also say you don't want to shell out for a mediocre machine learning service. So how to fix? One, reduce max tree depth, increase minimum number of samples per split, try just adding a few hundred more trees (in moments of frustration, I've told my CPU to go to hell and ran several thousand tree forests). So if those things don't work, I'd recommend what's called an extremely randomized forest. They generalize extremely well and can be found in scikit learn. Oh and don't use CV in an RF. That would be pretty close to pointless. Pointless things aren't fun.    Embed Quote