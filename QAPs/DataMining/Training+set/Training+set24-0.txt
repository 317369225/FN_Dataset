★How can one improve a classifier (random forest), when there is no overfitting + optimal parameter selection but performance on the test set is much lower than on the training set?
How are you splitting training and test data? If you are block splitting - i.e., spliiting as follows: test = and  train = it could be that there is non-stationarity (e.g., seasonal trends) in your data. In this case your model is performing poorly on test data because the underlying system generating the data may have changed    Embed Quote