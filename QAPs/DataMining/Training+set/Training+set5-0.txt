★How big should the training set be in the Naive Bayes text classification?I'm working in a concrete implementation of 800 documents and for 700 documents in the training set and 100 in the test set the accuracy is not greater than 0.5. Any thoughts?
First make  sure that data is balanced. Since simple naive Bayesian algorithm  won't work for unbalanced dataset. If dataset is unbalanced, then I suggest you to try out complement Bayesian algorithm. Weka(http://www.cs.waikato.ac.nz/ml/w...) and mahout(http://mahout.apache.org/) supports complement Bayesian algorithm. If dataset is balanced, Then I suggest you to try out active learning with Bayesian classification(since you are already using Bayesian classification). I suggest you to look at kamal Nigam paper "Semi-supervised Text Classification Using EM"(http://www.cs.cmu.edu/~tom/pubs/...), Paper Author used EM algorithm with Bayesian classification, and reported major improvement in accuracy. They use active learning approach for text classification, which helps them to overcome the problem of training data size. The paper also reported improvement of accuracy with respect to  variation of training  and unlabeled dataset size.    You can find kamal nigam python implementation on blog (http://www.mblondel.org/journal/...) I usually suggest 80-20% break up ratio between the training and testing data. But when your dataset is small(800 posts), there is possibility that training data and testing data are not compatible and so they are not giving best result.   I suggest to use cross validation techniques(http://en.wikipedia.org/wiki/Cro...), Cross validation gives you average result but won't help you in  training data selection.  I feel there should be a definite  statistical approach for building representative  training dataset(training data selection) . I like to share some of recent linkedin question posted by me. http://www.linkedin.com/groupIte... http://www.linkedin.com/groupAns... http://www.linkedin.com/groupIte... Statisticians use power law(http://en.wikipedia.org/wiki/Pow...) for  training dataset size estimation, in  pure data mining and statistical learning for a given break up ratio(between the classes) and required accuracy and confidence. But it won't work  for text mining problems, since vocabulary size plays important role and text mining problems are more complex as compared to data mining problems.Hope it helps,  suggestions are welcome    Embed Quote