★Machine learning: in computer-aided diagnostic programming, how much data is required for an adequate training set?
1. "How  do you determine how much is enough or if one item in the data/training  set is more important than another?" The beauty and utility of machine learning lies in its ability to generate a formula based on your training data. Machine learning is used in situations where (a) there exists a mathematical relationship between target (output) y and input (feature vector) x, and (b) this relationship cannot be described by a simple mathematical formula. Machine learning algorithms are generally divided into supervised and nonsupervised learning algorithms, but in either case the process consists of optimizing error functions, for example in the case of SVM, NNs, and logistic regression and even K-means. If we knew which features in the data set are more important than the rest, ML would not be necessary. The power of ML lies in the practicioner's ability to take a set of features (what you described in your question as 'items') and have the software determine automatically which ones are important and which ones are not; this is called weighting. In many applications of SVM, tens of thousands of features (or more!) are used. 2. "...Promedas, wouldn't they have to prepare a certain amount of data for what (I  think) is called a "training set" in order for the information to be  useful to the programmers?" Correct. I have not used Promedas, but it seems like you have to bring your own data. These data consist of (a) a training set, and (b) a test set (assuming the case of supervised, rather than unsupervised learning algorithms). The training set consists of input vectors with many (or not so many) features, and for each input vector there is also a target (known output). This target can be in the form of continuous numbers (regression), or it can be in the form of a finite number of classes (classification). The ML algorithm solves optimization problems and/or implements iterative methods such as gradient descent to obtain the weight vector that best fits the data. Usually the training set is also used as the cross-validation set, either by dividing it into the training set proper and the cross-validation set, or by implementing cross-validation on the training set. The purpose of cross-validation is to prevent over-fitting phenomena, where the weight vector fits the training set so closely that it does not generalize well to the test set. Note that the test set may or may not have target values. 3. "What would the programmer need from the  practitioner?" In order to apply machine learning algorithms, one of the earliest steps involves formatting the data properly and scaling it so it can be used by whatever package you are using. This is the intersection of data science/mining and machine learning. Assuming that the programmer will be writing much of the code used to extract and tidy up the data, she/he will need to know from the practitioner the desired format of the training/test data.    Embed Quote