★How big should the training set be in the Naive Bayes text classification?I'm working in a concrete implementation of 800 documents and for 700 documents in the training set and 100 in the test set the accuracy is not greater than 0.5. Any thoughts?
The fact that you get an accuracy of 0.5 should make you "worry" about the features that you are using, the quality of the dataset and finally ask yourself if the Naive Bayes model is appropriate for this problem. It is really really hard to provide any good suggestions without knowing the details of your problem and implementation, so I will just throw few "ideas" on what I would investigate: - Check the tokenization algorithm that you use for your documents. Do you extract the keywords that you were supposed to extract? Is there a bug there? - Do you run a feature selection algorithm to keep the important keywords? Do you extract too many keywords? Perhaps too few? - Is your dataset rubbish? You as a human, could you detect the class of the document? - Is your NB implementation correct? Look out for bugs (numeric underflow, unsmoothed counts which lead to 0 probabilities etc). You can try out this simple  Naive Bayes Implementation and compare your results. Hope this helps.    Embed Quote