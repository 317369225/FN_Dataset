★What are the different sampling methods to generate subsamples from a large training set to be able to  capture the correct correlation between features(a.k.a learn a model)? To add on, Is MCMC better than random sampling to generate this subsample ? If so, how big should the random sample be? I have used MCMC for parameter estimation, my question relates to using it for sample generation for learning models like for e.g regression.I am aware of online algorithms which is one way to solve the problem. I am looking for a sampling method which will allow me to evaluate accuracy of my system within some confidence interval.
You can also try  Stratified sampling. Though it is different from simulating the random sample from MCMC but it works well in case of heterogeneous population or problem where you have class imbalance. The only back drop it might have is if your overall data cannot be partitioned in disjoint group. but there is no harm trying. Since there's very little information about the data itself so you can shed more light on the properties of data and it's context. heres a python and R implementation of stratified sampling. sklearn.cross_validation.StratifiedShuffleSplit - scikit-learn 0.15.1 documentation drawing a stratified sample in R stratified sampling in numpy    Embed Quote