★In a support vector machine, the number of support vectors can be much smaller than the training set. How can this feature be useful?
This is useful as one obtains a sparser solution. Fewer number of support vectors, for example in the kernel case, allow a sparser representation of the solution to the optimization problem, which is beneficial in scenarios where one could have storage and computational constraints. Instances where this could be feasible are on mobile platforms/devices, where we may intend to use a machine learning algorithm for an application, or for chip realizations of ML algorithms. You may refer to this recent paper on a new classifier which has shown significant improvement in terms of reduction of number of support vectors, while obtaining comparable accuracies. @[1408.2803] Learning a hyperplane classifier by minimizing an exact bound on the VC dimension    Embed Quote