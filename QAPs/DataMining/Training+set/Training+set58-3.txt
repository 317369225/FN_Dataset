★What are the different sampling methods to generate subsamples from a large training set to be able to  capture the correct correlation between features(a.k.a learn a model)? To add on, Is MCMC better than random sampling to generate this subsample ? If so, how big should the random sample be? I have used MCMC for parameter estimation, my question relates to using it for sample generation for learning models like for e.g regression.I am aware of online algorithms which is one way to solve the problem. I am looking for a sampling method which will allow me to evaluate accuracy of my system within some confidence interval.
IMHO I dont see this idea going anywhere. You have a hypothesis and data, you learn your probabilistic model from that data. Now you want to create samples to train some other model. But one argument I would like to make, how do we know that our model/assumptions captures the complexities of the data. So you would be generating your assumptions. (until you take a non-parametric model and that might work, i have no idea) an example would be, if you assume the model to be gaussian, you are not going to generate from mixture of gaussians. Even If you could as your model might be capturing the data, you understand my point.    Embed Quote