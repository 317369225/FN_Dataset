★Can the validation set be larger than the training set?For example, if size(test data) is known and fixed, and size(test data) >> size(training data), then having a large validation set will better mimic the testing scenario.
It *can* but I don't think your model will be calibrated on enough data.   I imagine that if you're asking such a question, your data set is small and it's expensive to obtain more data.  In that case I'd recommend trying k-fold CV.  As an example, if you have 20 data points, you partition it into a training set of data points 1-15 and a test set of data points 16-20.  You train your model, run your cost function/measure of effectiveness/whatever you'd like to call it on the test set, then re-partition your data set with the test set now containing points 11-15 and the training set including everything else.  Repeat until you've done 4 different partitions, and take (for example) the average of your cost function over the different partitions.  If you think your model is good, then train it over the whole set (unless you have a reason not to do so).   And if your data is big enough, you don't need to be asking this question anyway.    Embed Quote