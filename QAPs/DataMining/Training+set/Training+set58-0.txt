★What are the different sampling methods to generate subsamples from a large training set to be able to  capture the correct correlation between features(a.k.a learn a model)? To add on, Is MCMC better than random sampling to generate this subsample ? If so, how big should the random sample be? I have used MCMC for parameter estimation, my question relates to using it for sample generation for learning models like for e.g regression.I am aware of online algorithms which is one way to solve the problem. I am looking for a sampling method which will allow me to evaluate accuracy of my system within some confidence interval.
This is a hard question to answer without a lot of context The feature space is typically linear, and statisticians usually only think about co-variances as correlations; this can be deficient in many situations The sampling issue depends on the length scale of actual correlations. Your system might have large number of very weak, but coupled, interactions.  In this situation, one needs to sample the correlations uniformly over the entire space of instances to pick up the dominant effect.  In the 1950s and 60s, one might compute the entire matrix of covariances and then apply random matrix theory to de-noise it.  (i.e we sample the covariance matrix directly and randomly, and this is different than, say,  sampling only the instances randomly, or only the feature space randomly). Today this can be accomplished using a modern matrix factorization technique, ala NMF or compressed sensing. Still, even this might not pick up all the correlations. As to MCMC, this is a technique lifted from physics that has been used to sample near the equilibrium, or most likely, distribution.  But this can be a weak  concept in a situation where you don't have all the phase space variables in play -- i.e. only linear features, and assuming a specific kind of correlations, such as in a specific graphical probabilistic model.   But we can do better One thing we have learned from deep learning, however, is that we can use a kind of short chain MC sampling, called contrastive divergence, to sample very complex correlations that are specified in certain kinds of  probabilistic graphical models.  So generally speaking, if you understand deep learning, you can do much better than random sampling using a kind of MC sampling. Ill leave it to you to pursue the matrix factorization and deep learning methods and then ask more questions    Embed Quote