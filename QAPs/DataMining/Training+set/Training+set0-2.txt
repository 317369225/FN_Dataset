★In classification, how do you handle an unbalanced training set?In some cases, you have a lot more examples of one class than of the others. How do you tackle this problem? What are some gotchas to be aware of in this situation?
There are a few things you need to be aware of: Regular classification rate isn't a good approach, because if you correctly classify only the instances of the marjority class (class with many samples), this measure still gives you a high rate. AUC (Area Under the ROC Curve) is the best way of evaluation of these datasets. You can use a Prototype Selection technique to reduce the imbalance level. Select only the instances that have importance. One-Sided Selection (OSS) is a pre-processing technique that handles unbalanced datasets. It is usually used before the actual training. Other option is to create new instances of the minority class, try re-sampling or prototype-generation techniques that handle such datasets. In your K-Fold validation, try to use the same proportion between the classes. If the number of instances of the minority class is too low, you can reduce the number of K, until there are enough. Also, be carefull with the techniques/algorithms you will use. In prototype generation, for example, there are techniques that have a high performance on regular datasets, but if you use them with unbalanced datasets, they will missclassify most (or all) instances of the minority class. In cases like that, search for a similar algorithm, adapted to handle unbalanced datasets, or adapt it yourself. If you get good results, you can even publish it (I've done that).    Embed Quote