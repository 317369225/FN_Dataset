★Web Scraping: When doing a mashup when should you write the crawler yourself, and when should you use an external service/program?
When creating a Mashup site you can use Web scraping or API's . If i were you, i would use web scraping . API’s stinks, use web scraping instead to power up your app will help you understand why .Here are two strategies of doing web scraping,  1. Do everything In-House, expensive in long run 2. Data As A Service, cheaper & reliable in long run In-House Way Build scrapers using a good framework ( like Python Scrapy -  An open source web scraping framework for Python. It has a big community and several companies support it. So if you run in to any trouble you can find someone to help ). The scrapers can save the data to a database, from which your web server can pick up and display it in the website.  If you are programmer you can do this yourself, if not hire a developer to do it. If some of these websites you want to be scraped has some kind of IP based blocking involved, you'll have to get some Proxies or Rotating IP solutions and instruct the web scrapers to use these for making requests ( Download pages ) to the website you scrape. If you are not using proxies or disposable rotating IPs, your server will be blocked and you'll either have to change the IP address of your server or get a new server.  Every website will change their designs now and then, and so should your scrapers. Scrapers usually need adjustments every few weeks, as a minor change in the target website affecting the fields you scrape, might either give you incomplete data or crash the scraper, depending on the logic of the scraper. It would be good to have Quality Analysis for the data before displaying them, and to make sure all scrapers are running well. If you are running a serious business based on this website, the above process would be painful. You'll probably end up spending 70% of your time for this solution. You might wake up to see that a scraper has broken due to a change and the next day IP might get blocked, or the server might crash due to overload, and much more. Hiring people for solving all these problems would have you spent a lot more money than expected. Data As A Service is the best option if you plan to make some real money from this website and if the data is critical for it.  You can find some good providers here What are the best web crawling services? Why DaaS ? They'd already have  solved the problems you have - Most of these providers have very sophisticated infrastructure designed only for web crawling. You can get data with just an API Call.. Most of these providers have a data download API, which you can call periodically based on your scraping schedule to collect your data and store it in your database. More time to focus on improving your website Once you put your scraping related problems on the DaaS Provider, you get more time to work on your website and make more money out of it. You'll have to spend some money for the monthly subscription to the DaaS Provider, but this would be cheaper at the long run, due to the above reasons. DISCLAIMER: I co-founded ScrapeHero , a Data As A Service startup which was built to solve all the in house problems above. Get in touch with me for any help. I wont bite :)    Embed Quote