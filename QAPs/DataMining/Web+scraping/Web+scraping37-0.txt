★How does Google do web scraping for collecting data for its indexes? How does it work?I am more interested in how Google filters the valuable data inside a webpage from lot of other recurring data in the HTML <body> tag like navigation bars, banners etc.
Google Patent: http://appft1.uspto.gov/netacgi/... A document may be segmented based on a visual model of the document. The visual model is determined according to an amount of visual white space or gaps that are in the document. In one implementation, the visual model is used to identify a hierarchical structure of the document, which may then be used to segment the document. Yahoo Patent: http://appft.uspto.gov/netacgi/n... To provide valuable information regarding a webpage, the webpage must be divided into distinct semantically coherent segments for analysis. A set of heuristics allow a segmentation algorithm to identify an optimal number of segments for a given webpage or any portion thereof more accurately. A first heuristic estimates the optimal number of segments for any given webpage or portion thereof. A second heuristic coalesces segments where the number of segments identified far exceeds the optimal number recommended. A third heuristic coalesces segments corresponding to a portion of a webpage with much unused whitespace and little content. A fourth heuristic coalesces segments of nodes that have a recommended number of segments below a certain threshold into segments of other nodes. A fifth heuristic recursively analyzes and splits segments that correspond to webpage portions surpassing a certain threshold portion size. http://appft1.uspto.gov/netacgi/... To approximate a visual layout of a web page without rendering the page, an object tree representing elements within the page is recursively traversed to determine bounds for the width of the elements, resulting in lower bounds induced for non-leaf nodes by elements within these nodes and upper bounds induced by ancestors and siblings of nodes. For each element, the minimum required width (lower bound), the desired width were there no constraints, and the maximum available width (upper bound) based on constraints of parents are computed, and an approximate width is derived therefrom. A positioning process positions each element within its corresponding parent container by advancing a cursor according to the elements' approximate width and appropriate constraints. The element that contains the most meaningful content is determined based on the amount of weighted content of elements and their position within the page. Microsoft Patent: http://research.microsoft.com/ap... As another example, a New York Times webpage may have a headline bar, sports, news items, and a copyright notice. A user may search for keywords such as “New York Times legal information.” There is probably some webpage on the New York Times web site that provides much legal information. But the keywords may also match a news page that does not provide the relevant search results. To provide more meaningful information about a webpage, it is useful to figure out that the webpage is mainly about the news item, and that the other content available on that webpage is slightly relevant but not the most important in that webpage. Thus, splitting up a webpage into different sections is useful to provide more relevant search results. http://patft.uspto.gov/netacgi/n... A classification system trains a classifier to classify blocks of the web page into various classifications of the function of the block. The classification system trains a classifier using training web pages. To train a classifier, the classification system identifies the blocks of the training web pages, generates feature vectors for the blocks that include a linguistic feature, and inputs classification labels for each block. The classification system learns the coefficients of the classifier using any of a variety of machine learning techniques. The classification system can then use the classifier to classify blocks of web pages. A nice extensive write-up of these patents, and their possible implications for SEO/webdesign, can be found here: http://www.seobythesea.com/?p=5168 We’re told in the patent that blocks with different functions often have different linquistic features. For example, a block containing navigation will usually have extremely short phrases and no sentences. The main content, which includes the primary topic of the page, will usually contain complex sentences. That main content section also often includes named entities, such as specific persons, places and things. Some types of blocks contain specific terms, such as a footer using the words “copyright,” “privacy,” “rights,” “reserved,” and so on. The terms “sponsored,” “ad” or “advertisement” can help a search engine recognize an advertisement block. The linguistic features may include parts-of-speech features, named entity features, symbolic features, and capitalization features. You could also take a look at Readability's source code, to get a global idea on how to extract relevant page elements: http://code.google.com/p/arc90la...    Embed Quote