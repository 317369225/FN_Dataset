★Is the most natural way to perform unsupervised learning to use generative models?From Kevin Murphy's book "Machine Learning: A Probabilistic Perspective", he says "The most natural way of doing [unsupervised learning] is to use generative models." (pg 999, last paragraph on page). Is this true and, if so, why?
I suppose that would be the way if you limit yourself to probabilistic models. But other non-probabilistic models have been shown to work equally well. For example,  in [1], soft k-means beat sparse RBM and sparse AE. But even for soft k-means, it is possible to give it a probabilistic interpretation... One thing that makes generative models really convenient for unsupervised learning is that you can compare the "data distribution" with the "model distribution" using some measure such as KL-divergence (or using your own eyes to examine the difference between "real data" and "generated data", if you prefer). So it's very easy to know whether our generative model is doing well. For other non-generative methods, you have to devise your own methods of evaluation, which may not be as theoretically elegant as (approximately) computing the KL-divergence or some other difference measure. [1] Coates, Lee, Ng, 2011, An Analysis of Single-Layer Networks in Unsupervised Feature Learning    Embed Quote