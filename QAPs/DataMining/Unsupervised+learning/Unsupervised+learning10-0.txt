★Is it possible for unsupervised learning algorithms to outperform supervised ones?Assume the same data set. If this has been done, please provide links.
I find this question hard to answer and maybe a little bit ill-posed because unsupervised learning and supervised learning are two essentially different learning problems. Their goals are different, their performance is evaluated differently, therefore one cannot really outperform the other as is. In probabilistic terms the difference between supervised and unsupervised is: Unsupervised learning is about learning something about a probability distribution p(x) based on samples from x. Supervised learning is about learning something about a conditional distributions p(y|x) based on samples from both x and y. Possible ways you can compare/combine the two: You can solve supervised learning problem (estimating p(y|x)) by applying unsupervised learning a joint model q(x,y) of x and y, and then computing a conditional model q(y|x) by marginalisation q(y|x) = q(y,x)/q(x). In this sense the resulting conditional model q(y|x) may be better than a model that directly aims at learning p(y|x). This distinction is often referred to as generative vs. discriminative learning, although I don't think there's consensus about what the terms generative and discriminative really mean. In semi-supervised learning you often have both labelled training examples (where both x and y are given) and unlabelled ones (where only x is given). Often the number of unlabelled examples is a lot bigger than labeled ones and you can assume that modelling the distribution of the input x will give you additonal power for predicting y given x. Generative models that model the joint distribution p(x,y) are often applied to solve semi-supervised models, and they are often superior to models built on supervised learning. Unsupervised pre-training in neural networks: Deep belief networks are neural networks that have been derived as probabilistic generative models, and can be used for unsupervised learning. However you can treat them also as a traditional neural network and train them as a supervised learning model. Often big neural networks are pre-trained in an unsupervised mode using inputs x only. The weights resulting from unsupervised pre-training are then used to initialise weights for the supervised training. In this case unsupervised learning acts as a kind of regulariser for the supervised learning algorithm.    Embed Quote