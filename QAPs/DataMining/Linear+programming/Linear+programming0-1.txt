★What is linear programming?
What a wonderful question! What exactly is 'linear' 'programming' (LP)? Let's take the classic problem that motivated the creation of this field to understand what an LP is: Given 'n' people who can do 'm' jobs with varying degrees of competence (think speed) what's the best allocation of people to jobs such that the jobs are completed in the fastest time possible? Let's time travel. Go back to 1950, mentally and "think" how you'd solve this problem. Genuinely think about it. You'd try some ad-hoc approaches by doing things manually but never be sure if you really have the "fastest" matching. Faster w.r.t. what? You may compare others and never be sure. You're wondering if all this could be cast as a "bunch of equations" that you can solve in some way, given an objective i.e., maximize speed of completion. That is, you don't want "a" solution to the system of equations, you want "the" solution that is optimum! That is, the highest/lowest value depending on the objective function (which could be to either, maximize or minimize something). These equations you come up with are rarely exact (read equalities). In most cases you wish to say that this equation is "less/greater than or equal to" some lower/upper bound. Reason? You want the "optimum" value. But optimum w.r.t. to what? You need a 'range' of values for comparison. Hence inequalities. If they're all equalities, you don't really optimize anything per se. You just "solve" the equations to compute the answer - there could be infinitely many solutions making it impossible to select the best one. But assuming that a solution exists, you'll always get that. Now, we have our "equations" which are inequalities. Let's call them constraints. Since you've "bounded" them, it makes sense to call them that. You also have an objective function that tells you whether you want the lowest/highest possible "best" solution. Anything remaining? Yes. Can these equations/constraints be arbitrary equations or do they have to obey certain "rules"? They do. In the case of LPs these constraints and the objective function (which is also an equation) must be "linear". Linear functions: Crudely speaking think of them as "lines" in cartesian space. Lines are quite cool, mathematically speaking. An intersection of 2 lines gives a single point, which is easy to compute. Given a bunch of lines, one can compute all the places that "line group" intersects. You want an example? If 5 apples cost $10, how much to 20 apples cost? Try solving this "geometrically": Apples on 'x' axis, and cost on 'y' axis. Draw a line from (0,0) to (5,10). Extend this line further and see what's the 'y-value' when x = 20. Simple! What if 5 apples cost $10 but 20 apples cost $2 (like in the US :)? This is NOT a linear relationship. The line says that the y-value should be $40 when x = 20. But not $2. This makes predictability much harder. You can see it'll get tricky very quickly if these relationships are not line based (i.e., nonlinear). So, if everything is linear (objective and constraints) what do I do next? You add a constraint for each of the variables - in 2D it's like adding equations for the axes (x = 0; y = 0) but you make it (x >=0 or  y>=0) saying that "any positive value would be okay. You then compute the value of the objective function at the intersection of the objective function and each of the "corner points" of all the constraints (conceptually speaking). The constraints will all intersect in a such a manner that they'll enclose a "polygon" (in 2D) of "all possible values of the objective function". Think about where the optimum value lies? At the corners! (Why? Think about it :) Now, all you need to do is compute "value" of the objective function at each of the corners of the "feasible region" (i.e., polygon above) and just find the max/min! Simple! So, if everything is "like a line" I can find a way to compute the maximum/minimum by simple equation solving! I can then come up with a proof of correctness that tells me that my optimum is indeed the optimum!! (Think, duality). But why is it called a "program". Well when this problem was given out by the DoD it was part of a "program". Linear functions were used to model/solve the problem and the program was referred to as a linear one. The name "linear program" has since stuck. The name just got carried on to Dynamic programming, convex programming etc., Now, Read what Justin Rising has written above and you'll understand why is the math the way it is. Hopefully this helps illuminate the abstract idea behind LPs and how fascinating they can be. Imagine being able to approximate existing real life constraints as linear functions, putting an objective on that and getting a value that can help make your real life decisions in the most optimal manner possible! It's just mind blowing :) Food for thought: Can objectives/constraints be non-linear? Arbitrarily or are there some rules there too? Think about it. You may fall in love with mathematical optimization as a whole (or hate it :) Best of luck!    Embed Quote