★What is the point of linear algebra?How can I motivate students to study this? Are there any tangible reasons why students should study linear algebra?
I'll start with a practical answer, but what I believe is the true answer is down at the bottom. One main point of linear algebra is that linear equations are easy to solve. Let me explain. Equations arise naturally all the time, for example when we try to model something in the world mathematically. Sometimes the equations will involve special functions of the parameters (trigonometric, exponential, logarithm, etc). But more often than not the equations are polynomials -- they involve only performing addition, subtraction, multiplication, and division operations upon the parameters, together with scaling various quantities by constants. This is quite reasonable, as a big part of why mathematics is a useful tool for describing the world is that the basic operations of arithmetic already yield enormous versatility. But there is some bad news: polynomial equations, while in some sense simple, can have exceptionally complicated behavior. An entire field of mathematical research (algebraic geometry) is dedicated to describing the shapes of the solution sets of systems of polynomial equations in many variables. The fact that a lot of effort is expended upon understanding these objects is at least heuristic evidence that understanding them can be nontrivial. In fact, another illustration of the complexity of polynomial equations is given by an amazing theorem: roughly speaking, any computation that you can perform on a computer can be encoded into the problem of finding integer solutions to a (very complicated) system of polynomial equations. More practically, when we have some equations that we care about, we often want to solve them. That is, we want to know if there is at least one solution, and if so, we would like to parametrize the set of all solutions in a convenient way. The unfortunate fact is that beyond the case of *linear* equations -- the domain of linear algebra -- solving systems of polynomial equations very quickly becomes intractable, even using a computer. To explain, let us consider the case of equations in one variable x. Solving a linear equation Ax + B = 0 is something most elementary school students have the capacity for (even if they don't learn the algebraic language until a little later). Solving a quadratic equation Ax^2 + Bx + C = 0 is part of the standard high school curriculum; in fact there exists a closed  formula for the two solutions (in the set of complex numbers) to this equation in terms of the coefficients A, B, C. A similar formula exists for cubic (degree 3) equations. But one of the great triumphs of early 19th century mathematics was the proof that as soon as the equation involves x^5 or any higher power, there can be no closed formula for its solutions (that is, there is no formula involving only extracting square roots, cube roots, etc., of various combinations of the coefficients). So solving non-linear equations is is general not a trivial task. Now when there is just one equation in just one variable, there's not really a problem; it's relatively easy to approximate the solutions to any desired degree of precision in an efficient way. (For example, the Newton-Raphson iteration we teach calculus students can do the trick.) The real issue is when you have a complicated system involving many equations in many variables. It turns out that when your equations are linear you can still solve them efficiently even when there are tons of them. To be precise, the time it takes to solve a linear system of equations is polynomial in the number of equations  or variables. When you remove the linearity condition and allow polynomials of higher degree, the best known algorithms for solving such systems take time that is exponential in the number of variables and equations. In other words, solving nonlinear equations on a computer is possible but often impractical in complicated situations. To sum up, linear algebra is important partly because it is the science of the only types of equations that we know how to solve easily. (Fortunately, many non-linear situations can be studied using linear methods. The best-known example of this is calculus, which is entirely about understanding curvy functions and objects using straight, linear approximations to them.) Like any good tool, linear algebra can be put to an incredible variety of uses. An (I think) elegant example is principal component analysis http://en.wikipedia.org/wiki/Pri..., but examples abound. Thus there is no shortage of tangible reasons for a student to learn linear algebra; in fact, like basic facts about chemistry, physics, and biology, I think one should be embarrassed if one does not know linear algebra. To compare with physics, Newtonian mechanics (notions of inertia, momentum, mass, etc.) is a *starting point* for modern physics, a basic tool in understanding where a baseball might go, or why a bird-versus-plane collision is worse for the bird. Likewise, in mathematics, facility with linear equations is prerequisite to just about any serious attempt to understand a situation mathematically. *** In an entirely different direction, another main point of linear algebra is that it is beautiful. Once you get behind all the B.S. with matrices and vectors, linear algebra might be defined as the study of objects where addition makes sense and maps between those objects which respect addition. An additive (i.e. linear) structure is one of the most pleasing structures one can have on a mathematical object. Partly this is because (as described above) we have wonderful tools for solving linear problems. But it's also nice because linear structures allow us to see and exploit analogies between mathematical objects that at first appear wildly disparate. Moreover, once you realize the ubiquity of linear algebra, you can even find amazing mathematical structures within linear algebra itself -- even if at first it seems like a simple theory. For example, Gaussian elimination (a basic technique in linear algebra) can lead to the combinatorics and geometry of Schubert varieties http://en.wikipedia.org/wiki/Sch.... Seemingly dry facts about matrices like the QR factorization actually reflect interesting structure results -- perhaps one day you'll learn about reductive linear algebraic groups and the Iwasawa decomposition http://en.wikipedia.org/wiki/Iwa... which generalized QR factorization. From the basic facts about inner products on real vector spaces one is led simultaneously to the rich theory of quadratic forms, and to the wonders of higher-dimensional Euclidean geometry. My point is this. Linear algebra is a marvelous tool for working with numbers, and that alone would justify it. But it is also a gateway drug into higher mathematics, where it is basically the lingua franca. (It would not be much of an exaggeration to say that the bulk of mathematical research consists in reducing situations of interest to known statements in either combinatorics or linear algebra.) Moreover, as an intellectual edifice built up from humble beginnings over the last 300 years or so, linear algebra even exhibits its own sort of beauty --- albeit all too often obscured when the subject is taught as a set of rules for manipulating rows and columns of figures.    Embed Quote