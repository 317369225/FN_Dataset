★What is an intuitive explanation of the latent Dirichlet allocation's graphical model?
Watch David Blei's MLSS2009 cambridge talk on  Machine Learning Summer School (MLSS), Cambridge 2009 Watch the first video multiple times till you get a feel of it. :P It is well explain and an eye opener. It also gives the feel of bayes rule. Informally, Like you can generate documents from the model given the parameters. so the direction of generation is from parameters to documents. What bayes rule enables us is the change of that direction and to model the uncertainty in parameters given the documents. On dependency from question description: If you see the graphical model, there is only one V-structure in the plate model, and that node is observed. That makes everything dependent. The words are sampled from topics so there need to exist a topic from where we can sample. So we sample a distribution over topics. Now we have a distribution over topic so we can sample a topic. Once we have sampled a topic which is a distribution over words, we need that distribution which is beta. If we dont have beta we dont have a distribution over words, so we cannot sample words.  If you did not understand what I wrote here, you can refer video lectures by daphne koller on Probabistic Graphical Models at coursera to understand dependency in graphical models. Understanding LDA can pay off as it has a lot from directed graphical model(All types of dependency, plates, approximate inference). I  would also suggest you to read standard text on bayesian statistics  like "The Bayesian Core" or for more complete stuff "The Bayesian  Choice". Also read about graphical models and inference. Blei's  JMLR paper uses variational inference and possibly a mean field  approximation if you see the appendix.(Although this is not a big deal  but first timers dont get what q was, q is a surrogate distribution used  as an approximation to true model distribution). So read about them  before you visit the appendix. MLSS2009 is a gem try watching as much as you can. You will know what you dont know and also understand more.    Embed Quote