★What is the relation between a probabilistic graphical model and neural networks?
Here's the simple answer: both are ways of predicting effects arising from multiple causes. In neural networks, you care about what the network will do (predict input-output bindings correctly). In probabilistic graphical models, you care about what the network is (which nodes connect to which, which connections are stronger). You can constrain a PGM to do what the NN does, and you can torture an NN to get at some of the information a PGM would give you. How requires some explaining. That brings us to the complicated answer: I'm going to simplify the question a little bit by only dealing with neural networks that do supervised learning and PGMs that are directed acyclic graphs. This will omit unsupervised NNs and Markovian PGMs, I know, but the similarities between the two arise primarily in the subset that I will consider here. Let's say I like a girl I know through N mutual acquaintances, and want to ask her out on a date. Being low on self-esteem, I want to ask some subset of our mutual friends to boost me to her. However, a referral from someone she mistrusts may have only a weak positive influence, while a referral from someone she dislikes might even have a negative impact. Now suppose n of my friends have already had the same idea, and have tried doing this before (assume, for the purposes of this argument, that the young lady in question is unbearably desirable). So I have in my possession, a set of observations, which I can compactly represent as an n bit vector {1,0,1,0 ....} where 1 is a boost, 0 means no contact. The computational problem I need to solve is to find the set of friends that I should ask to boost me, i.e. the best vector. Note that this need not be one of the n vectors already tried. I could try solving this problem using a neural network: the input layer would have N nodes that obtain the appraisal input, the output layer would be the girl's response (again binary), and I can throw in a hidden layer of M neurons that all have N connections back up to the input layer, and encode various quanta of me-friend-girl dynamics that when pooled together in M forward connections to the output layer, determine her interest in me. When I train this neural network with the n vectors I have, I will learn weights between 0 and 1 on the NM input-mid-layer connections and the M mid-layer-output connections. Intuitively, combinations of inputs that predict the output well (say her 3 closest friends) will be repeatedly reinforced, and will become bigger across n observations. So will the weight corresponding to the mid-level neuron that is receiving inputs from specifically that clique. However, there will be no easy way of knowing which of the M mid-layer neurons contains the 3-closest-friends information. The NN will function as a Delphic oracle - you can ask it about the fate of individual vectors, but not for reasons explaining its prediction. I could also treat this problem as one of Bayesian reasoning, where I potentially receive observations of approval from N nodes, which leads to the formation of an impression (a random variable), which causes date acceptance (an observable event). In this case, I get to see the likelihood probability p(approval from friend i|impression), from which I have to estimate the conditional posterior probability p(impression|vector of all approvals) using Bayes theorem. Going from p(approval i|impression) to p(all approvals|impression) though, is hard. Usually, machine learners tend to assume conditional independence for all i approvals, i.e. p(all approvals|impression) = product of all p(approval i | impression). This is simple to compute, but gives up on the possibility of modeling non-trivial correlations between inputs. For example, if hearing good things from either A,B and C or from C and F, but not from A and C together impresses the girl (assume that the girl's social life is extremely rich), such effects won't show up in such 'naive' Bayesian predictions. To summarize, in any situation where a number of causes could contribute to an observable effect, you can try to learn the structure of cause-effect using either a neural network or a Bayesian model. Thus, the key similarity between NNs and PGMs is that they can both be used to learn network functions. The key difference in structurally similar NNs and PGMs is that NNs naturally allow inference over arbitrary combinations of input features, by giving up on the necessity of intermediate computations making sense. On the other hand, PGMs, for technical reasons, restrict themselves to a limited set of hypotheses about connections between the inputs, but will give you detailed intermediate predictions about how likely the individual inputs will be to generate the effect.    Embed Quote