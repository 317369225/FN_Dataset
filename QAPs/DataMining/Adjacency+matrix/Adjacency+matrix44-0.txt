★How can you run analysis on graphs located on multiple servers when you need the entire graph and not a subset of it?For example, Pagerank.  Its impossible google has everything on one machine yet they need all the nodes in the graph to generate pagerank for the web.  I think there are many other examples of graph analysis when you need the entire dataset, how do you deal with it when its too large for one machine? Strategies or tools would be great to know
There are two options available: 1. Divide the problem into pieces that can be parallelized using something like MapReduce or Hadoop. However, in my experience, mapping graph algorithms to MapReduce can be a very difficult task -- it mostly amounts to converting the graph to an adjacency matrix representation (http://en.wikipedia.org/wiki/Adj...) or adjacency list representation (http://en.wikipedia.org/wiki/Adj...), finding separable parts of the graph and executing the algorithm. 2. You can use a graph-oriented parallel-programming architecture. One of these is Pregel, which is used at Google and amounts to implementing PageRank in 15 lines of code or so. Here's a paper describing Pregel: http://kowshik.github.com/JPrege.... There is also an attempt at an open source version: http://www.prweb.com/releases/20....    Embed Quote