★What is the state of the art in monitoring Hadoop clusters?
Look at the logs, there's a wealth of information. There's Chukwa and Failmon (a Hadoop contrib project) but you need to deploy a second hadoop cluster to monitor the first in both these cases. However the monitoring cluster typically needs only to be a fraction the size of the monitored cluster. With X-Trace you need to modify Hadoop; last I tried, the patches available provided only part of the X-Trace message generation but not everything. Ganglia will give OS-level monitoring of basic CPU, disk, network numbers, which is very useful. On top of that, I would recommend keeping track of netstat's figures but you might need to roll your own code to sample and parse the numbers; there might be a Ganglia plugin for that. There's also the JMX metrics that Hadoop already emits, you can run the Java Management Console or something like that to collect the statistics from Hadoop as it's running. I haven't heard too many people discuss that, it might be one of the underrated monitoring features available.    Embed Quote 