★Natural Language Processing: What is the best approach for text categorization?There are standard approaches like svm, naive bayes, logistic regression, neuron network. Features come from words, phrases scored with tfidf e.t.c. Is there are any more robost and scalable approach?
First of all, I wouldn't say that SVM-based categorization methods are not robust. They have proven to be very accurate and perform particularly well in cases when the number of categories is within a few hundreds, and training data is available for each category. As you move towards text categorization, where thousands if not hundred thousands of categories are required, and training data is limited to a subset of these, this task turns into term assignment or subject indexing, as used in Information Science. This task is usually solved using quite different methods, which easily scale with respect to vocabulary size. The vocabulary plays an important role, as it usually encodes not just the category names but also the alternative names of those categories. For example, if somebody searches for the category "South America", they might be redirected to a category "Latin America" (even if not equivalent). The algorithms that match documents to categories utilize such information as well. The way such algorithms work is by defining a set of candidate categories for a document and then ranking them based on pre-defined criteria, using machine learning or fixed formulas.    Embed Quote