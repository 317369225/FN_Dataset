â˜…How does natural language processing work?
Transcription of the Introduction from Chapter 3.1.0 - 3.1.1 of Exploring Artificial Intelligence in the New Millenium (Morgan and Kaufmann) Learn NLP with NLP with the EnFind Chrome Extension Recent years have been exhilarating ones for natural language understanding. The excitement and rapid advances that had characterized other language-processing tasks like speech recognition, part-of-speech tagging, and parsing have finally begun to appear in tasks in which understanding and semantics play a greater role. For example, there has been widespread commercial deployment of simple speech-based, natural language-understanding systems that answer questions about flight arrival times, give directions, report on bank balances, or perform simple financial transactions. More sophisticated research systems can generate concise summaries of news articles, answer fact-based questions, and recognize complex semantic and dialogue structure. But the challenges that lie ahead are still similar to the challenge that the field has faced since Winograd (1972): moving away from carefully hand-crafted systems toward robustness and domain-independence. This goal is not as far away as it once was, thanks to the development of large semantic databases like WordNet (Fellbaum 1998) and of general-purpose domain-independent algorithms like named entity recognition. Current information extraction and dialogue understanding systems, however are still based on domain specific frame-and-slot templates. Systems for book airplane information are based on domain specific frames with slots like FROM_AIRPORT, TO_AIRPORT, or DEPART_TIME. Systems for studying mergers and acquisitions are based on slots like JOINT_VENTURE_COMPANY, PRODUCTS, RELATIONSHIP, and AMOUNT. In order for natural language understanding tasks to proceed beyond these specific domains, we need semantic frames and semantic understanding systems that do not require a new set of slots for each new application domain. In this chapter, we describe a shallow semantic interpreter based on semantic roles that are less domain specific than TO_AIRPORT or JOINT_VENTURE_COMPANY. These roles are defined at the level of semantic frames (see (Fillmore 1976) for a description of framed-based semantics), which describe abstract actions or relationships along their participants. The interpreter itself is a statistical classifier that is trained on sentences annotated with role labels. We first parse sentences with the Collins parser (Collins 1999) and then train a statistical classifier based on the output parse to label the semantic roles (e.g., AGENT, PATIENT, INSTRUMENT, PROPOSITION) in the input sentence. The semantic classifier is trained on 50,000 sentences that were hand labeled with semantic roles and uses features derived from the training set (e.g., the probability for each verb, noun, and adjective taking a particular compliment type). 1.1 Approaches to Natural Language Understanding Modern approaches to natural language understanding may be grouped into two classes: domain-independent, logic-based systems, and domain-dependent statistical systems. In the first class, logic-based, or symbolic, systems have the goal of producing a deep and rich semantic and pragmatic interpretation of a text. They generally use representations based on predicate logic and include hand-built knowledge structures and inference patters necessary to understand the meaning of connected texts. In the second class, systems typically forgo such deep representations in favor of directly modeling the task to be performed. These systems tend to reformulate the task of understanding as a pattern-recognition problem. These tasks are then addressed by machine learning techniques, allowing systems to be trained directly from examples of input/output pairs. An early paradigm of a deep and rich representation of meaning is ... (more)Loading...