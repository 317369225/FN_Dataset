★What exactly is Deep Natural Language Processing (DNLP)?See also: What are good examples of shallow natural language processing (SNLP)?
Bill Skaggs hit this one on the head pretty well, but I will try to take a look at this from a computer science point of view. The goal of computational deep natural language processing is to allow computers to be able to understand/extract information from human language on a depth that goes beyond the simple substitution of words. This extraction can then be used to generate queries, summaries, and even natural language sentences. For example, consider the sentence: "Contrary to before when it wasn't feeding them at all, Apple is now using resources to feed its employees meals of steak and chicken." This would be easily translatable by most people to know that Apple, Inc. is now feeding its employees compared to before, when it wasn't. A computer extracting the information from this sentence without using DNLP (and thus simple/shallow language processing) could take this same sentence and conclude a few incorrect possibilities, including: Apple is the name of a person or is an object. Apple is a food company. Apple is feeding its employees now. (now as in the exact current moment of time versus now as in a general time period) Apple is feeding its employees steak and chicken made of resources. Before, Apple wasn't feeding its employees at a location called 'all'. Moreover, most humans would also be able to glean from that sentence that Apple is feeding its employees well - steak and chicken are hardly a yeoman's diet. A computer processing the text shallowly would be unable to conclude this. Let's now say someone wanted to find local places to eat. They could use three (of many) different approaches: I want all the restaurants within a 5-mile radius. Show me some close by locations to eat at. Display food places nearby. A human would know that the end result of all three requests should be approximately the same listings of nearby restaurants - but notice how there are absolutely no shared words between the sentences. Shallow language processing becomes futile given the high amount of variability. A computer would need to use DNLP to extract a common target: 'restaurants', and apply a common intent: 'find_nearby'. Only then would it be able to process each different sentence to give the same requested information. Thus the goal of DNLP is an algorithmic approach to help machines understand language using natural human tendencies of information extraction including (but not limited to) intent, pertinent past information, and context. It goes beyond a simply syntactic approach (shallow language processing), and focuses on a semantic approach. The applications of DNLP are quite extraordinary. Given the proper DNLP algorithms, computers could theoretically: generate natural language and thus be able to compose articles, and even novels based on a simple basic set of entry data summarize huge pieces of information into smaller chunks give natural responses to questions and queries (as if you were speaking to another person about the topic) Think Rosie from the Jetsons.    Embed Quote