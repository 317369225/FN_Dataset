★Natural Language Processing: What are the most important research papers which all NLP students should definitely read?Which NLP research papers (no matter whether classic or state-of-the-art) do you recommend students to read, if you were a teacher/professor/adviser? And why?
I honestly think that there is no single research paper that every NLPer should read. NLP is such a broad field that no person can specialize in everything, and research papers are, by nature, rather narrowly focused. However, in certain areas, there are classic papers that should certainly be read by everyone in the area. Here are a few that I particularly like (out of my admittedly biased and limited bag of tricks). Parsing Klein & Manning: "Accurate Unlexicalized Parsing" (shows that lexicalization is not necessary to achieve reasonably good parsing accuracy) Klein & Manning: "Corpus-Based Induction of Syntactic Structure: Models of Dependency and Constituency" (a revolution in unsupervised dependency parsing) Nivre "Deterministic Dependency Parsing of English Text" (shows that deterministic parsing actually works quite well) McDonald et al. "Non-Projective Dependency Parsing using Spanning-Tree Algorithms" (the other main method of dependency parsing, MST parsing) Machine Translation Knight "A statistical MT tutorial workbook" (easy to understand, use instead of the original Brown paper) Och "The Alignment-Template Approach to Statistical Machine Translation" (foundations of phrase based systems) Wu "Inversion Transduction Grammars and the Bilingual Parsing of Parallel Corpora" (arguably the first realistic method for biparsing, which is used in many systems) Chiang "Hierarchical Phrase-Based Translation" (significantly improves accuracy by allowing for gappy phrases) Language Modeling Goodman "A bit of progress in language modeling" (describes just about everything related to n-gram language models) Teh "A Bayesian interpretation of Interpolated Kneser-Ney" (shows how to get state-of-the art accuracy in a Bayesian framework, opening the path for other applications) Machine Learning for NLP Sutton & McCallum "An introduction to conditional random fields for relational learning" (everyone should know CRFs, and this paper is the easiest to understand) Knight "Bayesian Inference with Tears" (explains the general idea of bayesian techniques quite well) Berg-Kirkpatrick et al. "Painless Unsupervised Learning with Features" (this is from this year and thus a bit of a gamble, but this has the potential to bring the power of discriminative methods to unsupervised learning)    Embed Quote