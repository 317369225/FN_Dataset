★What is the difference between Bayesian and frequentist statisticians?
The more I reflect upon the divide between Bayesian and frequentist statistics the less I am convinced that there is a serious divide between the two. Yes, there are undoubtedly conceptual differences but not enough to arouse the amount of animosity between both "camps" that exists, and these differences seem smaller in magnitude compared to the differences between a design vs. model  or parametric vs. nonparametric approach. Furthermore, most modern statistical frameworks seem to blend the two in some way, as will be discussed. Let me begin by summarizing how (parametric) Bayesian and frequentist statistics are similar. In either case one specifies a distribution for the observed data given a set of parameters which may fall into two categories: those we care making an inferential statement about, and those that are there for the sake of the mathematics of the model, typically termed "nuisance" parameters. Viewed as a function of the parameters this is termed the likelihood function and is common to both the Bayesian and frequentist viewpoint. However, the parameters of interest are interpreted differently in either camp. From a frequentist viewpoint these are fixed but unknown quantities. From a Bayesian viewpoint these are random variables. Hence, Bayesians are afforded the convenience of basic probabilistic computations when deriving quantities like "credibility intervals" and getting rid of nuisance parameters, but must specify a prior probability distribution.  Most importantly, a Bayesian makes inferences conditional on the data observed but (typically) does not consider hypothetical data sets that were not observed. In contrast, a frequentist may evaluate a particular estimator by considering the distribution underlying the data generating process. For instance, Fisher's classical result posits the distribution of the MLE  is approximately normal with variance prescribed by the inverse of the Fisher Information, the average curvature of the log-likelihood function. Someone who believes in the likelihood principle (i.e a Bayesian) would most likely care only about the observed fisher information -- the curvature of the log-likelihood in one's experiment, not an average over all experiments. For another example, a confidence interval either does or does not trap the "true" parameter once data has been collected, but may have a certain coverage in the long run if the procedure is conducted under a stationary data generating process. In contrast, mathematically a credibility interval contains the inferential parameter of interest with a prescribed probability, but this does not imply anything about how the procedure behaves in the "long run". Decision theory seems to merge the two in some ways. The Bayes risk of an estimator is the average risk over the prior distribution, which is equivalently the average of the average posterior loss over the data. Furthermore it turns out that the Bayes rules are the admissible estimators (this is called the complete class theorem), where loosely an admissible estimator is one such that there exists no estimator that has strictly smaller risk, no matter what the "true " parameter is. There are some asymptotic results about the posterior distribution as well. Asymptotically, the posterior distribution can be approximated by a normal distribution with the MAP as the mean and the inverse of the observed fisher information as the variance. Additionally if one posits the existence of a "true" theta and assumes that data collected are i.i.d samples from a likelihood then it turns out that the posterior distribution contracts exponentially fast to the "truth" with very weak conditions on the prior distribution one chooses. In some sense, I believe the distinction between the Bayesian and frequentist viewpoints can be understood with an analogy to the Copenhagen interpretation of Quantum Mechanics, where one believes the true state of nature is inherently probabilistic. However, in Quantum Mechanics it is possible to do an experiment which is consistent with this claim such as the double slit experiment. In such an experiment, a diffraction pattern is observed even when only a single photon passes through the double slit at a time, consistent with the view that the photon's wave is interfering with itself. I am not sure if an analogous experiment could be conducted to determine whether or not a statistical parameter is inherently probabilistic, but it is an interesting question to ponder.    Embed Quote Updated 19 Mar. 3,902 views.