Bayesian Inference: In what way is Bayes' law unscientific?
Bayesian methods were aggressively attacked during the 20th century, and in many fields to this day, because they force you to confront your assumptions. And assumptions have a regrettable reputation of being "unscientific". Let's recall the basic procedure of Bayesian inference -- one starts with a prior that encodes the current knowledge of a system, and then updates that knowledge via a measurement of data described by a likelihood function.  The prior is no less scientific than selecting initial conditions when solving a differential equation [1], but choosing a prior forces a scientist to formally determine what is known and few have any experience in that.  What, for example, does it mean to have no information about a system?  Without a formal definition of ignorance, everyone develops different heuristics that can lead to conflicting results [2]. Of course the choice of likelihood is an assumption as well, and it can introduce just as much "subjectivity" as the prior.  Note that classical statistical methods use that same likelihood function, only its subjectivity is never addressed.  The sensitivity of the classical results on the assumptions were never addressed [3] and the statisticians flew the false banner of "objective scientific inference". In the end, you can't do inference without making assumptions [4].  Bayesian inference formally embraces these assumptions and consequently admits powerful techniques such as model comparison and marginalization.  Classical methods, on the other hand, mostly ignore the assumptions behind a facade of "scientific objectivity" that seduced scientific thinking for most of the 20th century. Yes, Bayesian inference was considered "unscientific" at one time, but only because "scientific" was defined as an unobtainable ideal. [1] These "differential equations" require initial conditions in order to determine a final solution?  What if our initial conditions are different!  Let us never speak of them again. [2] This is really the biggest issue with priors.  While every reasonable property of "ignorance" that has been introduced, from Haar measures to Jeffreys priors, yields the same measures, those measures can't be normalized and can introduce numerical problems into the inference.  This indicates that there's something fishy about doing inference on and there is interesting work on generalized measures that avoid these issues. [3] Sensitivity analysis in classical statistics is not unheard of today, but it is still exceedingly rare [4] I believe this is attributed to Stephen Gull.    Embed Quote Updated 25 Jun, 2014. 5,800 views.