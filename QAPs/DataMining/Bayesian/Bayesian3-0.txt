★How do Bayesian algorithms work for the identification of spam?
So far, Jinghao Yan has given an excellent description of the how we would use a Naive Bayes (NB) classifier to deal with spam (see also [1]). In this answer, I'd like to develop a stronger notion of the challenges inference algorithms must face when they deal with spam. Foolish assumptions: I will deal (mainly) with the algorithms insofar as they are related to the content of the spam messages. This stands in stark contrast to dealing with the context of a message, like improperly-formatted packaging, detection of Domain Keys spoofing, and analysis of location of sender and time. I will deal with spam as an issue of the inbox, rather than the outbox. Mail providers expend a good amount of effort making sure their servers are not used to send spam, but we will not cover such concerns here. I will deal with spam as an issue of email, rather than, say, text messaging. I will deal mainly with the issues of building scalable machine learning algorithms, mostly ignoring the (critical) human component. Part 1: Problems that spam classification must deal with  Scaling machine learning (ML) algorithms is often tricky from an infrastructure perspective. Before we deal explicitly with the methodology of actually building a model, it's important to understand the issues that could cause additional scalability problems. I'll cover some of the problems anti-spam teams have confronted historically to give you a flavor of such problems they might deal with. It is not intended to be comprehensive: Issue 1: Spammers adapt quickly When researchers at Hotmail first introduced ML-based classification techniques, spammers would avoid using high-weight words like "free" and "sex" by obfuscating them, for example with HTML comment tags embedded between characters (e.g., "free" -> "fre<!-- -->e") or by substituting characters with ASCII codes (e.g., fre&#101x). Researchers report [2] that in 2003, this trick accounted for 5% of all spam coming into Hotmail. They introduced a "fix" for the problem, and by 2004 it had dropped back down to almost nothing. These researchers note that when they deploy countermeasures, the spammers "actively adapt, dropping techniques that do not work". An ideal system must allow the spam team the flexibility to address rapid methodological changes of spammers. Issue 2: For large providers, there is a LOT of spam One estimate[3] pegs the total spam emails sent in a given year at 62 trillion in 2008. To put that into perspective, generating and dealing with that data accounts for around 33 terawatt hours, which is equivalent to the energy usage of 2.4 million homes or 3.1 million cars over a year period. Dealing with this amount of data is very challenging, especially in an domain like ML, which usually requires very expensive algorithms to run well. An ideal system must allow users to run on lots and lots of data, possibly with tens of thousands of features. Further, due to issue 1, we may be required to repeatedly update the weight vector in order to address current spam issues. Issue 3: There is no "winning" type of misclassification. If your aunt marge sends you email to tell you that your mother has died, and we mark it as spam, it's disastrous. If you receive an inbox with a few spam every day, it's disastrous for the brand. (Think of how much more fond we are of Gmail than Hotmail!) All things equal, it's probably more expensive to misclassify legitimate email as spam, but in general your system should just work. The ideal system is just perfect, in spite of the fact that, at scale, there is a lot of different types of email, and it needs to work in virtually all situations. Consider that most gmail users are actually pretty happy with their spam situation. Aggregated over millions of users, the rarity of a truly bad case is actually really impressive. Issue 4: Getting accurate data can be challenging It's easy to pick the low-hanging fruit (e.g., training with email found in the TREC), but finding the spam that is pushing the algorithms can be a bit of a challenge. Spam teams often set up honey pots to catch spam messages, and there is of course the "report spam" button, but spam teams are always on the lookout for better methods of finding examples of spam. Issue 5: "Spam" is not always well-defined Is spam just unsolicited viagra ads? Do we include phishing schemes? How do we differentiate from list emails sent out by, e.g., Barnes & Noble, and regular spam? (That is to ask, are we differentiating between "professional" spam and stuff like the Nigerian Prince?) The more groups we include, and the more different they are, the harder it is to get right. Operating at scale, an ideal system will need to confront the issue that their decisions about what is and is not spam have impact. Companies get upset if you block their "solicited" emails for millions of your customers, for example. On the other hand, you want users to be happy. Part 2: Selecting the basis for a model Early spam models used pretty traditional techniques like word or n-gram-based classifiers. This technique is sensitive to a huge number of exploitations, the main one being (as we saw in the first bullet point) that you can use a number of complicated obfuscation techniques to about the highly-weighted terms. So how do we get around this? One alternative to this model is to use compression-based models, which at least one prominent investigation [4] shows is much more effective than traditional (word- or n-gram-based) ML techniques. The basic idea is that you build a compression model for "spammy" email, and compress a given message using that model; the messages that compress the best are most likely spam. Intuitively, it is not obvious why this would be better than word-segmented ML techniques. One reason is that compression models are more sensitive to things like character encoding and composition of words. Consider, for example, that an n-gram model will depend on there being a constituency of "high-weight" words, but it will be unable to notice that f<!-- -->ree! and fre<!-- -->e! are actually both the same thing. In contrast, a compression-based model will notice that both such things contain <!--, which it will incorporate into its classification decision -- if there are many such sequences, it will compress better and thus is more likely to be reported as spam. It's been a few years, but in around 2006 Dynamic Markov Compression seemed to be the best, though it is worth noting that other similar techniques, like Prediction by Partial Matching (PPM), tend to be nearly as effective. If you're interested in actually implementing this, the paper at [5] gives a good overview. Of course, there are also downsides: these models tend to consume a lot of space, particularly in cases where there is lots of data. These models can also take a long time to train, although nowadays we have at our disposal techniques like Sequential Conditional Generalized Iterative Scaling, which in the case of the former makes training over even very large data sets doable in just a few hours. Another problem is that compression models does contain information about the messages it operates on. If you are really concerned about privacy, it may be worth your while to keep the model under lock and key. Part 3: Tuning and training the model A good approach is probably highly heterogeneous from the core algorithm up. For example, in one case [6] researchers used one filter specifically for identifying easy cases, and another for identifying hard cases, and reduced total spam by 20%. This intuitively satisfying: if you're really measuring two things, then it makes sense that you'd get more spam by making two filters than you would by using one. But there are other reasons this is practical, too. One particular approach is that it's faster from the researcher's perspective. I could spend a ton of time tuning one model, or I could divide up the team and tune up both models simultaneously. Then there's the fact that tuning the models themselves will take less time, since each model will probably require less data to tune individually than the big one does. It's hard to say where exactly the state of the art is, but I will say that it seems unlikely that industry has moved completely away from compression-based models. They may actually use many sorts of models, but this should give you a rough estimate of the sorts of things that go into building a spam classifier. This seems especially true when you consider that this information gives us a good starting point for dealing specifically with the problems I brought up in section 1. PLEASE, feel free to offer suggestions or hit me up over email for clarification. I'm new here. [1] The Manning/Raghavan book, Introduction to Information Retrieval also goes over NB in a way that is perhaps relevant here. Look at chapter 13, available here:  http://nlp.stanford.edu/IR-book/... [2] http://ceas.cc/2004/165.pdf [3] Funded by McAfee and ICF International; perhaps biased, but a good discussion point nonetheless http://img.en25.com/Web/McAfee/C... [4] http://jmlr.csail.mit.edu/papers... [5] http://citeseerx.ist.psu.edu/vie... [6] http://citeseerx.ist.psu.edu/vie...    Embed Quote Updated 4 Aug, 2012. 6,354 views.