★The Technological Singularity: Will self-aware, intelligent, sentient artificial intelligence be sociopathic?
A brief synopsis of how Artificial General Intelligence (AGI) will emerge from the march of Artificial Intelligence (AI) can shed some light on this general issue. The path to AGI will be a progression, not a quantum leap (no pun intended). As noted, we currently have various algorithms/systems/tools/devices that exhibit aspects of intelligence, and even some emergent social behaviors. In an increasing number of cases, specialized systems far surpass human abilities. This will proliferate at a rapidly accelerating rate, as will the abilities of existing systems. By way of example, consider the progression of speech recognition. For the last several decades, progress has been painfully slow. The mechanical ability to convert a spoken word into its text equivalent, a necessary first step, began to appear in specialized situations and matured over two decades to the likes of Siri, et al. As an aside, before this came to pass, this technology was considered AI. Within the last decade, semantic abilities emerged. In addition to algorithmic improvements, semantic and other corpora became available and are maturing rapidly, as well as proliferating to an increasing number of languages. In just the last few years, the ability to accurately detect sentiment and other subtle aspects of speech has emerged. Today, Natural Language Processing (NLP) is not an uncommon aspect of a Software Engineer's tool kit (and to many, is no longer considered AI). Note the shrinking time frames and the continual raising of the bar for what is considered AI. Analogues of this are occurring in all disciplines. This is accelerating the rate of convergence points, where advances in multiple disciplines can be combined to create new possibilities (e.g., protein folding). Over time, the various underlying aspects of what is believed to be required for an AGI will appear and mature within their respective areas. For example, NLP will become increasingly widespread and accurate, soon surpassing human abilities to detect semantic content. Expert Systems (ES) is an area where human-like behaviors are beginning to emerge. The ability of some of these systems to draw sophisticated conclusions, that include embedded moral judgments, is constantly improving. The operative word here is embedded. The ES is not making a moral judgement, the knowledge base, or rule base, includes moral judgments. ES-specific convergence points will occur. First, related ES knowledge bases will merge and then related inference engines will merge. Over time (recall the shrinking time frames for advances in speech recognition), the convergence points will become increasingly general. In particular, nascent generator technologies, software that can create or enhance a rule base, will blossom. As this process unfolds, undesirable conclusions or behaviors will continually be engineered to acceptable levels or eliminated entirely. ESs will be shaped to conform to societal norms, including the addition of behaviors such as politeness (i.e., improving the User Experience (UX)). We will pass through a period when there are multiple near AGIs (NAGI) that are generally intelligent, but have obvious major flaws relative to human intelligence. These flaws will be engineered out, first reaching an acceptable level for use in specific situations, and then eliminated. For example, a NAGI that can calm an agitated caller and then talk with them about an insurance claim before passing the caller to a human adjuster. The fear mongering around AGI ignores temporal realities. We will have ample opportunity to shape AGI morality long before any AGI matures beyond our control.    Embed Quote 