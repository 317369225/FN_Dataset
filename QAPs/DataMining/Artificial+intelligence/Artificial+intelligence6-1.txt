★What is artificial intelligence?
Artificial Intelligence (AI) is sometimes distinguished from Artificial General Intelligence (AGI) because the term intelligence is used so often in marketing and design of technology. Anything programmable can arguably be referred to as 'intelligent', since, for example, a thermostat which you have to manually adjust is 'dumb' compared to one which can store a week's worth of times and temperatures. A credit card with an embedded chip that stores data and runs applications is a 'smart card' in comparison to a card that lacks any chip. The original intent of AI is to refer to a manufactured device which performs mental tasks as well as or better than a human being. It is unclear to me whether AGI refers to this Weak AI concept or to Strong AI (coined by John Searle in his Chinese Room Argument) which would go beyond merely simulating the skills of a human being, but would actually have a human-like understanding of what it is doing. Also called Computational Theory of Mind or Computationalism, Strong AI is a philosophical rather than scientific position, since it is debatable whether such an additional quality of awareness is testable. Some debate whether a quality of subjective understanding even exists as an additional phenomenon and believe that all of our human psychological experiences can be accounted for entirely, or will be accounted for eventually by a complete knowledge of computation, information, and/or physics. The "Turing Test" is a popular notion derived from Alan Turing's 1950 Computing Machinery and Intelligence paper.  In the paper, Turing talks about an Imitation Game in which a human judge is pitted against a computer and a human to see whether they can tell them apart using only text conversation through a terminal. Unfortunately, in 60+ years, we still have not progressed much beyond this initial quick-and-dirty idea for evaluating human consciousness vs machine behavior, and there is a lot of play in judging. In a recent article that made the rounds, for example, a computer program which was promoted as having 'Passed the Turing Test' led judges to believe that they were talking to a child for whom English was a second language. Strong and Weak AI run parallel, in some respects to the concepts of Strong and Weak Emergence, in which the difference between Weak and Strong AI is thought to arise in a way that is unexplainable from the lower (Weak) phenomenon, or if it can be explained conventionally. This gets deeper into the philosophical arguments such as David Chalmers work on Easy and Hard Problems of Consciousness, Panpsychism, philosophical Zombies, Frank Jackson's  Knowledge Argument (Mary's Room), Thomas Nagel's What Is it Like to Be a Bat?. All of these, and others are attempts to drill down on the difference between objectively derived phenomena and subjectively derived phenomena, a difference which may literally not be possible for everyone to relate to. Alfred Korzybski's Map–territory relation can help make the distinction between abstract information and concrete realities, but under computationalism, the human brain is seen purely as a biochemical computer, so that even our concrete realities would be expected to be composed purely of information. In my mind, this clearly begs the question of computationalism, and the fact that we can even question that there is a difference between information and qualia, when we have no problem recognizing information as abstract should be at least a yellow flag.    Embed Quote