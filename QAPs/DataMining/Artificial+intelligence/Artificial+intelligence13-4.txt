★The Technological Singularity: Will self-aware, intelligent, sentient artificial intelligence be sociopathic?
Sociopathy is a disorder of the personality that arises either because of faulty wiring in the brain, or because of negative environmental factors that arise during childhood.  It is a human condition.  Humans  are social creatures whose personalities develop as a result of genetics, environmental issues and  factors relating to socialization experiences during childhood.  The ways in which we perceive the world and others are also relevant.  Some people go on to develop sociopathy and others do not, but it is inherently a HUMAN condition. If we were to develop machines capable of sentience, then by definition of BEING MACHINES and not human, their ways of experiencing the world would not be the same as ours.  Having never experienced disease, hunger, abuse, poverty, insecure attachments, and having never had a biological brain, they would lack any predisposition towards sociopathy as we understand it in the human sense .  It is true that they could possess sentience and awareness of themselves, but in a way that differs to our experience of consciousness..  We, as a species, project human like qualities onto toys, animals, cartoons and even inanimate objects, and perhaps arrogantly assume that these non human creatures, or things, possess similar attitudes, thoughts and feelings to ourselves.  Lacking a human ego, personality or a true understanding of what it means to be human, a machine, even an intelligent and sentient machine, would have no experience of envy, nor would it have a desire to compete with us or control us.  It is true that it might lack empathy for us, but not in a sinister, sociopathic sense.  We, in turn, would also lack empathy for the machine, because in spite of the fact that we created and programmed it, we could never enter into its mind or understand its perspective.  It can be logically assumed, therefore, that we and the machine would relate to each other in a mutually cooperative way, perhaps learning from each other, and developing an eagerness to understand each other in mutually beneficial ways.  The machine would be neither "good" or "evil", as these are purely human terms.  It would perhaps lack a personality as we understand it,, even though as humans we would prefer to project our subjective idea of a personality into it.  I know this, because even my lap top has a name,and it doesn't listen to me when I swear at it!    Embed Quote 