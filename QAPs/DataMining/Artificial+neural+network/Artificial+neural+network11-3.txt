How can I learn about artificial neural networks if I don't know anything about this field?
Well, it is a good time to learn something about artificial NNs since in recent years NNs have achieved great success in areas like speech/image recognition.        Then, let's come to your question. Now you say that you still have no background. That's Ok. Everyone starts without background, all right? For people who first tries to learn artificial NNs, the material I would recommend is the Unsupervised Feature Learning and Deep Learning Tutorial written by Andrew Ng and his students.        This is a nicely written, easy-to-follow and yet comprehensive tutorial. It begins with some basics in supervised learning since artificial NNs is inherently a architecture for supervised learning. Then it talks about simple neural networks, formally the fully-connected networks, which are easier to analyze mathematically. After that, it jumps into a currently hot topic, the Convolutional Neural Networks (CNNs), which is the type of artificial NNs that actually achieve the above mentioned success. By the way, you may have heard about "deep learning". Well, most of deep learning is just about CNNs. After that, the tutorial switches to unsupervised learning by introducing one important type of NNs, the autoencoder. Then it will build connection between the autoencoder and some classic techniques like PCA and ICA. Don't worry if have not heard about them. You will get to know them and they are quite understandable. Finally, the tutorial will end with a area to which Andrew Ng has contributed a lot, the self-taught learning, which uses autoencoders to learn features from unlabeled data.         Well, I may have included too many terminologies in the above answer. So I would recommend you to try yourself. One nice thing of the above tutorial is that it includes nicely designed exercise for each section. You will learn by doing and have a better grasp of the material. For this exercise, I have handed in a set of solutions to GitHub (Jianchao-ICT/UFLDL_NEW-Solutions) which you may use as a reference. Most of the solutions work as expected except one which I mentioned in the readme file.        Finally, one thing worth mentioning is that the above tutorial has an old version in UFLDL Tutorial - Ufldl. I have studied through both of them. The old version begins with the relatively easy while representative example of NNs --- the autoencoder and most of other sections are treated as some extensions to aotuencoders. Also, the old version gives relatively few weight to CNN, which is more detailed illustrated in the new version.         Oh no, this answer is too long. So, any take-home message? Well, I think the first important thing in artificial NNs is the Back-Propagation (BP) algorithm, which is used to train the network. This is a classic algorithm. Unfortunately, it is not easy to understand when you learn it for the first time. You may become confused and frustrated. However, believe me, this is actually a hard algorithm, even Andrew expressed this idea in his Coursera course Machine Learning. So if you find it to be too difficult, normally many other people do so. And the second important thing, I think, is the autoencoder (AE), which is inherently a simple fully-connected network.        If you could write codes to train AE using BP (The exercise provides you with a chance to do so!), I think you have already know the key elements of artificial NNs :) Then you may delve deeper into this area by learning the Coursera course Neural Networks for Machine Learning ( Page on coursera.org) offered by Geoffrey Hinton as mentioned by Alexander McMurray. If you find you have fallen in love with this area, try Li Fei-Fei's CNN course CS231n: Convolutional Neural Networks for Visual Recognition.       Enjoy yourself! By the way, I am certainly not an advertiser :)    Embed Quote 