How do artificial neural networks learn?
A neural network "learns" by solving an optimization problem to choose a set of parameters that minimizes an error function, which is the typical sum of squared errors. This definition of learning isn't unique to a neural network model. Consider, in the simplest case, a linear model of the form . Given a vector of data , we choose   that minimizes , where is an by matrix with "training data" on the rows.  Solving this least squares minimization problem has a nice well known closed form analytical result: . There is, however, a tradeoff between computational ease of finding optimal model parameters and model complexity.  This is evident in the linear case, since the model is extremely easy to fit but has a very simple form. The neural network attempts to find a "sweet spot": while the model is highly non-linear, its particular functional form allows for a computationally slick fitting procedure called "backpropogation". To fully appreciate this idea we need to first define the model. The Model:A "neural network" is a function from . Writing down the mathematical form in one monstrous expression is inordinately ugly, so we will break it down with words and diagrams. A neural network with layers and neurons per layer looks like the following: The input to each neuron is a linear combination of the outputs of each of the neurons in the lower layer. The output of the neuron is a nonlinear threshold applied to its input: it's something that maps the real line to (-1,1) in a 1-1 fashion such that "most" of the positive line is mapped pretty close to 1 and and "most" of the negative line is mapped pretty close to -1. A common choice is the function .    The final output of the signal is the sign of the top neuron. Note that the top layer is constrained to have a single neuron. In the cartoon example above, we have 3 layers with 3 neurons in the first layer, 2 in the second, and 1 on top. 2. Fitting the Model With "Backpropagation" The goal of fitting the model is to find a suitable set of  "weights", which we can compactly refer to as , for the inputs of each of the neurons. One way to do this is to choose a set of weights that minimize the sum of squared errors for training examples we already have. The intuition here is to choose a model that is "close" to the true model, just like we would in a linear regression. However, unlike linear regression, an analytical solution is not feasible because of the ugly threshold functions, so we need to resort to a computational approach like gradient descent. Gradient descent takes steps in the direction of greatest Error decrease in the parameter space, hoping to find a (global) minimum. (Recall that from multivariable calculus, the gradient of scalar field points in the direction of the greatest increase of the function, and so walking in the opposite direction points in the direction of greatest decrease repeating the argument with the negative of the function.) Start by initializing the model with some arbitrary set of weights. Feeding forward, given an input , we may compute the output as delineated above. Hence, we may calculate the error , which is the error from the first training example. Now, we compute the gradient of this error function with respect to the weights. The beauty of the method is that computing the gradient of the error is computationally slick and can be done recursively using the chain rule. To see this, we'll introduce some notation. Let indicate layers, assume that is the output of the jth neuron in layer , is the input into neuron in layer , and is the weight for the signal input into the th neuron in layer coming from the th neuron  in layer , so that  and . Note that stands for the number of neurons in layer .  By the chain rule, . Since is linear in the weights, the tricky part is only in computing the former component of the product. We may recursively compute this as The recursion terminates since . We start by computing the gradients from the top layer, and store the gradients as we progress down each layer,so that we need not recompute the gradients. This leads to computational efficiency.  Thus "learning" in a neural network  is nothing but iterating between computing the error using the training data and updating the weights by calculating the gradient of the error function. 3. Code I have thrown up some java code for a neural network on my github account at ggopalan (Giri Gopalan) · GitHub. However, I would use this at your own risk! 4. References I learned this material from Professor Yaser Abu-Mostafa at Caltech in his course CS156. This is available online at: Learning From Data - Online Course (MOOC). I would also recommend his textbook: Learning From Data MOOC    Embed Quote Updated 5 Dec, 2013. 31,207 views.