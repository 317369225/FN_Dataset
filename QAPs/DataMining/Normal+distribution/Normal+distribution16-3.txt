★What is an intuitive explanation for how the t-distribution, normal distribution, F-distribution and Chi-square distribution relate to each other?Why do all these different distributions exist and how do we use them in statistics? What influences the choice of distribution in statistical testing?
If you are reading this I assume that you know what a normal distribution is. Lets get to the other stuff and how they are all related. But, firstly you would need to understand the Central Limit Theorem. It says that the mean (average) of a sufficiently large number of independent and identically distributed random variables will be approximately a Normal distribution. As n So this algebraic expression is supposed to follow Standard Normal distribution as n becomes infinitely large. But in reality, we can't have infinite data. If n is small, this distribution of the location of the true mean, relative to the sample mean and divided by the sample standard deviation, after multiplying by the normalizing term is a t-distribution with n-1 degrees of freedom. As n becomes infinitely large, this becomes the standard normal. That is why we see the t-distribution in computing confidence intervals. For large n you may notice the use of z distribution instead of t. This implies the use of the inverse of a standard normal, which implies an assumption of infinite data (large data). Now we have seen a way to find the sample mean, with some confidence interval. What about sample variance? Just like the mean of a sufficiently large number of independent and identically distributed random variables follows normal, the variance of a sufficiently large number of independent and identically distributed random variables follows a Chi-square distribution. This follows from the theory that the sum of squares of standard normal distributed random variables follows the Chi-Square distribution. F-distribution is a little more difficult to explain for me. A ratio of two Chi-squared distributions approximately follows F-distribution. Hence you would find the use of this distribution in F-test which is used for Hypothesis Testing. One example is testing for the hypothesis that the means of several normally distributed populations, all having the same standard deviation, are equal. This is perhaps the best-known F-test, and plays an important role in the analysis of variance (ANOVA). You would take ratios of variances and then check for the truth of your hypothesis. To understand all these better, you can try reading some material on 'Hypothesis Testing'. A video link on Khan Academy: Hypothesis Test for Difference of Means    Embed Quote