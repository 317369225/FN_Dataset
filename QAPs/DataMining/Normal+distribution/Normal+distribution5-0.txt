★What is special about the normal distribution?What special properties does the normal distribution have that cause it to be the distribution that falls out of the central limit theorem? I.e., there are various distributions that are symmetric, roughly bell-shaped, etc. What properties cause the normal distribution to be singled out? What is the intuition behind its specialness?
Essentially, the Gaussian distribution is the unique distribution that has zero k-th order cumulants (which is closely related to the central moments) for all k>2 . The Central Limit Theorem is basically saying that the average or sum of n independent random variables (with finite variance) has k-th order cumulants that become negligible for all k>2 as n grows, i.e., converges to a Gaussian.  Note that the mean is first cumulant and the variance is the second cumulant. (Aside:) This is why scientists and other data analysts typically use the Gaussian assumption when estimating confidence intervals (i.e., standard error) from data.  No matter what distribution your data actually follows, as long as you're collecting enough (reasonably) independent samples, you can approximate the average using a Gaussian distribution.  Modern science stands proudly on the shoulders of the Central Limit Theorem. A more detailed explanation follows. Characteristic Functions: The (classical) Central Limit Theorem is most easily proved by analyzing the characteristic functions (i.e., the Fourier transforms) of the random variables in question. Let denote the density function of a random variable X.  The characteristic function of X is The characteristic function has the following relevant properties.  If X and Y are independent random variables, then Because the characteristic function is essentially a Fourier transform of the density function, there is a bijection between the two: which implies that the characteristic function essentially completely defines the behavior of a random variable (just like the density function does). The k-th moment of X (which is the same as the k-th central moment if X has zero mean) can be computed by evaluating the k-th derivative of the characteristic function at 0: The characteristic function of a Gaussian with mean and variance can be written as (The Gaussian distribution is the UNIQUE distribution that takes this form.) Proof Sketch of Simple Case: (See also the Wikipedia proof of the Central limit theorem.) Let be n independent and identically distributed random variables with zero mean and unit variance.  Then the CLT says that To prove this let's look at the characteristic function: By Taylor's theorem and (4) above, the characteristic function of any zero mean and unit variance random variable can be written as which implies that (7) is equal to which converges to the characteristic function of a unit Gaussian (5).  More Detailed Interpretation: From the relationship between characteristic functions, moment-generating functions, and cumulants, we know that if a moment generating function has the form then the k-th cumulant is equal to the k-th derivative of g evaluated at 0: . The moment generating function of a Gaussian with mean and variance can be written as which is related to the characteristic function (5) via Thus, an intuitive interpretation of the proof sketch above is that: as you sum over more and more independent random variables, the resulting distribution's higher order cumulants become negligible compared to the first and second central moments.  Once you divide by , then the higher order cumulants disappear, and the the mean and variance (which are the 1st and 2nd cumulants) converge to a stable point.  It turns out that the Gaussian is the unique distribution that has those properties.    Embed Quote