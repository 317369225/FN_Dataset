★Why does the frequency of so many events appear to be normally distributed?This may be  unanswerable, but I'm looking for some explanation as to why the frequency of so many events (especially in nature) manifest as a symmetrical cluster about a mean, with frequency decreasing as it moves away from the mean.
The Central Limit Theorem predicts this. If you sum together a large number N of identically distributed and independent variables, you get something that approaches a normal distribution as N goes to infinity. (Actually, you need an additional condition: finite variance.) Even when these assumptions aren't true, they're often close enough to true, in the real world, that you end up with a bell-shaped distribution. (Many measured phenomena are well-modeled as sums of independent random variables-- possibly latent ones.) The Gaussian distribution is what's called an attractor distribution. Why is it this way? When you add random variables together, you're losing information. If X + Y = 9, that could mean that X = 6 and Y = 3, but it could also mean X = 9.735 and Y = -0.735. Aggregations tend to be reductive: you throw away details you don't care about to measure a quantity that you do care about. An aggregate property like a sum or average is going to tend toward a high-entropy (low-information/minimal-assumptions) distribution that meets certain defining parameters (in this case, the mean and variance). As it turns out, the normal distribution is the maximum entropy distribution with a specific mean and variance, so it's (approximately) what you'll get when you sum together a large number of independent variables.    Embed Quote