Computational Complexity Theory: How is it possible, that P != NP hasn't been proven yet?
Actually, it's not so 'obvious'. Very plausible, yes, but not obvious. Just for contrast, consider the class BPP, which is the class of problems that are solvable in polynomial time by a probabilistic algorithm with bounded error. Before, it was 'obvious' that using randomness would help tremendously, but now it's widely conjectured that actually P = BPP, i.e. all of these problems can be solved in polynomial time by a deterministic algorithm. People conjecture this because it follows from other very plausible conjectures involving the existence of pseudorandom generators and whatnot. An even more pertinent example is that PSPACE = NPSPACE, where the former is the class of problems solvable by a Turing machine using polynomial space, and the latter is the same thing with nondeterminism. In turns out (Savitch's Theorem) that you can simulate any nondeterministic Turing machine with a deterministic Turing machine using only quadratically more space. As a result, while nondeterminism helps us save space, it does not help us save more than polynomially much space. It is obvious that nondeterminism helps. The question is: does nondeterminism give us more than a polynomial boost? It's believed that randomness does not give a superpolynomial boost. It turned out that nondeterminism does not give us a superpolynomial boost in space. The P != NP conjecture simply states that nondeterminism does give us this boost in time.    Embed Quote 