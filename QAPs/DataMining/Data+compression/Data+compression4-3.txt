Is data compression a dual of learning? If not, why?
Sure. You can easily make an argument along those lines. 1. Data compression works by discarding irrelevant information (lossy) and exploiting repeating patterns in the data as well as similarity with other datasets (lossless). 2. The above is essentially the ability to generalize from specific examples to general rules or patterns, almost the very definition of learning. Reading the synposis of Grünwalds book "The minimum description length principle" [1] this appears to be not so much the reverse of MDL as it is MDL saying it's two sides of the same coin.   At [2] is a more thorough discussion which may or may not support the claim that a randomly picked data compression technique has a counterpart in a corresponding learning algorithm, or vice versa.     [1] http://homepages.cwi.nl/~pdg/boo... [2] http://hunch.net/?cat=40    Embed Quote Updated 20 Sep, 2014. 111 views.