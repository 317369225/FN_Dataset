★What is the difference between "Top-Down parsing" and "Bottom-up parsing" in programming languages?
Background InformationParsing a language presupposes the existence of a grammar for the language. The grammar for a programming language consists of a list of productions. Here's an example of a very simple grammar for a language that consists only of very simple variable declarations: 1
2
3
4
5
 Declaration = Type Identifier ";"             | Type Identifier "=" Expression ";" Expression = Number            | Expression "+" Expression            | Expression "-" Expression This says that a Declaration can take one of two forms, and that an Expression can take one of three forms, two of which are recursive. The grammar containing this rule would also define productions for each of the symbols Type, Identifier, and Expression (and probably many others). The grammar also defines a "start" or "accepting" symbol that describes a complete program. In the examples that follow, let's assume that our entire language tries to match a Declaration, and so that is the start/accepting symbol. Let's talk about how a parser with the above grammar rules might parse the input: int foo = 10 + 20 ; The tokens in this input are int, foo, =, 10, +, 20, and ;. Bottom-Up ParserAs a bottom-up parser reads in tokens, it checks to see if it can reduce (combine) any part of what it's currently working with into another symbol by satisfying its production rules. That is, it tries to assemble the symbols on the left sides of the production rules by grouping together tokens it finds so that they look like the right sides of the production rules. A bottom-up parser is not unlike a bachelor in his kitchen trying to decide what he can make to eat: as he gathers more potential ingredients, he compares what he has with the recipes for things he knows how to make, and then makes whatever is possible every time he realizes that he has all the required ingredients for something. Scanning the example input from above: The parser begins by scanning int, which it recognizes as a Type. It goes through its list of productions, searching for production rules consisting only of Type, but finds nothing; the only production rules that begin with Type need a bunch of other stuff before they can be reduced to a Declaration. So it leaves the Type be for now. foo is scanned and recognized as an Identifier. The parser looks to see if it can reduce Type Identifier to anything, and fails. It then looks to see if it can reduce just Identifier to anything, but this also fails. Neither Type Identifier nor Identifier is a complete production rule for any symbol. So now the parser is sitting on Type Identifier. Like the previous two cases, the parser can't do anything with =. It checks to see whether any of Type Identifier =, Identifier =, or = are complete production rules, but none are, so it just stores the = token and keeps reading. When 10 is scanned and recognized as a Number, the parser looks for the production rules: Type Identifier = Number (nope), Identifier = Number (nope), = Number (nope), and Number (ah-ha!). When it gets down to just Number, the parser sees that this satisfies a full production for an Expression, so it performs that reduction. After this reduction, it's looking at Type Identifier = Expression. Unfortunately, none of Type Identifier = Expression, Identifier = Expression, = Expression, or Expression look like any of the production rules in our grammar. So another token is scanned. As in most of the previous cases, scanning + is pretty unceremonious. No reductions are possible, leaving the parser looking at: Type Identifier = Expression +. Things get interesting again when 20 is read. 20 is a Number. Since there are no productions ending in Number except for Expression = Number, Number is reduced to Expression, resulting in: Type Identifier = Expression + Expression And the only sequence of tokens that match a production rule in there is: Expression = Expression + Expression... (more)Loading...