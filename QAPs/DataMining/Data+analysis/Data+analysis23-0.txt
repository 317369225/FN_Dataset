★What kind of collaboration tools would reduce duplication of R&D effort in data analysis and sharing?
Some sort of friction-free Github for scientists (see http://news.ycombinator.com/item... ) In the words of User.... Github for scientists - a distributed hosting and version control system for all parts of scientific communication, including writing, code, data, and audio/video/images. So that you could build on somebody else's work by versioning it! Isn't that what science is meant to be about? Nonetheless, there really aren't any friction-free tools available yet. Collaborative wikis work somewhat well, but they still have a lot of friction (especially with tables). The problem is - that there are still VERY few tools (if any) that allow for the frictionless merger of tables and other types of text. And that's precisely what we need the most - something that maybe combines the best parts of Wikis, Google Docs (with its changesets), GitHub, and Quora (in science, credit matters, and only Quora does a good job at assigning credit). In fact, a system like that might even provide a viable alternative to citations (with all the information they hide) someday, since it would then easily allow us to identify how someone contributed to a project (and quantify their contributions too) Maybe SAGE (http://www.sagemath.org/ ) is a step in the right direction. In SAGE, they actually do have collaborative notebooks that provide a foundation for a frictionless merger of tables, equation, and documents. But also - it's true - it's the separate cultures of each field that is the problem. Most scientific fields are quite segregated from each other. And a lot of it is because many scientists think that *their* methods are best and that they don't have too much to learn from each other. People who "dabble" in different fields, in particular, are often shunned. See http://blogs.discovermagazine.co... and http://blogs.discovermagazine.co... . I posted a thread in Physics Forums about the issue of "reinventing the wheel", but I ultimately ended up getting attacked for it (http://www.physicsforums.com/sho... ) I also discussed this issue with several researchers in the Computational Astrobiology Summer School (http://www.ifa.hawaii.edu/UHNAI/... ) - many of them also want to reduce the duplication of R-D effort. But the problem is - again - people often think that if you don't develop things from the very basics, then you're missing something out (pedagogically speaking). They think that you're an intellectually sloppy person who always tries to take shortcuts. But these sorts of beliefs are the same types of beliefs that are forcing us to take longer and longer to get through school (and as a result, we aren't doing creative work during the years when we're at our peak). At some point in time, we have to do what works best - intellectual purity be damned. After all, we stand on the shoulders of giants. We don't need to know how the washboard works before we use the laundry machine. And besides, there isn't any proof that "learning from fundamentals" is any better than learning things backwards. Personally, I think I gain a far more sophisticated understanding of things when I learn things backwards (and I learn far faster, too) Some more useful info at http://cameronneylon.net/blog/wh... The first step is simple, make a record, ideally an address on the web for everything we create in the research process. For data and software just the files themselves, on a hard disk is a good start. Pushing them to some sort of web storage, be it a blog, github, an institutional repository, or some dedicated data storage service, is even better because it makes step two easy. Step two is to create feeds that list all of these objects, their addresses and as much standard metadata as possible, who and when would be a good start. I would make these open by choice, mainly because dealing with feed security is a pain, but this would still work behind a firewall. Step three gets slightly harder. Where possible configure your systems so that inputs can always be selected from a user-configurable feed. Where possible automate the pushing of outputs to your chosen storage systems so that new objects are automatically registered and new feeds created. This is extraordinarily simple conceptually. Create feeds, use them as inputs for processes. It’s not so straightforward to build such a thing into an existing tool or framework, but it doesn’t need to be too terribly difficult either. And it doesn’t need to bother the user either. Feeds should be automatically created, and presented to the user as drop down menus. The step beyond this, creating a standard framework for describing the relationships between all of these objects is much harder. Not because its difficult, but because it requires an agreement on standards for how to describe those relationships. This is do-able and I’m very excited by the work at Southampton on the OREChem Experimental Ontology but the social problems are harder. Others prefer the Open Provenance Model or argue that workflows are the way to manage this information. Getting agreement on standards is hard, particularly if we’re trying to maximise their effective coverage but if we’re going to build a computable record of science we’re going to have to tackle that problem. If we can crack it and get coverage of the records via a compatible set of models that tell us how things are related then I think we will be will placed to solve the cultural problem of actually getting people to use them.    Embed Quote 