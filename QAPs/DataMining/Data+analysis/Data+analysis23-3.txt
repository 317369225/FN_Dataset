★What kind of collaboration tools would reduce duplication of R&D effort in data analysis and sharing?
Sven Crone of Lancaster University Management School shed some light on this in a speech a few years back. He contrasted the culture of machine learning with the life sciences. We can deride their genomics and proteomics studies for their sloppy use of statistics and deficient data sets, but turning the table, the life science people would be appalled at machine learning's lack of reproducibility in its research. Sven Crone examplified this beautifully by actually trying to reproduce a result in a machine learning paper. He found that even with access to the raw data, a detailed description in the paper and even mailing the authors for additional details, it was not possible to reproduce the results. Not because it was wrong, but because a wealth of undocumented parameters and initial setups affected the result. In another study, he set three people the task of comparing the merits of different machine learning methods. If I recall correctly the three participants were given the same data set, but arrived at three different conclusions. Just the manual tuning and differing experience in selecting parameters for machine learning algorithms, were enough to completely change the ranking. It is a cultural problem that such non-reproducible results get through peer-review. But it's also a practical one as it's often time-consuming and difficult to make working code available to the reader. One attempt to address this is found at www.executablepapers.com which is a contest hosted by Elsevier. The finalists in that contest seem to address many aspects of the reproducibility problem.    Embed Quote Updated 21 Mar, 2013. 375 views.