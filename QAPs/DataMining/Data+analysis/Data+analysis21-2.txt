Big Data Analysis: What are the Alternatives to Hadoop?
"Hadoop" isn't really one thing. It's a collection of technologies that have grown together, ranging from the file system (HDFS) to the map-reduce architecture to the libraries that have come out of the project, or been built on top of it. If you're going to use Java, you might as well use Hadoop, because it would take too much effort to write something comparable. You can call Spark an "alternative", but it actually uses a lot of the Hadoop machinery already. (Spark gets faster performance because it prefers memory for data storage, which is a massive win in iterative algorithms, which is what most optimization/ML problems are. It's arguably easier to get started because of Scala and its Repl, but putting Spark into production is still painful because of the Java legacy.) That said, I don't think it would nearly as hard as many people think to write a comparable system (with better performance and much better usability, so that it doesn't require that most companies hire expensive consultants to get started) in Haskell. The infrastructure's there, the language is better in a number of ways than Java is, and with the ability to interoperate with C for anything that has to be fast, the best-case performance is also going to be superior. That, however, would take some effort: probably a high-single or low-double-digit number of person-years from a very high calibre of engineer. It could be done, though, and I imagine that it will be in the next few years.    Embed Quote 