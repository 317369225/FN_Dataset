What are some real-time data analysis frameworks?
At LinkedIn we have been working on a streaming system called Kafka, which is in this area; it is open source, and recently added to Apache as an Incubator project. At a high-level what it does is capture persistent "streams" of data, spread across a cluster of machines. Any number of consumers can subscribe to a stream, forking off their own copy for processing, and a cluster of consumers can group together to divide up the messages in a stream amongst themselves. This allows scaling the volume of data handled by the servers and by the consumers beyond what a single machine could process. We allow data consumers and publishers to route data based on keys, which gives an API similar to MapReduce. (Note that a streaming system can't really be equivalent to MapReduce because MapReduce contains sorting as one of the primary operations to group things together, but sorting a infinite stream is not well defined). The style of programming to take advantage of this is to potentially layer processing stages which allows data to be published out by some key as a stream, grouped or further processed, and then republished by another key for another stage of processing. This doesn't do anything higher-level than this, though, it really is similar to Hadoop in that it provides an API for partitioned processing and grouping but there is no higher level query language built in. This is system is in production at LinkedIn, and handles our tracking and monitoring data streams which are quite large. There is more information available here: http://sna-projects.com/kafka/de... Other frameworks that I am aware of include, but I know less about the details since I haven't worked with all of them: S4. This is similar to Kafka in capability in that it provides streaming/messaging capabilities in a cluster-aware system with the ability to partition by key. It is not persistent, however. http://s4.io Storm. Not sure if this is available yet, but sounds similar to S4 but without requiring Java or XML (which is good). Not sure if this is persistent or not. http://tech.backtype.com/preview... Zillions of traditional messaging systems are not that different from this either (RabbitMQ, ActiveMQ, etc). Basically they allow a similar style of programming, stringing together processing stages that moves data between queues. These typically offer some persistence though it may not be very high-scalable. The distribution model for the systems I have looked at is, in my opinion, a little bit lacking too. Flume and Scribe are similar as well though I would say their focus is really on getting the stream of data into Hadoop or other systems rather than facilitating direct stream processing.    Embed Quote 