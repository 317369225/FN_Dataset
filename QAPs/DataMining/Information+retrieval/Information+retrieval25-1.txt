★What are the courses required to learn information retrieval and machine learning?
ATA. Here is my view on it. I would say, start with the basics of machine learning and then expand from there. I always rate myself in a 2D scale. (effective, dangerous). Being effective essentially means, having a higher level knowledge in your field and have enough skills to solve a problem. That would translate into ability to master Andrew Ng basic Machine Learning course with some undergrad level practical machine learning course, proficient in python, using Scikits-learn etc to solve some problems. Then learn map reduce programming model and do some basic data etl using those technologies. Somewhere down the line, you will experience a ceiling into what you can do with the existing tools you have. This is where you want to go into depth. To gain depth, here are the courses I would recommend: 1) Linear Algebra 2) Probabilistic Systems Analysis and Applied Probability 3) Advance Machine learning courses (plenty out there  but the best one I found are Machine Learning 2013 , Machine Learning Video Library, Introduction to Machine Learning) 4) Then go deep into Stanford School of Engineering ,Coursera , Coursera ) The above is the curriculum I followed which made me appreciate this field. It is truly fascinating. If you understand Statistics, Linear Algebra and Optimization well, you will start decomposing the existing "standard" solutions into other building blocks and appreciate why these things are standard but at the same time, how you can tweak them if some assumption in your dataset doesnt hold but a particular algorithm assumes (e.g what if the noise in your dataset is not gaussian and you want to solve a regression problem) Regarding distributed systems, I would say just start using an existing big data library. Thats how I got started. Start using hadoop or spark. The courses I would recommend for distributed systems are: 1) Page on lintool.github.io (implement this book end to end) 2) Distributed Algorithms, http://www.ict.kth.se/courses/ID2203 3) Page on stanford.edu   I was fortunate enough to work in a research group at my previous work (Intel), where they were trying to scale out machine learning algorithms into distributed systems and definitely, having folks who understand the computers from silicon up is a huge plus but it was here when I started reading the source code of these technologies and then understand the system level details. I have realized that no matter whether its machine learning or distributed systems, it is always when you pop open the hood, you realize the beauty is hidden inside the api (be it scikit learn or spark). If you admire a library, start contributing into it or start something. This whole process, I term it as being "dangerous". Having skills in these two dimensions are very valuable in the industry. Given a problem, quickly prototype it (being effective) and then have the skills to scale the solution and deploy into production... Hope it helps and good luck.    Embed Quote