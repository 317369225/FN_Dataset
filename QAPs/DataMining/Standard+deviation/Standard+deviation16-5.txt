★Why do we square instead of using the absolute value when calculating variance and standard deviation?
I found an  answer better then mine[below] : The reason that we calculate standard deviation instead of absolute error is that we are **assuming error to be normally distributed**.  It's a part of the model. Suppose you were measuring very small lengths with a ruler, then standard deviation is a bad metric for error because you know you will never accidentally measure a negative length.  A better metric would be one to help fit a Gamma distribution to your measurements: Like st. dev., this is also non-negative and differentiable, but it is a better error statistic for this problem. http://stats.stackexchange.com/a... My answer : This problem comes up over and over again in statistics, such as when computing sample variance or regression coefficients. In each case, there are two commonly used formulas, and the formula easier to apply manually is potentially inaccurate. To make matters worse, books sometimes imply that the more accurate formula is only for theoretical use and that the less accurate formula is preferable for computation. For example  The two terms being subtracted  can be each around and yet their difference can be  around . That means that if calculated to infinite precision, the two terms would agree to 21 significant figures. But a floating point number (technically a double in C) only has 15 or 16 significant figures. That means the subtraction cannot be carried out with any precision on a typical computer. in probability theory and statistics,however, the computational formula for the variance Var(X) of a random variable X is the formula No square root . Here is the proof,The computational formula for the population variance follows in a straightforward manner from the linearity[1] of expected values and the definition of variance[2],why we define it that way? , in your terms a net zero value of AC will be less informative then RMS value. isn't it ?                         In exact math however there are methods including the RMS type you mention.[3], with their own advantages/disadvantages in terms of precision loss/overflow  depending on magnitudes/data type. http://en.wikipedia.org/wiki/Exp... , http://en.wikipedia.org/wiki/Var... en.wikipedia.org/wiki/Algorithms_for_calculating_variance    Embed Quote