★In linear regression, why would a large standard deviation of Y increase the slope and why would a small standard deviation of X decrease the slope?
Thanks much for the visual graphics! But if we imagine the y values are all over in a random way, then the slope will be zero....but if the y values are all over, does this not mean the standard deviation of y values is greater?   So does this mean that increasing S.D. of y can also decrease the slope?  Or am I confusing scenarios?    Embed Quote