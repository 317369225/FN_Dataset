★How can I run linear regression in parallel?
There are a couple of ways to do this, and it will generally depend on the dimensions of your data, and your environment.  There are several matrix factorization approaches that work well in shared-memory multiprocessors, but may not be viable for something such as MapReduce.  A common approach is to parallelize the matrix multiplication needed to get and . However, by a series of parallelized QR decompositions, it is possible to solve the least squares problem.  The following is a useful reference: Communication-avoiding Parallel and Sequential QR Factorizations Parallelizing Matrix Multiplication Two matrices are needed, and , each of which can be parallelized by distributing blocks of rows, observations, over several processors.  Each processor computes these matrices in parallel, and the final result can then be achieved by aggregating each of these subproblems.  The problem is then solved on a single-machine.  The symmetry of the makes the Cholesky decomposition particularly attractive.  This is a pretty common implementation in a MapReduce setting. QR Decompositions in Parallel With a QR decomposition, we can decompose a matrix .  Substituting the QR factorization into the original least-squares equation gives . By splitting across several machines, we can compute the QR decomposition on each of these subproblems, or "local" problems. A subsequent  QR decomposition can be run by aggregating the R terms from each of the "local" problems, which gives the final matrix. The matrix can be obtained by manipulating the two matrices from the "local" and "intermediate" problems.    Embed Quote