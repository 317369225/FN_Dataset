★What is the difference between singular value decomposition and multiple linear regression?They both seem to find the best-fit subspace for a set of points, unless I've understood the techniques incorrectly.
Also, to add to Sean Owen's answer, when you do Principal Component Analysis (the statistical use of SVD) in high dimensional space, you usually do no stop to the first Principal Component (or Singular Value) Imagine your data has a deflated rugby ball shape (couldn't find better ;)). The first PC will approximate the rugby ball as the line running along the longest axis. And a LR should "approximately" find this one too. Unless you are unlucky and the variable you are trying to predict is close to the first PC (the case where the line is vertical on Sean Owen's post). Adding the second PC will find the plane in which it lies. The second PC being orthogonal to the first one. The third PC being the deflated direction. In short, if you want to find a best fit subspace, use SVD. And you will get the extra information of the most relevant directions in that subspace, which help you decide how many dimensions that subspace needs to be. If you want to predict a given variable, use regression. But the closest your variable will be from the first PC, the less you will succeed.    Embed Quote