★Can we treat insignificant variables in linear regression as 0?For example, if we have p predictors and only the first p0 are significant. If we compare the true model (with first p0 predictors) and the full model (with all p predictors), we know that the true model is unbiased but it is ineffective (larger variances). I was working on the proof and wondering if I can have this assumption of setting all variables that are not significant in the full model to be 0.
There is no "true model" in any regression and both the full and limited models will be unbiased if the sample is random.  If you set the parameters of insignificant variables to 0, you are deleting them from the model. There is no general solution to the question of whether it is a good idea to drop or keep variables - it depends on many things, including whether they act as mediators, whether a small effect size would be interesting, the sample size, any interactions and so on.  Automated method such as backwards, forwards and stepwise should not be used - it can be proven that the results of such procedures are incorrect.    Embed Quote