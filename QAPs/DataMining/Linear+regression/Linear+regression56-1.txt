★Can we treat insignificant variables in linear regression as 0?For example, if we have p predictors and only the first p0 are significant. If we compare the true model (with first p0 predictors) and the full model (with all p predictors), we know that the true model is unbiased but it is ineffective (larger variances). I was working on the proof and wondering if I can have this assumption of setting all variables that are not significant in the full model to be 0.
In my regression classes most professors agreed to keep insignificant variables inside your model. Why? Variables are insignificant, if statistically we cannot reject that the corresponding coefficient is 0. Now, however, that does not mean it is certainly zero. Hence as long as it does not do any harm, keep the variable in your model. When does it not do any harm then? Well in case you are interested in inference, the coefficients should not change, if you keep the insignificant variable in the model. If they do, your model might suffer from omitted variable bias, which is a different story, but will certainly suggest to keep the variable in your model (@Omitted-variable bias). On the other hand let's say you want to consider forecasting. The difficulty in forecasting is to find exactly those variables that explain the underlying variance in the variable you would like to predict. Sometimes those variables are also said to have predictive power. If you then find insignificant variables in your model, it might be worth considering to remove them, as they will probably not explain a lot of variance and thus won't have a lot of predictive power.    Embed Quote