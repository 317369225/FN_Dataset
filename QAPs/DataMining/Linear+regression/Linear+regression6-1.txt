★What is the difference between linear regression using MLE, Bayesian linear regression and linear regression using MAP?
MAP : maximum a posteriori refers to the model parametters maximizing the likelihood. If you look a the bayes formula , you got several elements: the prior , the likelihood and the posterior. Maximum likelihood means finding the  model parametters such that P(data| model ) increases.  Maximum a posteriori takes into account P(data|model)*P(model), which de facto is quite close to MLE. The  bayesian point of view thinks about a distribution in space of the possible models. The prior P(model|prior) codifies this "model parametters distribution" and the data probability is weighted from the outcome of all the model space Sum_{i}^{models} { P(X|model_i)P(model_i|prior)}. At the end of the bayesian inference update rule you obtain a distribution in the model space, the model with the highest probability in this distribution is the MAP model. If you want a better explanation please read the bayesian inference article by M. tipping: Page on miketipping.com    Embed Quote