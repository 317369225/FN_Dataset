★Can we treat insignificant variables in linear regression as 0?For example, if we have p predictors and only the first p0 are significant. If we compare the true model (with first p0 predictors) and the full model (with all p predictors), we know that the true model is unbiased but it is ineffective (larger variances). I was working on the proof and wondering if I can have this assumption of setting all variables that are not significant in the full model to be 0.
When a predictor in regression is statistically insignificant it means that it's numerical value may not be zero but this predictor do not have significant information about response variable... Even if we keep all such insignificant variables in the model coefficient of determination may increase very slightly... Therefore many times it is recommended to drop these variables from the model... The concept of forward, backward & best fit regression deals with omission of insgnificant variables from the model.    Embed Quote