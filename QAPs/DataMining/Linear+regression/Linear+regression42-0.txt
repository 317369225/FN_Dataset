★Why do we need the bias term in ML algorithms such as linear regression and neural networks?
As you know, the goal of linear regression is to estimate the parameters that best predict the outcomes, given the input features/predictors. If the expected value of your outcome variable is not 0, then we would also need to estimate the bias weight (i.e., the shift from 0) along with the feature weights. If we don't account for this bias, then any predictions from our estimated model will be off. However, if expected value of your outcomes is already 0, then it's actually not necessary to include a bias term, though you could anyway and the estimated bias would just be 0. In addition, you could also force the expected value of your outcomes to equal 0 by "demeaning" (i.e., subtracting the mean of your outcomes from every outcome). The same rational holds in the case of a neural network (NN). Of course, the difference is that instead of one regression model, you have many from each input layer and, for a standard NN, the outcome values are binary. When outcomes are binomially distributed (or more generally, multinomial/categorically distributed), linear regression obviously won't work here. Nevertheless, you can still think about the setup of the problem like a linear regression model, except it will be transformed with a nonlinear activation/squashing function (e.g., logistic). You can imagine that once we start nesting these regression models for multi-layer NNs (where "outcome" variables are a function of preceding layers), it gets complex! Thus, a bias term is needed to account for the possibility of a mean shift.    Embed Quote