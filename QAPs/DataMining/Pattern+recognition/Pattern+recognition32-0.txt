★How much resources would a Pattern recognition app for Android consume?
There are simple algorithms that can run directly on phones (simple features and linear classifiers) and more complex machine learning algorithms that take on the order of minutes per image (usually academic prototypes that try something ambitious like recognize many objects at once). You should first worry about getting an algorithm to do something useful at all. For this first stage, you'll want to develop on a modern computer. Once you have an algorithm which recognizes the patterns you care about, determine if it is fast enough to port to a phone or launch a cloud-based micro service for processing.) If your algorithm takes 1-3 seconds per image on a desktop, you should be able to perform optimizations (lots of good vision gurus out there to help you) and make it an order of magnitude faster. You shouldn't worry about premature optimization. I've seen many students start out with Android/iOS for vision projects, and so much time is spent on just making it run vs. actually making the pattern recognition algorithm better. Good luck!    Embed Quote