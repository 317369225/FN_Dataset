★Say I have a box that contains 4 red balls, 10 green, and 1 blue (identical in every way aside from color). How many times would an observer need to randomly draw balls from this box (replacing and mixing each time) before being able to determine the respective proportions within standard error?
You can compute exact probabilities when looking from the outside, as follows: Scenario 1. You know that the box contains 4 red balls + 10 green balls + 1 blue ball. You call your friend. You tell him that the box contains 15 balls and you ask him to determine their colors. Your friend decides to follow the following procedure: he will pick a ball x times, and then he will make a guess by rounding the color frequencies to the nearest multiples of 1/15. Given x, we can now compute the actual probability that your friend will give the correct answer. Note that we know the correct distribution of balls. Example: suppose that x=15000. Your friend would give the correct answer if and only if: he sees a red ball between 3500 and 4499 times, he sees a green ball between 9500 and 10499 times, and he sees a blue ball between 500 and 1499 times.(Note that our friend's procedure is not perfect: for example, if he sees a blue ball 497 times out of 15000, he would round it down to 0 and say, incorrectly, that there are no blue balls. We don't really care, the strategy is good enough as is, this event is very unlikely. Reporting 1 blue ball when seeing 1-1499 blue balls gives essentially the same probabilities as the ones reported below.) Here are some numbers: For x=50 the probability that your friend computes the correct answer is about 18.59%, for x=100 we are at 32.77%, x=200 gives 56.57%, x=400 gives 77.96%, and for x=800 we are at 93.84%. Thus, even with 800 rounds there is still a decent probability that your friend will give an incorrect response. At x=1500 (i.e., on average he will see each ball 100 times) the probability of him giving the correct response is finally a comforting 99.2%. For x=3000 we are at 99.987% -- almost certain to receive the correct color counts. Now consider the same experiment, but from your friend's point of view. Scenario 2. In your friend's situation you cannot compute the probability of being correct. To do that, you (a Bayesian statistician :) ) lack one important piece of the puzzle: prior probabilities for possible initial contents of the box. The only thing you can compute after you make the x experiments is the likelihood for each of the initial states of the box. If you do enough experiments, the likelihood of the correct answer will be significantly greater that the likelihood of any other box contents. Certainly it is a good strategy to stop once the difference is large enough for you, and to announce the maximum likelihood estimate. It's just that from within the system you cannot assign an explicit probability to the event "when I announce this answer right now, I will be correct and my friend will congratulate me". In other words, from within the system you cannot tell (without receiving additional information) whether or not you are in an extremely unlucky branch of the probability tree. For example, even though you have examined 150 balls and all were white, it is still possible that you are unlucky and there is a black ball you have not seen. And you do not have enough data to assign an explicit probability to this event.    Embed Quote