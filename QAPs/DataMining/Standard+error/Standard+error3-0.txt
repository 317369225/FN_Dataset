★What are the differences between standard error and adjusted standard error in a regression? How does it affect the slope, intercepts and t-statistics (using ASE instead of SE)?EDIT: Ok I figured this out, Adjusted SE just means adjusting for heteroskedasticity using the White method or Breusch Pagan
I am quite sure that by standard error in linear regression you mean R-Squared, which explains goodness of fit and by adjusted standard error, you mean adjusted R-Squared. I will try to explain in plain English for a better understanding. In case of regression, we try to find a relationship between a few independent variables with a dependent variables. Suppose you have the Human Development Index of a country dependent on 5 variables. You will get a value of slope and intercept and a value of R-Squared. R-Squared is a percentage index and symbolize that how much variability is explained by the variables. The thing with R-Squared is that it always increases as the number of variables. Now you can see that you can add any variable to the set of variable and increase your R-Squared and claim that you have obtained a better fit. But this will be wrong. For that reason we use adjusted R Squared which changes with addition of any new variable. It increase for relevant variable and decreases if the new variable is irrelevant. That is why Adjusted R-Squared is preferred over R-Squared. To have a mathematical reasoning behind the two, look at :http://web.maths.unsw.edu.au/~ad... \ I hope I answered your question and do remember that difference between the two R-Squared is very important interview question.    Embed Quote