★Robotics: Why Traditional way of modeling and control are still in use in Robotics, even though we have sophisticated algorithm like Reinforcement learning?Might be modelling the Robot and derive the equation of motion and design the controller looks sexier, but  Reinforcement  learning which make the system to find and learn its own model and make system to control itself is far more better. So why traditional way of modelling and control is still in use?, is it because it looks sexier ?
I think this is a very good question. The word "sexier" is a little funny to be honest. Having said that, I actually participated to an optimal control lecture offered by a professor who thought that certain optimal control problems were sexier than others. But anyway, who am I to judge? :) Also, my work is focused on model based design and control. So I am biased toward those topics. Let's start with the answer. I think there are two parts to this question. I will start with the first part. According to the beautiful book 'Fabric of Reality' written by David Deutsch, a scientific theory should have the power to explain things. It should have a realist approach to natural phenomenons rather than an inductive one. His ideas on scientific knowledge are influenced by another very important scholar, Karl Popper. You might be wondering where I am going with this. Traditional way of modeling and control in robotics are explanatory. You can use them to explain why a bipedal walks without loosing stability. You can use them to explain why bicycles don't fall, and if you think this is a trivial problem, I suggest you take a look at the following TED talk. You can also use the same theories that explains how dynamic systems work to control pretty amazing machines including quadrupeds, humanoid robots, quadrotors ... You name it. Additionally, you can prove the stability of your controller under certain constraints/conditions using tools from non-linear system theory such as Lyapunov stability. I don't know of any reinforcement algorithm that will prove or discuss the stability of a controller with you. Reinforcement learning will not also explain you why the set of actions it performs over time actually works. The second part of the question is more practical. Let's assume that you are a controls engineer, who is assigned with tuning PID gains of DC motors of a 36 DoF humanoid robot. You can do this manually. It is not that difficult if you have some basic control experience. If you need to tune hundreds of humanoid robots coming out of a factory, you probably need a more repeatable way of tuning. Do you want to use reinforcement learning? If you suggest using reinforcement algorithm for tuning each robot, my first question would be: How feasible is that? Is it faster than a tuning algorithm based on adaptive control?  Or are neural networks faster? You really need to answer why you would want to do that. Moreover, if you are a company who engineered the robots, you probably have a lot of knowledge on their system parameters - mass, damping coefficients, gearbox design etc ...-. In that case, you would want an algorithm that utilizes that knowledge to perform more efficient and I doubt if reinforcement learning is the best way of doing that. Having said all this, there are meaningful ways of using reinforcement learning in robot control. Especially in uncertain environments. What people do is that they make the robot learn the environment and then they try to find trajectories in those environments that are optimal with respect to the cost function. There is ongoing research out there that use these tactics in motion planning and in control of highly dexterous landing in winged flight. Also: If all you have is a hammer, everything looks like a nail.    Embed Quote