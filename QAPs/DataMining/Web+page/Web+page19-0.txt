â˜…What is the basic structure of a web page crawler?How do you parse for outgoing links in a web-page? Where do you store such links? (Throwing some light 'how Google does it' will also be good.)
There's a nice diagram in the "Web Crawling" chapter by Christopher Olston and Marc Najork in "Foundations and Trends in Information Retrieval" [1]. Not shown on this diagram is the page harvest, a data store that contains the contents of each page that has been crawled, and to which Greg refers in his answer. From talking with crawling experts, there's also some serious work that goes into things like classifying the encoding of documents, identifying spam and adversarial content, and identifying common structure across documents. [1] http://research.microsoft.com/ap...