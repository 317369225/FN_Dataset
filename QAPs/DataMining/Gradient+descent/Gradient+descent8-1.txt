★Mathematical Optimization: Why would someone use gradient descent for a convex function?Why wouldn't they just find the derivative of this function, and look for the minimum in the traditional way?
As Priyanshu Ranjit notes, if n -- the number of parameters -- is large, then finding the minimum of the function involves solving a system of n equations. In the simplest case, such as in linear regression, when this is a system of n linear equations, this will in general involve inverting an nxn matrix. The standard matrix inversion algorithm is O(n^3) time. So when n is large, even linear regression can take a very long time to solve directly. And if the equations are not even linear, then the problem of finding an exact solution will be even more difficult, if not impossible (there must be some Galois theory-type unsolvability results in convex optimization, right?). Gradient descent often allows us to bypass such bottlenecks. But the issue is that you can't really rigorously find a bound on how long it will take for it to converge (as far as I know -- though I am new to this subject). However, the main argument for gradient descent seems to just be that in practice it seems to usually work well and converge to the minimum very quickly. Another issue with gradient descent is that in general -- when the function is not convex -- it will find a local minimum, and not necessarily a global minimum -- though you won't have this issue if the function is convex, for example in linear regression. A third issue is the fact that gradient descent, strictly speaking, only yields an approximate solution, and never an exact solution. But again, in practice, this usually seems to not really be an issue.    Embed Quote