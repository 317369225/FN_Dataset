★Difference between stochastic gradient descent and online learning?
Besides being gradient based, stochastic gradient descent usually works under a specific type of online setting: the iid setting, where the assumption is that data are random samples from a fixed but unknown distribution. The goal is usually to optimize an objective function with respect to this unknown distribution. In order to gain performance guarantee, the type of objective function therein is usually convex, and I believe this is the so-called online convex programming setting (google the paper by Zinkevich). Besides online learning, SGD can also be applied in the batch case, where instead of feeding the entire data set to the algorithm, one sequentially samples data from the batch, and assume this results in iid sampling. This type of application is usually termed as the large-scale learning framework, where SGD has the advantage of light computational cost (you can check the related work by Leon Bottou in his website). Under this framework, SGD is usually used to find the Empirical Risk Minimizer of the batch data, without having to sample all of the data set. A prominent example is a SVM solver based on SGD, called PEGASOS.  Online learning by itself has many different variants in terms of paradigms. For example, some does not assume any distributional assumption, which is the so-called online adversarial case; some assume that comes from a drifting distribution, etc. If you want to learn more about online learning, check out the book Prediction, Learning, and Game (by Nicolo Cesa-Bianchi)    Embed Quote