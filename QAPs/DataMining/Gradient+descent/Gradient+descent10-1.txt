★What are some tips for debugging a gradient descent algorithm that isn't converging?I'm interested in graphical and numerical methods for tuning hyperparameters, batch size, initial weights, etc.
What do you mean it's not converging?  You mean your function just keeps getting smaller and smaller forever?  Sounds like you're optimizing a function without a minimum (local or otherwise)... that might take you the better part of a weekend, ya know.  If you're minimizing an error function like the cool kids tend to do, you're probably not going to deal with this case for obvious reasons.  If your function keeps minimizing for more than 6 hours, please consult a medical professional. Is it that your output value is getting smaller and smaller but by tinier amounts with each step?  Sounds like you need to specify some sort of threshold at each iteration, like "if I only get smaller by x% or y total, then stop."  You could be in a beeline for an asymptote so you can never quite get off the HMS Shrinkytown, which is nice in theory, but you get diminishing results with each iteration so eventually you have to decide "good enough" and tap out. Is it that you keep alternating between the same two points over and over again?  Hah, sounds like my last relationship!  But seriously folks, you might need to reduce your step size or make sure you don't revisit old states.  You can even reduce it dynamically over time or simulate yourself some annealing (http://en.wikipedia.org/wiki/Sim...). Sorry, this question is vague.  Can you explain exactly what you're seeing?    Embed Quote