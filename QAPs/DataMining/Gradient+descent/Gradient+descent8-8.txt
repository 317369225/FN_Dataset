★Mathematical Optimization: Why would someone use gradient descent for a convex function?Why wouldn't they just find the derivative of this function, and look for the minimum in the traditional way?
First, gradient descent is trying to find the point with gradient zero. Second, let's consider a simple example. We know that polynomial of degree greater 4 don't have a closed form solution. So even if we take a convex polynomial (one variable function) of degree greater than 5, we get the derivative (or gradient) to be of degree at least 5 for which we don't have a closed form solution. But we do know that the function is convex and the gradient points towards the direction the function increases (simple Taylor's series argument). Combining these two, we approach the optimal point.    Embed Quote