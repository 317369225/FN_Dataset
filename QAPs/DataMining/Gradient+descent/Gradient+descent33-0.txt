★What is the difference between derivative of a function or gradient descent?I know Gradient descent is a first order optimization algorithm.The first derivative of a function also means minimization/optimization of a function.
Derivative is a mathematical operator. Gradient Descent is an algorithm. Gradient Descent utilizes the derivative to do optimization (hence the name "gradient" descent). The observation made here is that for a differentiable function, at any given point, the function has the greatest decrease in its value in the negative direction of the gradient. To see why this is the case, let us consider a differentiable function . Let us say that you are at point in kth step of your optimization and you are looking for a direction to move so that the value decreases, then you are looking for a direction such that ... (first order taylor approximation) The dot product is maximum when x = y (Cauchy Schwartz), therefore the that minimizes the value most must be . Note that the Derivative is used in several places other than optimization and far more important tool than the very niche Gradient Descent algorithm.    Embed Quote