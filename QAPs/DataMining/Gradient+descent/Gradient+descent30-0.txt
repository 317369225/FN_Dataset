★What is the relationship between Metropolis-Hastings algorithm for Markov Chain Monte Carlo and Gradient Descent?
As other commenters have pointed out, MCMC is a sampling technique while gradient descent is an optimization technique.  That said, you can view optimization as a form of "biased" sampling, where you try to sample *exclusively* from the peak of your distribution.  This leads to great similarities between optimization techniques and MCMC algorithms--especially since, for most optimization problems, the objective function is multimodal, and it is beneficial to use multiple random restarts or to inject some other form of randomness in the algorithm. Example: stochastic gradient descent and hit-and-run MCMC.  In stochastic gradient descent, in each iteration one moves in a direction which is approximately the gradient, but with some random error.  In hit-and-run MCMC, one moves in a random direction according to a distribution which is biased towards the direction of greatest increase. Another example:  simulated annealing (optimization) and simulated tempering (MCMC). Most optimization methods, including Newton's method and gradient descent, have a major weakness for getting stuck in local optima. The idea behind simulated annealing is to get out of local optima by occasionally making large jumps.  Simulated tempering achieves the same goal, in the context of MCMC sampling.  This is because in MCMC, one also has to worried about being trapped near local modes (local maxima) of the distribution, as then you will end up sampling disproportionately from the local mode rather than the entire distribution.  In fact, simulated tempering is often used as a more sophisticated version of simulated annealing, for solving highly nonconvex, high-dimensional optimzation problems.    Embed Quote