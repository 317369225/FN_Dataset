★When should I use MCMC rather than Stochastic Gradient Descent?
These algorithms are primarily used for different purposes, but there is some overlap that I will discuss at the end of my answer. Gradient Descent Gradient descent algorithms are optimization algorithms designed to find a local minimum of an objective function.  This is accomplished by taking repeated steps of steepest descent until a local minumum is established.  Stochastic gradient descent is a modified version of the gradient descent algorithm that is used on large-scale machine learning problems when it becomes too expensive to compute the cost of gradients on the entire training set.  Instead, stochastic gradient descent approximates the gradient iteratively for each training example (or a small set of training examples), taking repeated steps until an approximate local minimum is attained.  Due to the iterative nature of the algorithm, it will not converge in the same manner as batch gradient descent, but this can be addressed by decreasing the learning rate α as the process iterates to force convergence. Markov Chain Monte Carlo (MCMC) Markov chain Monte Carlo methods are a class of sampling algorithms used to obtain a sequence of random samples from a probability distribution.  These are generally used when direct sampling from the probability distribution would be difficult.  Some of the use cases of MCMC methods are to approximate a target probability distribution or to compute an integral.  There are several different methods, but they work by constructing a Markov chain whose equilibrium distribution equals the target probability distribution.  As the number of steps increases, the sample more closely matches the target distribution.  The resulting probability distribution can then be used for optimization, but this is not the primary purpose of MCMC methods.  Use Case of MCMC for Optimization Most optimization functions are not unimodal distributions, so there is the issue of local optima.  Gradient descent algorithms search for local optima that are "good enough", and generally will not result in the global optimum for non-convex functions.  You may get closer to the global minimum by randomizing the starting values and rerunning the gradient descent algorithm, but this still may not find the global minimum.   For non-convex functions where finding the global maximum is critical, it may be useful to use MCMC for optimization.    Embed Quote