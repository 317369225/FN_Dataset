★What is the current status on training recurrent neural networks?
The Optimization method you use depends lesser upon the type of Neural Network (Convolutional / Recurrent / Recursive) but rather more on the Optimization problem you get when you formulate the Neural network. Here is what I observed when I tried to use these to optimize a non-convex neural network: SGD with momentum : 1. Is easy to code. 2. Might not converge/take a large time to converge Hessian Free: 1. Is tougher to code (although open source implemetations exist) 2. will almost always converge, however its not really too fast. You might want to try Adagrad/Adadelta which perform really well, and will converge faster despite of whatever initial values are taken. HTH    Embed Quote