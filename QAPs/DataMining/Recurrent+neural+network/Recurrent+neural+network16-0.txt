★Why can't recurrent neural networks scale up well?
I am not entirely sure if what you are saying is correct. There are two types of scaling up in any neural network based models : 1. Training time scaling (That is to train on more and more datapoints) 2. Use time scaling (To be able to use model on more and more datapoints) Training time scaling : This might be bit of a problem if one is training using a GPU. RAM on the best available GPUs is limited to 8Gb(that is the maximum I have used). But still it is very possible to do this. We have to load the training data in batches on to the GPU. Say we work on 4Gb input at one point, store the entire state of neural network and then load a new input data with the stored state. We might go ahead and train on infinite amount of data using this approach. Good thing about Recurrent Neural Networks is that one does not require to apply universal functions on the dataset as a whole (like PCA/Kernel function of a SVM ). So one can store the state of Neural Nets and just apply it on a new block of data. If one thinks that training batch-wise can be slow, one can try cluster based approaches like graphlab and GPU clusters with scala (If I am not wrong, this is available with the dl4j platform) . Use time scaling: I do not see this as a problem. Recurrent Neural Networks are basically set of matrices which determine how a series should be combined. These matrices change only during training time. At runtime it is just the question of how many matrices one has to multiply (which is an easy problem) Source: Personal Experience. We use Recursive Neural Network (a concept like Recurrent, but the backpropogation is on structure not on time) at http://www.paralleldots.com .    Embed Quote