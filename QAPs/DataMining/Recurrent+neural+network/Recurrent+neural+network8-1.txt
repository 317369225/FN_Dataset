★How do people come up with an appropriate topology for (recurrent) neural networks?Obviously there's training, but fully connected networks don't scale at all. Specifically I'm curious about Hopfield and Boltzmann machine based networks, including deep belief networks and so on. I'd like to know the various heuristics researchers use, and maybe some comments on how well they work and when they might fail.
General speaking, deciding it by a couple of empirical reasoning is better then any slight provision since thereby  NN seems very large scales at the successful models therefore estimation of best possible model in advance is even impossible. My route plan is; read some papers about the particular interest use those proposed model measure results change in a way that you expect to see some improvements measure again if works write a paper or submit to challenge or make money out of it :) Caveat: keep the Occam's simplicity in mind    Embed Quote