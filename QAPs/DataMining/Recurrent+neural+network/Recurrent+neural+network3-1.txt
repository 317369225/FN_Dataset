★Is there any other problem with recurrent neural networks besides complexity?My understanding is that the reason people can't use RNN's too much is because if you have too many neurons, you run into a very large and intractable combinatorial problem with obnoxious complexity. Is my understanding correct? Are there other reasons as well?
Your understanding that complexity is an issue is certainly correct, though it has more to do with learning methods and time dependency than combinatorial complexity. The training phase of feed forward neural networks is much simpler given that the standard, gradient based back-propagation algorithm proceeds in layers backward until the input layer is reached, and there is no time evolution of the network parameters.  Recurrent networks, on the other hand, contain cycles in the graph, and so, have no such terminal layer.  As such, they may train forever if they do not converge.  This necessitates attaching some time variable to the state of the network indicating how many iterations have passed since the output data has been propagated backwards.  There is a similar requirement for output values on the forward calculation.  These values may oscillate chaotically depending on the training data and state of the network prior to training.    Embed Quote