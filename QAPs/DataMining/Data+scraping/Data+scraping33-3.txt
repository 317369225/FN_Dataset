Is there a way to prevent your website (data) from being scraped?
I realize that this answer is a little late but i wanted to put it here incase you still need help or for future reference by anybody that reads this article and is having the same problem. There is a couple ways to prevent web scraping, at the application level, through a hardware service or using a cloud based system. At the application level, you can disable right clicking and using javascript remove someone's ability to copy content. This will make it harder (not impossible) for someone to just copy information. Web scraping usually happens via automation though and some other ways to prevent automated programs include rate limiting and blocking bad user agents. Another option is is Imperva WAF or the F5 ASM which are appliances that can help stop bots. Alternatively, you can use a cloud service like http://www.distilnetworks.com (full disclosure, I am a cofounder of Distil Networks)    Embed Quote 