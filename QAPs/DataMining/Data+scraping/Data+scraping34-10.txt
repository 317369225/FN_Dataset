What is the best way to scrape data from a website?
Jesse Sherlock,Need your advice on the web scraping framework/language, have read your article and comments on stackoverflow and searched the web. 1) need to scrape multiple websites, with as less fragility as possible. 1.5) Solution should help extend the number of websites in an "easy" way 2) Am experienced in C, C#, familiar with golang. 3) Web(Python,js, ruby on rails, node.js) is relatively new for me but worked with HTTP/TCP-IP, XML, LAMP and familiar with Webservices, HTML to an extent. 4) Guess have around 1.5 months full time to get this done.  I know this is subjective and matters on how fast i pick it up, but there is a hard limit on the overall project and this is a piece of it. 5) Prefer to have a "simple"(as compared to "easy") solution, if it violates 4 above will need to see if i can tweak trade-offs. After searching around, i think i have the following choices Pick up python, and try out scrapy Get more familiar with golang and use Fetchbot: https://github.com/PuerkitoBio/f... Flexible, similar API to net/http (uses a Handler interface with a simple mux provided, supports middleware, etc.) Coupled with goquery (PuerkitoBio/goquery ) to scrape the dom Clojure, subotai, and other links you mentioned in Stack Overflow comments. Use Kimono or Import.IO Hire a consultant to get this done. I will be dependent on him for future work and will need to check on his availability when i need it. thanks hemant    Embed Quote 