What are some good resources to learn data mining and data scraping from websites using Python?
I was told that Python is too slow for this kind of work. That is not true. The CPU speed of python, a relatively slow language, usually does not matter because web scraping is an IO-bound job. This means that  the network speed costs most of the time no matter if you were to use a slow language like python or a faster language like Go, Java, or C++. Many companies use python for scraping tasks: Examples: Google: Their very first web scraper is listed as being written completely in python. Read The Anatomy of a Search Engine, Google's Stanford paper. In order to scale to hundreds of millions of web pages, Google has a fast distributed crawling system. A single URLserver serves lists of URLs to a number of crawlers (we typically ran about 3). Both the URLserver and the crawlers are implemented in Python. Each crawler keeps roughly 300 connections open at once. This is necessary to retrieve web pages at a fast enough pace. At peak speeds, the system can crawl over 100 web pages per second using four crawlers. This amounts to roughly 600K per second of data. Reddit: Uses python to perform thumbnail scraping jobs. Check out some examples in Reddit's code: reddit/reddit Tons of startups (mostly internet 2.0 companies) exclusively use python for scraping jobs: Few examples: NewsBlur, Swayy, Instagram, and many more not listed. I'd venture to guess that Quora and Pinterest also use python for scraping jobs (which they definitely do a lot of). If that's not enough to convince you, query 'scraper' on Github: https://github.com/search?q=scra... By far most of the results are in python. Anyways, back to your question. I learned scraping by building real life tools more than anything else. That way, a lot of the real world problems of scraping, like Unicode conversion for example, will come your way and you can learn the fastest. In a nutshell, scraping involves visiting pages on the web by first downloading them from their unique urls and then parsing downloaded HTML. You are kinda mimicking the action done when surfing the web via a browser! (Various python options like lxml and BeautifulSoup are discussed by others). With these parsed dom objects, you can begin to do cool things, like: - search the web pages for stuff you are interested in, key words, imgs, etc. - save and build an index of these pages (your own search engine!?) - use the contents of these pages for your own app (an aggregator!?) - Find out all the URL href <a> links on that page and recursively visit them! - Find the most important image on that page? (Reddit, Facebook, and many more use this technique to display you a relevant thumbnail when you submit a web url link) Those are the basics, and once speed becomes a problem you can begin to add lot's of cool things like: distributing your scraping jobs, implementing async-io, and etc. I personally learn from example, search online for the many great existing scraping technologies which are published open source. This is my favorite simple tutorial for a few of the basic tasks described above: The Hitchhiker's Guide to Python - HTML Scraping. Also refer to this page for a good intro on the topic: Web scraping with Python (I do not recommend using high level scraping frameworks like Scrapy framework, especially if you are here to learn.) Check out the popular news scraper I wrote and open sourced online: codelucas/newspaper This was used for a toy news search engine I built: Wintria. Be goal oriented, think of things you want to build, read examples, and build them! You will learn lots, and in my opinion lots more than reading 1-2 tutorials which will barely introduce you to any real scraping problems. Good luck, and python is sure as hell fast enough.    Embed Quote 