★What is the probability of the model in the hidden Markov model?as you know the posterior distribution of the hidden Markov model when given observation is: p(model | observation) ∝ p(observation | model)*p(model) p(observation | model) is clear and can be obtained. but Is There any way to find p(model)?
You can compute the posterior P(HMM|data) using the forward-backward Baum-Welsh algorithm.  This is in contrast to computing the likelihood p(data|HMM) which uses the Viterbi algorithm.  For sequential data, the Viterbi algorithm will give you the sequence of HMM states that maximizes the likelihood of the data.  The forward-backward algorithm, on the other hand, gives the posterior probability of each HMM state at each time index of the entire sequence of data.  The posterior probability of the last HMM state at the end of the sequence of data is the posterior of the whole HMM.   That reason is that this posterior is equal to the summed posteriors of all state sequences reaching this state through all possible alignments of the HMM to the data. Things get more interesting when you are talking about more than one HMM where the posterior of each HMM depends on where you transition from one to the next.    Embed Quote