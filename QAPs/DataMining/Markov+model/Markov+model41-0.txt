★In layman's terms what are the differences and similarities between Bayes Networks, Markov Decision Process, and Hidden Markov Models?
A hidden markov model is a special case of a bayes network, but one that's also often applied with different context.  A markov decision process is a markov model which adds on an additional feature, which is the ability of some agent to influence the system. This is one of the canonical models of a Bayes Network: It allows you to say things like: if you know the state of the sprinkler (on or off) and the state of the rain (rainy or not), then knowing whether it's cloudy doesn't affect the probability that the grass is wet.  To talk about a hidden markov model, you first should talk about the vanilla markov model.  A markov model generally captures the value of some object at different times (i.e. a time series).  The key assumption of a markov model is that, if you know today's value, then to predict tomorrow's value, there is no benefit to yesterday's value.  This is actually called the Markov property.  Note the difference compared to the Bayes network model above, which is cross-sectional in nature.  This is the big difference in context.  However, you can still represent a Markov model as ... --> (Yesterday is rainy) --> (Today is rainy) --> (Tomorrow is rainy) --> ..., so it can be represented as a kind of Bayes Model.  Of course I'm making the silly assumption that rain behaves in this Markov way. A hidden markov model adds a wrinkle to the Markov template, which is to add a layer of unobservability.  This turns into a new Bayes Network: Now, you can only observe the y's, which are related to the unobservable x's.  So, for example, you are blind and can't observe the sky or feel rain drops, and the y's are "the grass is wet on a specific day", and the x's are "it's raining on a specific day". Markov decision processes are fundamentally different, because they involve "control".  You, the agent, have the power to influence the system.  So, for example, to carry the previous example forward, you are still blind, and you are deciding whether to turn on the sprinkler in a given day.  Each day, you base your decision on the state of the world that you observe.  So, you turn on the sprinkler if you observe the grass is dry.  It is not allowed to turn on the sprinkler based on the state of the grass tomorrow, for obvious reasons.  Your control strategy has to be 'adapted" to the information flow.    Embed Quote