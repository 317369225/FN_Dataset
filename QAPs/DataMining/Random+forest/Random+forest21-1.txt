★When would one use Random Forests over Gradient Boosted Machines (GBMs)?
There is one fundamental difference between the two that may force you to choose Random Forests over Gradient Boosted Machines (GBMs). That is, Random Forests can be easily deployed in a distributed fashion due to the fact that they can run in parallel, whereas Gradient Boosted Machines only run trial after trial. So, if you are constrained either by the size of the data or the number of trials you want to try, you may have to go with random forests.   Personal opinion alert: On the other hand, I would prefer Gradient Boosted Machines over Random Forest if not constrained by the size. The idea of reinforced learning clicks with me, it is like when you are preparing for an exam, after one prep test, you would definitely spend some time checking out those mistakes you made, rather than hustle to the next prep test. That being said, so often we are constrained by the size and it is easier to run RF with 2000 trees than GBM with 2000 trials.    Embed Quote