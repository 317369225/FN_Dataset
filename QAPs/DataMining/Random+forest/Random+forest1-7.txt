★When are random forests better than linear regression?
Random Forest is able to discover more complex dependencies at the cost of more time for fitting. If it's established, that your variable of interest has the linear dependency from the predictors, you will probably get similar results with both algorithms. Therefore, due to huge computational complexity of RF (especially, with wrong regularization parameters) compared to regression's, there is no reason to wait significantly longer for +0.001 AUC. But, if the dependency is something different from linear, there is no possibility for an algorithm to come up with a linear equation, which would be similar to the empiric law of training sets' point distribution. To make decision in practice, you should fit linear regression and look at the results of cross-validation - if you are not satisfied, then, probably, it's the case when you want RF.    Embed Quote