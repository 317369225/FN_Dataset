★When and why is  naive bayes classifier a better/worse choice than random forest  classifier?
Random Forests, It is robust against overfitting at least with my experiences and the claims of the creator Leo Breiman and Adele Cutler. It is influenced by the Adaboost. It gives better results with the increasing number of examples. It might be used for clustering, statistical inference and feature selection as well Works good with numerical, categorical data.(You need to estimate a distribution over continuous values for naive bayes however it is controversial to have some assumptions) However; slower to train Need to be set well its randomization parameters. (Selection of nodes, number of trees, randomization of instance variables). Some objections for it overfitting. Naive Bayes, Easy to trains and understand the results, It has different extensions for different needs Its model is smaller than the random forests since you need to keep all the trees in memory. Promising results for textual tasks. It makes any one to able to do ML if he knows counting. However As its name it is based on naive assumptions that re not generally concordant with the data (exp: All the variables are uncorrelated to each other, but generally it is not true) It is really fragile to overfitting without any regularization assumption.    Embed Quote