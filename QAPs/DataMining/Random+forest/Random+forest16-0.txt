★What roles do features and classes play in Random Forest?
Well let's start with a brief understanding of Random Forest algorithm. It works as a large collection of decorrelated decision trees.  The decision trees used to make the classification. For example we have this matrix here: We have features such as fA1 feature for first sample to the training Class1. Perhaps, the goal here is to have a Random Forest to classify the sample set. From the sample set, subsets gets calculated to find a DT1 to DTn: Lots of decision trees > forest? Hah! See what they did there! Out of the Decision Trees a ranking gets created and thus the Class prediction comes out. Using relevant features help finding fitting data. Read here: ŷhat | Random Forests in Python Random forest is a capable of regression and classification. It can  handle a large number of features, and it's helpful for estimating which  or your variables are important in the underlying data being modeled. One way to overfitting is to only use really relevant features in  your model. While this isn't always cut and dry, using a feature  selection technique (like the one mentioned previously) can make it a  lot easier. Source: ŷhat | Random Forests in Python    Embed Quote