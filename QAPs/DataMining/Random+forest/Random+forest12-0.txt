★What is an intuitive explanation of random forests?A simple metaphor or example walkthrough would be greatly appreciated!
Let´s say you want to know if tomorrow will be sunny, rainy or cloudy based on several measurements from the previous day like temperature, dewpoint, cloud cover, humidity etc. Imagine you have a lot of measurements, say 50. You want to build a decision tree to decide the weather forecast, for example if temperature on previous day > 60 and cloud_cover < 20% then Sunny. But you don´t know which features to use, you have a lot. So you take a random set of measures and a random sample of your training set (days with measurements and known weather outlook) and you build a decision tree. Then you do the same many times using a different random set of measurements and a random sample of data each time. At the end you have many decision trees, you use each of them to forecast the weather and then decide the final forecast based on a simple majority. Hope this analogy is clear to understand please mind the typos as I´m on a phone.    Embed Quote