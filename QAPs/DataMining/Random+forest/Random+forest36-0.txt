★When Random Forest is expected to fail, while SVM would probably perform better?
Random Forests generally needs larger number of instances to work its randomization concept well and generalize to the novel data. In addition, in one way or another, random forests works with combination of some kind of soft linear boundaries at the decision surface thus I believe that this is still below the success of max margin SVM non linear boundaries. Thus if you have small amount of data compared to possible variations of the instances than SVM is better choice. That is the case for Computer Vision generally. Another point I realized lately, random forests is not suitable for high dimension data since it requires so much trees. A practice concern is random forests implementations are not capable to work with sparse matrices, at least up to my knowledge thus for very large sets simple non kernel svm is better    Embed Quote