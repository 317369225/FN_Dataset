★How does one choose the best feature and threshold in a random forest?The features are continuous-valued.
There are two main reasons for feature selection, which are (1) model quality and (2) speed. For model quality, with Random Forests, it generally doesn't make sense to remove features. RFs are very strong against overfitting and removing features will typically make the model worse. If you're really worried about overfitting try using Extremely Randomized Trees[1]. If you're worried about runtime speed, check out FEST[2]. Finally, one way to do it is to run a few decision trees, and find the features with minimal importance in the tree. Especially if some features get an importance of 0 every time, you know they contribute no new information. [1]: 3.9. Ensemble methods [2]: fest    Embed Quote