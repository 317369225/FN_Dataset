★Artificial Neural Networks: How does one create a neural network capable of abstract reasoning?
If a formal inference algorithm of useful complexity is taken as a reference paradigm it is likely that no neural network, including biological ones, is capable of fulfilling the paradigm perfectly, but it is quite feasible to train a biologically plastic one (as we have existence proofs in excellent human reasoners), or to construct (in my opinion) a suitably architected one artificially, to a useful approximation of the paradigm. I will not pretend to have complete closure on the question,  until and unless I have constructed one, but I think it is useful to say that certain components or aspects are required: 1) A cognitive sequence model.  This is akin to a language model, but abstracted to dominating concepts of deep structure, rather than overfit to a surface form.  It is, in the coarsest measure, a kind of auto-associative memory.  2) A reinforcement framework encompassing inhibitory and excitatory reinforcement, such that it favors a Zipfian connectome, with stochastic dropout to effect holographic representation and avoid reflexive overfit (i.e. effect generalization). 3) A bootstrap objective function.  This may be provided by an algorithmic automated reasoner. 4) A bootstrap encoding.  I suggest GloVe. 5) A knowledge base including formal and/or natural language representations of premises for reasoning.  Natural language premises will be GloVe encoded (initially) and presented to the fundamental inputs of the language model layer, at least. Formally correct abstract reasoning is not known to exist in neural networks absent a linguistic facility.  Therefore, I would naively infer that linguistic function and natural language inference is a relatively short (i.e. relatively achievable) path to achieving a neural embodiment of approximately formally correct abstract reasoning.  Convolutional networks and HTM systems share this commonality with the mammalian cerebral cortex:  A layered fundamental connective architecture, differentiating the functions of a small number of layers.  Taking cliques of such "columnar" clusters as fundamental units of a higher level network, the natural language sequence level should be distinguished from the conceptual, semantic level, which may employ parallel and recursive structures more freely. The process of self-organizing adaptation of the raw components into a functioning reasoner will require concentric training loops.  In the innermost loop, the individual neurons of a column are trained directly on something analogous to perception and emission of language, to refine the language model.  Unallocated columns will be connected locally and randomly to this surface layer, and likewise to each other, in initialization.  The connectome of the network of columnar regions will be refined in an enclosing training loop, which applies the objective (local similarity to and global coverage of the body of conclusions of a formal reasoning algorithm) to the network output.  Articulating that output as natural language should derive naturally, but is unnecessary for our purposes. Sequenced training will be responsible to propagate higher abstracted signal up the cortical stacks.  Since we have ready access to intermediate layers, training may be more feasible if standard NLP and formal semantic processing by conventional algorithms is used to present stimuli to higher layers in the stack and/or broader levels of organization, simultaneously to the fine-scale encoded presentations. The system should not operate on a global update clock, but rather on a stochastic local clock.  The sequencing of higher abstract conditional reasoning will depend upon the nearly homeostatic representation loops in the fine-scale neural network, which must therefore be reinforced. That's all I have for now.    Embed Quote