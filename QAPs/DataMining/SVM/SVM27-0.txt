★What is the difference between the perceptron learning algorithm and SVM?Both algorithms deal with trying to find some separating hyperplane. I know that perceptron has some well studied bounds with respect the the largest margin the data is separable by. SVM tries to solve some dual problem that maximizes the margin.
Let's work in 2D for simplicity. Given a set of points in 2D each assigned one of two labels, the perceptron algorithms finds a line that separates the points by class (provided such a line exists). Typically there will be more than one such separating line, and the exact line obtained through a run of the perceptron algorithm depends on the order points are processed. Among all the possible lines separating the points into their two classes, the line which best predicts the class of a future point not included in the test set will vary. Imagine, for example that your test set consists of these four points (in the classes red and blue) A perceptron may find, for example, any of the thin green lines as separators. None of those thin green lines, however, are likely to be picked by a human attempting to maximize the number of non-test points that are classified correctly. Intuitively, a human would be more likely to pick a line that roughly lies between the two classes of points (like the thick green-yellow line). A support vector machine makes this intuition mathematically concrete --- an SVM is a quadratic program that maximizes the margin (the sum of the squared distance of each point from the hyperplane) under the constraint that the hyperplane separates the points into two classes. The dual formulation of this problem (which is a minimization problem) is typically used, which has a less intuitive objective function but is easier to solve. More information is available online (e.g. these slides Page on harvard.edu )    Embed Quote