★When should I use Boosting instead of SVM?I do research in Computer Vision and most of the literature when it comes to supervised learning is filled with SVM's. When should I use boosting (Adaboost)? Or has boosting been overthrown by SVM?
When should I use boosting? As a quick answer, support vector machines are quicker to train and evaluate than AdaBoost. If this is not a problem, i.e. Adaboost is not too slow for your application, and it provides better test error rates (or whatever metric you wish to use, error, precision, AUC, Kappa statistic, Matthews correlation....) then by all means, use it. Why does everyone in the literature use SVMs? In the papers you've read, maybe everyone has used SVMs. That's because machine learning algorithms go in and out of fashion. Artificial Neural Networks were super fashionable back in the 80s/90s and then became incredibly unfashionable, Support Vector Machines have been very vogue in the 90s and noughties, I would say Boosting has superseeded SVMs in popularity, they're a bit more recent and mysterious. Ensemble learning (of which Boosting is an instance of) in general is very popular at the moment, however deep learning is probably going to become the new big thing. Tell me more about when I should use boosting. It's really not a complicated decision, if train/evaluation time isn't an issue - use the one that gives the best (test or cross-validation or hold-out) performance on your data. I'll elaborate, They're both non-parametric models. I.e. you're not making implicit distributional assumptions about your data. That's usually where you can distinguish two models, "which assumption makes more sense?" They both can capture very complex decision boundaries whilst avoiding (in many cases) over-fitting. That's what makes them two notably popular ML algorithms. They both produce a model that is not really interpretable. So if you want to interpret the model (i.e. with a decision tree you can look at the rules it creates, with a naive bayes you can look at the probability weights) then don't use either.So in summary, I can't see how you'd make a prior decision to use SVM over Boosting or vice versa. Let the data decide. In my experience, boosting has always outperformed support vector machines. Disclaimer: No free lunch theorem One is never better than the other, averaged over all possible input. I'm sure you know this, and many people reading, however it's good to reiterate. (Although I think this theorem is relatively useless).    Embed Quote