★Support Vector Machines: What are the advantages of choosing the v[nu]-SVM formulation VS epsilon-SVM?Besides "feeling" that the parameterization of v[nu] over epsilon is more natural? Reference for v-SVM (http://www.kyb.mpg.de/fileadmin/...)
Source: http://wiki.eigenvector.com/inde... There are two commonly used versions of SVM regression, 'epsilon-SVR' and 'nu-SVR'. The original SVM formulations for Regression (SVR) used parameters C [0, inf) and epsilon[0, inf) to apply a penalty to the optimization for points which were not correctly predicted. An alternative version of both SVM regression was later developed where the epsilon penalty parameter was replaced by an alternative parameter, nu [0,1], which applies a slightly different penalty. The main motivation for the nu versions of SVM is that it has a has a more meaningful interpretation. This is because nu represents an upper bound on the fraction of training samples which are errors (badly predicted) and a lower bound on the fraction of samples which are support vectors. Some users feel nu is more intuitive to use than C or epsilon. Epsilon or nu are just different versions of the penalty parameter. The same optimization problem is solved in either case. Thus it should not matter which form of SVM you use, epsilon or nu.  For more details on 'nu' SVM regression see http://www.csie.ntu.edu.tw/~cjli...    Embed Quote