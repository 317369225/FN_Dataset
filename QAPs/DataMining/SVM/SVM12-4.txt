★Support Vector Machines: What is the intuition behind Gaussian kernel in SVM?How can I visualize the transformation function that corresponds to the Gaussian kernel? And why is Gaussian kernel popular? This question extends to other popular kernels as well (such as polynomial kernel).
The Gaussian RBF kernel is very popular and makes a good default kernel especially in absence of expert knowledge about data and domain because it kind of subsumes polynomial and linear kernel as well. Linear Kernels and Polynomial Kernels are a special case of Gaussian RBF kernel. Gaussian RBF kernels are non-parametric model which essentially means that the complexity of the model is potentially infinite because the number of analytic functions are infinite. If you see it from the point of view of polynomial kernel, it essentially is infinite polynomial kernel. The Gaussian RBF kernel is defined by    and this can essentially be written as where, Here, is the kernel width parameter. Large  would essentially mean small and would imply a smoother fit and thus having a larger influence of neighborhood data point and vice versa. When ,  a data point is not influenced or correlated with any data point. More about choosing value of (or alternately ) can be found in [1]. When using Gaussian RBF kernel,  the separator(classifier) is described by bell shaped surfaces centered at each support vectors and the width of each bell-shaped surface is directly proportional to . The optimal value of should be somewhere between minimum pair-wise distance and maximum pair-wise distance. This being data dependent , one generally approaches it using grid-search/cross-validation.  [Reference: Page on stackexchange.com ] [1] Caputo, B., Sim, K., Furesjo, F., Smola, A.: Appearance-based object recognition using SVMS: which kernel should i use? In: Proceedings of NIPS Workshop on Statitsical Methods for Computational Experiments in Visual Processing and Computer Vision (2002)    Embed Quote