★What does support vector machine (SVM) mean in layman's terms?How to calculate the SVM taining accuracy using ROC area
A vanilla SVM is a type of linear separator. Suppose we want to split black circles from the white ones above by drawing a line. Notice that there are an infinite number of lines that will accomplish this task. SVMs, in particular, find the "maximum-margin" line - this is the line "in the middle". Intuitively, this works well because it allows for noise and is most tolerant to mistakes on either side. That's all a (binary) SVM really is. We draw a straight line through our data down the middle to separate it into two classes. But what if we don't want a straight line but a curved one? We achieve this not by drawing curves, but by "lifting" the features we observe into higher dimensions. For example, if we can't draw a line in the space (x1, x2) then we may try adding a third dimension, (x1, x2, x1 * x2). If we project the "line" (actually called a "hyperplane") in this higher dimension down to our original dimension, it looks like a curve. This video is an excellent illustration: By using the kernel trick, we can do these lifts very efficiently (actually, we don't really do them at all). Kernels allow us to draw "straight lines" in very high dimensions, and even infinite dimensions. EDIT: notice that to draw the maximum margin line, only the data points closest to the line matter (these are the ones with darker borders). These points are known as "support vectors" which gives SVMs its name.    Embed Quote