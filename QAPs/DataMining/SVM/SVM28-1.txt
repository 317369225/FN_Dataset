★What is some good advice on the incremental learning of SVM?
Thanks for A2A. To my knowledge, I don't have an idea of incremental learning in SVMs. To answer your question from a different perspective, People tend to use dimensionality reduction techniques when there are a ton of attributes, thus fighting the curse of dimensionality. If you have a lot of attributes, use PCA, SVD or any other dimensionality reduction techniques, but at the same time you lose explicability of your model. To answer to your point 2 and 3, yes, there are several preprocessing steps to ensure high accuracy and strong model performance. Pre-processing steps: Ensure orthogonality in your features. Many algorithms assume each attribute is independent of each other, but real life datasets are so much intertwined that, some of the features are certainly dependent on the other. Interaction effects: To state point # 1 differently, ensure there are no interaction effects (thus ensuring orthogonality). To do this, you can see correlation plots, or do chi-square testing of independence, in case of categorical attributes. Check out Adaptive Boosting. Several trees are built in each iteration to ensure correct classification of data points which are misclassified in the previous iteration by assigning a probabilistic estimate for data points. The process that you have mentioned reminded me of AdaBoost Classifier. Hope this helps!    Embed Quote