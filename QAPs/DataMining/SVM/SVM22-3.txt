★What does support vector machine (SVM) mean in layman's terms?How to calculate the SVM taining accuracy using ROC area
Let's say you have a bunch of red and blue points on a cardboard. You are asked to draw a straight line to separate them. You look at the points and realize that there is no way this can happen because in order to separate all the points correctly, you will have to draw a squiggly line. Now you take a step back and see that you were looking at one face of a 3-dimensional cube. In this cube, you see that you can easily place a simple planar cardboard piece somewhere to separate the red and blue points (because they are at different depths). Coming to the concept of SVM, it relies on the fact that finding out the properties of that cardboard piece in the 3-dimensional cube is much easier than finding out the properties of that squiggly line in that 2-dimensional cardboard piece. So it just extracts the properties of that cardboard piece and projects it back to 2-dimensions. A simple plane in 3-dimensions will look like a squiggly line in 2-dimensions. That was a simple demonstrative example. To generalize it, SVM basically projects given data points onto really high dimensions (using kernel functions), get the separating hyperplane and convert it back to the lower dimensions. SVM defines that boundary using something called Support Vectors. They are the ones that are closest to the boundary and "support" the separation. The separating boundary will the optimal boundary (equidistant from both sets of points). PS: This is an example of a binary classifier. One can easily extend this logic to design a multiclass SVM.    Embed Quote