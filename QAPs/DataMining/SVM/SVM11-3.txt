★Support Vector Machines: Why does SVM work well in practice, even if the reproduced space is very high dimensional?
From my experience, I'd say oftentimes SVM simply are overkill. But as long you do not know the simpler replacement (e.g. decision trees), it works reasonably well just because the actual "problem space" only has a few dimensions (like Mikio said, it's all about the data populating the space, not the space itself). That is, it is usually possible to find a handful of crisp features that help you to divide your high-dimensional space appropriately. SVMs take care of that for you. A comparison of SVMs vs. Decision Trees (and even single 1R classifiers) can be found in my WSDM 2010 paper "Boilerplate Detection using Shallow Text Features" ( http://code.google.com/p/boilerp... ) where I discuss a ML strategy for extracting full-text content from arbitrary Web pages. In my scenario, SVMs were just as good as (and somehow even worse than) the much more simpler decision trees. As DTs expose an hierarchy, they can help you address the problem space in a top-down approach, effectively treating special cases individually. The size of such rule sets can usually be reduced (pruned) without losing a lot of classification goodness (in terms of ROC AuC, for instance). Few decisions means fast execution. Moreover, classifiers such as C4.5 that operate on maximizing the information gain on a per-feature basis can relatively quickly construct such trees, as opposed to SVMs    Embed Quote