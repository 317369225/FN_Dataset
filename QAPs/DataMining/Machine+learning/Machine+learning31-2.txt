★Will deep learning make other Machine Learning algorithms obsolete?Every once in a while a new algorithms comes and makes all others (in the same domain) seems kind of obsolete when it comes to the same domain. Will deep learning make that related algorithms (backpropagation NN, GMM, HMM, ...)?
There have been many excellent answers to this question, but my two cents are: "Deep Learning" is a big tent and describes something more like a meta-algorithm for producing features rather than a machine learning algorithm per se. As a feature learning method it may very well make hand-crafted features obsolete.  Future feature learning methods may always incorporate some kind of deep learning to them. I'm not really sure how often an algorithm has come along that "makes all the others obsolete".  There have been big algorithmic advancements: linear discriminants (Fisher), perceptrons, logistic regression, multi-layer perceptrons, random forests, boosting, support vector machines, kernel methods, etc.  We should note that nearly all of these algorithms in some shape or form have been used in conjunction with deep learning where deep learning provides features from the data examples on which to apply these algorithms. Deep learning is also a big-tent meta-algorithm in the sense that there is no unified-agreed upon deep learning formulation.  There is a wealth of different formulations, loss functions, architectures etc. with no clear equality between them.  Support vector machines and logistic regression, however, have clear loss functions that distinguish them.  They are both "linear classification" methods but considered separate because they have different underlying objectives (and different theories for their performance).  Deep learning is sufficiently broad that it isn't characterized by a particular loss function and seems only cleanly separated from support vector machines or logistic regression because it isn't a linear or kernel method. Deep learning, however, has changed feature learning.  While there is still quite a ways to go before we no longer use HOG/SIFT in computer vision, or Mel Frequency Cepstral Coefficients (MFCCs) in speech, people have gotten state of the art results on MNIST, ImageNet without HOG/SIFT or even edges (http://papers.nips.cc/paper/4824...).  Furthermore, the best results in speech recognition are now obtain with Mel Frequency Spectral Coefficients which includes one less computational step than the Mel Frequency Cepstral Coefficients (MFCC) that were so commonly used in the past (https://www.inf.u-szeged.hu/~tot...). My opinion is that hand-designed features are likely destined to go the way of the expert systems from the '80s which is not to say that they will disappear completely, but that features we compute for new types of data are going to be learned from training sets rather than derived using expert intuition and knowledge.  My reasoning is simply that cycles are cheaper than synapses and deep learning will likely show that cycles can be as good or better than synapses at constructing features. I should note that we are not yet at this point. In speech recognition Mel Frequency filtering applied to spectrograms (or PLPs) is a necessary pre-processing step to get strong performance and, thus far, deep learning directly on the audio signal has not been as successful.  I predict this will change in the coming years as we dream up and experiment with more powerful deep learning architectures.    Embed Quote