★Why isn't supervised machine learning more automated?
In order to address the stated question ("Why isn't supervised machine learning more automated?"), we have to begin to understand how complicated supervised learning really is. (We'll get to the other questions in the "details" section in a minute.) Here's how complicated it is. Say you work at a lab somewhere. Your boss, Professor George O'Jungle, hands you a box marked "data". He mumbles, "use machine learning to classify this data", and then walks away. Here is a nifty picture: fig 1: George pictured here in skirt due to it being International Subvert Patriarchy Day You're pretty busy, and groan out loud: Q: Is there some way to automate this learning task? A: No, at least not at this point in time. You don't even know what's in the box. It could be hamsters or something equally ridiculous. Before we do machine learning, we must know what our observable phenomena is. Ok, so you decide to find out. You open the box. Inside are papers with numbers on them. Great, the empirical phenomena are something sane. If it was, like, bird migration patterns, we'd have to change real observations about that into useful learnable data. But here we have just a bunch of numbers. Computers are good at looking at doing stuff with numbers, so it looks like we're getting something for free. So now you ask: Q: Now can I automate this learning task? A: Still no. Your data are just numbers on a paper. In order to do machine learning, there must be a meaningful interpretation of our data. Interpreting the data is often called "cleaning" the data. Sometimes this step is trivial. For example, if your data are JPEG images, then you should probably just "interpret" each binary as a JPEG image. In other cases, it is less straightforward. For example, if your data are emails, then you'll want to remove the headers, HTML tags, images, and other vestigial data that could needlessly harm your algorithm. In other words, you are "interpreting" the data as a set of emails, where "email" is really just "text in the body" or something. Not doing this correctly can literally ruin your ability to do machine learning, so don't ignore it! Anyway, you now set off to find out how all these pages of numbers should be interpreted. You ask Professor George. He explains that they are images. He shows you how to use his expensive image-interpreting machine. You feed all the papers into this image-interpreting machine: [Cow image sources: File:Cow female black white.jpg, File:Cow-IMG 2050.JPG] Now you have a nice stack of images. So once again, you come back to your original question: Q: Ok, now can I automate this learning task? A: Sorry, still no. You may have a useful interpretation of your data, but you have not specified your hypothesis set. A hypothesis basically maps things to some set of classes (i.e., it "classifies" things), and a hypothesis set is the set of possible hypotheses. Examples of hypothesis sets are the SVM and the perceptron. Examples of a hypothesis are weight vectors that "classify" your data.  Note that hypothesis sets make assumptions about the data (for example, independence assumptions), so choosing the right model is often a balance between hypotheses that are (1) tractable to learn, and (2) expressive. In order to do machine learning, you need to know which hypothesis class you're using, what your learning algorithm is (e.g., gradient descent), and what classes you're mapping to. So once more you consult Professor O'Jungle. He explains that your task is to separate pictures into piles of those that contain cows and those that do not. You can use whatever hypothesis set and learning algorithm you like. "Great!" you think. "I choose the SVM, with whatever learning algorithm is fastest, and the rest will be easy." You sit back and grin. Q: ... Because now I can completely automate this learning task, right? A: Wrong. You may have c... (more)Loading...