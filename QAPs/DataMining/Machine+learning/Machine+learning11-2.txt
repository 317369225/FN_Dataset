★Is machine learning dying?
Certain areas appear to be.  With the great interest in Deep Learning, it appears that a lot of work in advanced convex optimization is slowing down. I have not seen much work on structural or transductive SVMs in a long time, although there are still a few holdouts, and a few interesting papers and methods come out from time to time. I also don't see a lot of new work in Kernel learning, except perhaps to mimic the great success on ConvNets. Good theoretical work is certainly lacking.  Methods like VC and PAC theory have not really proven of great practical use, and I don't think it is so necessary to prove a VC bound when a new method is released.  To that end, does anyone really know anything fundamental about Deep Learning that is qualitatively different from our understanding of Hopfield -like Spin Glasses from the  late 90s?    Embed Quote