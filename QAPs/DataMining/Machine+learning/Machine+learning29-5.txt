★Why isn't supervised machine learning more automated?
There is a whole sub-field in Machine Learning called Meta learning (computer science) dedicated to just this question. There are two aspects to this - Data and Machine Learning Algorithms (Duh!). The challenge is to understand both of them. What do I mean by this? A machine learning practitioner over several years of experience would ask himself these questions: 1] How big is the data? 2] Is data sparse? 3] Are the features boolean-valued or categorical or bounded-continuous or unbounded continuous or mixed? 4] Are there any missing attribute values? If yes, should I fill in the missing values? If yes, how? Pearson correlation? Matrix completion? 5] Should I normalize the data? 6] Given answer to 3 and 5, how do I normalize the data? Which normalization scheme should I use? 7] Is there bias in the data? Is there Selection bias in how the labeled data was obtained? If there is bias, how do I offset this bias? Importance weighting? Active Learning? 8] Do I need to reduce features? Are there noisy features? Is feature selection necessary? Which feature selection scheme (subset evaluation measure) to use? One has to answer all these questions everytime just to gain an understanding of the data. Now, the answers to the data questions has large impact on the algorithms used. Ideally, that should not be the case, but unfortunately it is. In many algorithms you can get improved performance just by normalization but that is not necessarily true for all algorithms. The size of the data dictates how complex your hypothesis set can be. This implies that we need to be able to understand algorithms and rank them not just by their performance but also by their complexities. Almost all the time, the answers and the decisions taken are driven by domain-knowledge or domain-experience. What's more, what works for one domain may not work for some other domain, which implies that certain observations we make, as users, are domain dependent. Hopefully, in the years to come we will see development in the meta-learning community which might make this whole process automated and alongside, the supervised learning community, will gain a better understanding of the datasets and algorithms. Active Learning: An alternative viewpoint could be: why try to understand the data and the algorithms? Most algorithms make i.i.d assumption of the data and as long as training data is sufficiently large and well represented, algorithms like SVM are guaranteed to give reasonable generalization performance. Why not just sample enough points and label them so that any underlying bias is eliminated and there is improvement in generalization. Active Learning, in some sense, is a step towards this. This is not particularly a bad approach, given that most organizations which use data-critical applications can afford few editorial resources. Combine this with the rise of crowd-sourcing applications like MTurk and CrowdFlower and you can get a very potent classifier with few additional cost. We will have to wait and see, how this space will further pan out.    Embed Quote