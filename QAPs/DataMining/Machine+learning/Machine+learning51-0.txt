★What are the connections between machine learning and signal processing?
The short answer is that both fields have contributed solutions to extremely important problems from the other, but the story is pretty interesting, so you should keep reading. (BTW, most of this is written from the perspective of an ML person to other ML people.) The ML influence on signal processingA generation ago, the central question of signal processing was how we can analyze signals -- that is, how we can extract information from a fine-grained signal, usually by decomposing it into a glob of information that is much coarser-grained. The textbook example is decomposing a raw audio signal into speech utterances, which is still an important application of the theory. Useful though this theory is, the field's fixation on it was not entirely healthy. For example, excitement sometimes got out of hand, like when people went around claiming that wavelets (which were a huge part of signal analysis literature at the time) could be applied to do everything from solving debt crises to making better malt whiskey, among other somewhat ridiculous claims. What the field needed was a good counterpoint, and in the late 1980s, they got it, through people like Albert Benveniste. He and his group were interested in understanding how we could make principled claims about which of these tasks wavelets were actually good at. They sort of went in the opposite direction, saying that: We should model the signals, rather than analyzing them. That is, instead of decomposing a fine-grained signal into a coarse-grained signal, we should think of the coarse-grained signal as a set of latent variables, and then use the fine-grained signal to statistically infer them. This is called a multi-resolutional model, because it deals with data of many resolutions. The problem of piecing together finer-grained observations to infer the latent coarse-grained variables, called synthesis, is a much beefier statistical inference task than analysis. Additionally, wavelet synthesis can be thought of as the "opposite" of wavelet analysis.One of their contributions to this area was to pose the task of wavelet synthesis as a hierarchical modeling problem. An example (which I have shamelessly stolen from http://artint.info/ ) might look very vaguely like the following tree, where the fine-grained observations are at the bottom, and the coarse latent variables are at the top. Now, if you know machine learning, th starts to look familiar. It's a classic statistical inference problem. That's not to say they don't have their own problems, though. For example, signal processing problems of this type are somewhat distinctive, in that they can be utterly massive, like when they try to estimate sea level (which is different at different points on the planet). And by "utterly massive", I mean "many more latent variables ML people tend to think of when they do inference." Takeaway: Something that people like Benveniste seem to be happy with is that signal processing has drifted away from pure analysis to adopt the modeling machinery of ML, and it has benefitted tremendously as a result. Certainly, analysis is still a part of signal processing, but in a lot of cases, the combination of ML and signal processing enables signal processors to solve some difficult inference problems that no other field is really equipped to handle, especially those in areas where signal processing has a more meaningful history than CS, like oceanography. The effect of signal processing on MLOne of the hallmarks of ML over the last decade or so is a massive proliferation of models that are extremely high-dimensional, but which in general cannot depend on there being a lot of data to train the model on. If you're a classically trained ML person, you know this is a serious issue, as illustrated by this picture I made: As an example, take the extremely popular model, Latent Dirichlet allocation. Its features are very high-dimensional count data, and in a general setting, we would want there to be a lot of data to train on. For most models that are high-dimensional, if we have too little data, we end up with very bad problems like overfitting. So the top line represents our general wish, and the bottom line represents the reality. Fortunately, (and this is especially true of LDA) we don't care about the general case. We avoid this issue by assuming that the data (and usually the model too) are sparse--that is, that most of our features occur very infrequently, or are otherwise unimportant to our model. Over the past decade, the study of (very generally speaking) how sparsity affects what you can do with data has simply exploded. One remarkable result, by Tropp and Gilbert [Page on Caltech.edu]demonstrates that you need only random measurements to completely reconstruct a -dimensional signal with nonzero entries, and that in fact it is computationally feasible to do. In ML specifically, this sparse setting has led to breakthroughs in noisy matrix factorization and matrix completion (which is the essence of the Netflix prediction prize), along with dimensionality reduction, and Venkat Chandrasekaren's attempted formalization of the tradeoff between sample complexity and computational complexity. This is a few results among many, many, many other applications. There are also many other amazing non-ML results from people like Terence Tao, Emmanuel Candès, David Donoho, and so on. Takeaway: Actually, signal processing wasn't really the field that made these breakthroughs, but a lot of the tools and concepts that they are famous for were responsible (especially when combined with control-theory style numerical linear algebra), and it does not seem to be an exaggeration to say that signal processing people tend to have understood sparse signals better than ML people. Much of ML is about understanding how and when we can do inference, and the literature surrounding sparsity seems have taken us in an interesting direction toward really understanding this problem as it exists today. Whether we like it or not, this contribution to inference is going to greatly affect out trajectory in the next decade, and probably the next few decades at that. We owe this debt to a lot of people, but certainly signal processing work is on this list. If you enjoyed this answer, you might enjoy my Quora blog, in which I talk about this sort of thing a lot.    Embed Quote