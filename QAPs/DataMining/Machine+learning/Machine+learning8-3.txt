★What are the best interview questions to evaluate a machine learning researcher?
Josh and Pete make excellent suggestions and I use some of those open-ended questions (like design a recommender system) as a warmup or as phone interview questions just to make sure the candidate has a basic idea of posing real-world problems as one of the well known classification, clustering, ranking problems. However, in an environment where you get to interview a candidate in person for only 50 minutes (with 6-7 such onsite interviews per candidate) I often tend to focus on a narrow problem that they can implement well in that time and test how well someone has a grasp of the theory behind it. Often ML interview candidates at Twitter come with a few years of industry experience (great hands on but at the risk of being unaware of literature and forgetting fundamentals) or straight out of grad school (mostly good awareness of literature and basics but little implementation experience). To be a successful ML practitioner it is important to have combination of both skills. To give a concrete example, consider one question I like to ask our ML candidates -- "implement logistic regression training for binary classification". This should be straightforward with only a few lines of code and should not take the candidate more than 10 (or at most 15) minutes to write down the objective function and finish a basic implementation. If your candidate struggles with it, it is a red flag. If your candidate, like someone I once interviewed, says "I've always been using libraries like WEKA or Mallet" then that's a big red flag to me esp. when we're interviewing for a ML role. This is a basic algorithm (like the "binary search" of machine learning) and everyone who has studied ML is expected to know. Once we get through these sanity tests, it's time to probe for depth. If the candidate has not already used a regularizer in the objective, I usually ask probing questions about weights learnt by that implementation and try to steer them towards regularization. If candidate does not know what regularization is or, worse yet, just used it in the objective without knowing what it is, that's a red flag. Most practical implementations will need some form of regularization. "How will you make one small change in your training code to add L2 regularization?" Once we get past that, I ask about changing that to perform L1 regularization. A lot of candidates don't get past this stage. The ones who do are usually doing well in the interview. Once we get past that, I ask more deeper questions like when is L2 preferred over L1 and vice-versa? Why does L2 produce smooth non-sparse weights? The last question usually involves a bit of theory since it involves showing (or at least hand-waving) the equivalence between MLE with L2 and MAP estimation with a gaussian prior on the weights. If the candidate gets this far, fantastic! If the candidate has progressed through all questions satisfactorily except the last, I usually give her some leeway.    Embed Quote