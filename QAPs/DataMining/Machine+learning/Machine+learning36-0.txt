★How does NASA use machine learning?
A lot of ways! Here are some that I know about off the top of my head: Feature detection and classification using Hubble or Kepler data for identifying stars, supernovae, clusters, galaxies, quasars, exoplanets, etc. You can also use the same techniques for understanding a planetary surface from rougher images, sometimes in EM spectrums that are not in the visible range. Planetary rovers and other vehicles would also use this to understand its surroundings and go check them out, avoid them, or at least snap pictures from afar so they don't miss interesting scientific stuff. Navigation and path planning of planetary robots so that they don't get stuck or take forever to get to their destination. Usually this is not 100% autonomous. The mission planners set general waypoints on the path to the final destination, but the rover itself should be figuring out how exactly to get to that waypoint. Two or three dimensional image reconstruction using satellite data and/or rover data. This helps with the path planning bit for rovers. It's kind of difficult to know what you're doing in general if all you have is a camera on the ground. Utilizing an eye in the sky autonomously is an interesting and important problem. You also have the smaller problems with the rover of telling what in the world it's looking at. So things like horizon detection and arbitrary feature selection (like, larger features beyond rocks and things) would also be a part of this whole system. Anomaly detection in autonomous systems. So you have a bunch of sensors around the engine system of an F-18. How do you detect a potential failure? Well that's kind of easy, but you want to do that way, way before any failure actually occurs. Inductive monitoring is a technique developed to detect potential failures much earlier than they would actually happen. One experiment showed IMS detecting a coming fault 6 days in advance. Adaptive science (the intelligent gathering of scientific data). You have this rover or probe that has limited power capabilities. The whole point of the mission is to find out more about stuff, so you want to take as much data as you can. How do you balance these two constraints? One thing you can do is take sparse samples and reconstruct the reality of the environment based on those samples. In this way, you've used less power to get roughly the same data, if you're doing it correctly. This is great because then maybe you can spend more energy on other stuff (and there is always more stuff that would be nice to do). Event detection. Say you're on Titan, which has a methane-ethane atmosphere as well as lakes and seas. It has an analogous climate to Earth, but much colder and weirder. What does a storm look like? No one knows, but you want to be able to learn this from the data you've collected. Doing some time series analysis and using some cool learning techniques, you can come up with some learned states that tell you if the environment is in a state you'd be interested in or not. I'll add more if I remember them.    Embed Quote