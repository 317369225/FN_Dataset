★Why is machine learning not more widely used for medical diagnosis?
An additional problem is how the data is accumulated. The physical exam is becoming a lost art, as evidenced by a myriad of start-ups using emails and mHealth for diagnosis-completely excluding the physical! Scary. To make a proper diagnosis, much does depend on the nuances one gains in examining the patient. It is a dialogue and the subtleties can't be overemphasized. I had a great teacher in med school, Dr. Phillip Tumulty. He wrote a classic entitled "The Effective Clinician" (http://amzn.to/xQMgf6 ). Dr. Tumulty got the toughest cases referred to him from around the world, and he always picked up something someone else missed which led him to the correct diagnosis. No matter how advanced the algorithm written for an expert system, nothing could ever replace the consummate clinician. That said, I am a big fan of machine learning. There are just two many possibilities to consider for a mere mortal (unlike Dr T). Thus the computer serves as a useful adjunct - not a replacement. We are going the wrong way, however. I practiced in Tucson for several years. The hospital put in an EHR system - EPIC. Each clinician had to spend two days in training! Counter-intuitive, unwieldy, unmanageable garbage. Seemed to be designed by well hackers with good intentions, but having way  too much functionality and impossible to navigate. Steve Jobs knew, if it requires instructions, it's not user friendly.  So what happened. The hospitalists (doctors that admit patients and oversee their care while in hospital) would almost always use the default choices. For example Chest: Clear to auscultation. No murmurs. Abdomen: Soft without organomegaly. As an interventional radiologist I would be consulted for a procedure, I would go see the patient, examine him/her and come back to the nurses station to enter my note. Time after time, the admitting physical was completely useless. Obvious big misses: a thyroid mass; a large node in the axilla (arm pit), a swollen leg etc etc. You wonder, did they even see the patient? If they did, was it quicker to just use the defaults instead of entering their findings?  The point is this: If a computer algorithm is using this kind of useless data to make determination of disease process, garbage in, garbage out. Thankfully, medical imaging (CT and MRI particularly) has gotten so good, that things missed on physicals get picked up. In the busy ED, triage nurses where I worked would often send patients for CT scans before the doctor even saw the patient. Abdominal pain: CT scan. Headache:CT scan. How would I know this? I would call the doc with the result and ask some questions and he/she would say "I haven't seen the patient yet."  It's called ED protocol. They have a separate sheet for various complaints (presenting problems). Depending on your problem, you get shunted into various exams such as blood and urine tests, ECG, and medical imaging. EDs are so busy that unfortunately these protocols are the only way to get throughput. And yes, a nurse will always see you first. Those ED nurses are damn good having seen so much pathology. The docs count on them to let them know when they need to see a patient right away. But machine learning? Still need the human factor.    Embed Quote