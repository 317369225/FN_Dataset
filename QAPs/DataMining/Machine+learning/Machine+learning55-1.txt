★How can a beginner train for machine learning contests?
My approach to learning most new things is to first get some of the basics down so that I have a framework, then put it into practice. In terms of getting a framework, the course that Benjamin Haley mentioned would be a great place to start.  If you'd rather learn from a book, you can download Elements of Statistical Learning at data mining, inference, and prediction. 2nd Edition..  It's a big book, but looking at the chapter headings and the first page or two of each chapter would give some good context.  Aside: Fig 7.3 on pg 225 is a nice depiction of the bias-variance tradeoff, which is IMHO the most useful piece of learning theory for practitioners to know.  Table 10.1 is also a great overview of some different supervised learning algorithms. A more detailed "curriculum" is (source: Becoming a Data Scientist - Curriculum via Metromap - Pragmatic Perspectives ): The second, and I think more important piece of my advice is to just try it!  Most of the hard work is often getting the data processed nicely, and the stats/ML background isn't as huge there.  It also seems like a lot of the contests are won by similar methods.  For example, At Kaggle, It’s a Disadvantage To Know Too Much mentions that the Random forest algorithm works well a lot of the time.  You can get the data into scikit-learn: machine learning in Python and run a random forest without knowing anything about machine learning, statistics, or the problem domain.  Once you have run that, just be curious.  Try using the different classifiers in scikit-learn.  Try processing the data differently.  See how different approaches work using different evaluation techniques from 3.5. Model evaluation: quantifying the quality of predictions .  You'll notice things like "this model gets really high accuracy, but really low area under the ROC curve...what's going on?" (this happens when you have a lot more instances of one class than another). It used to be harder to find good problems to work on, and see if you're doing a good job.  With Kaggle, that's a lot easier.  Not all of the problems are earth-shattering, but they provide you with 3 key things: data, evaluation criteria, and quality comparisons.  As you do it more and more, you might start to realize the shortcomings of a certain technique, or that the evaluation criteria for a competition aren't as good as they could be, but that stuff is really hard to know when you're starting out.  When you have to think of it on your own, its even harder.  One last piece of practical advice--don't try to learn everything at once.  I'm not sure what kind of programming you've done, but I would stick with the competitions where you don't have to worry about the data fitting into memory before you start working on the "big data" stuff.  A lot of work in industry will be larger than memory, and those are skills to develop eventually, but there's no point slowing down your understanding of the core learning algorithms in order to learn that part simultaneously.    Embed Quote