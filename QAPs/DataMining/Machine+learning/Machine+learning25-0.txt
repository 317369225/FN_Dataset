★Is Measure Theory relevant to Machine Learning?
Knowing the basic ideas behind measure theory is certainly helpful for probability theory, but I guess most machine learners have a more "intuitive" approach to probability theory so it's not really essential. Measure theory is of course absolutely essential to have a mathematically sound construction of probability measures and so on, so in that sense it's important. On the other hand, as long as you deal with real vector spaces and continuous functions (or functions which are somehow strange on at most countably many points), every set or random variable you encounter is measurable anyway, so it's not really necessary to know all about measure theory. Measure theory actually gives rise to a quite elegant formalization of probabilty measures and integrals (much better than what you usually get from physics), because you can uniformly deal with measures which have a density and discrete measures. Otherwise you end up with strange stuff where you have an integral with a density and a sum of "point masses". Finally, one area where you absolutely need measure theory (but nobody really seems to care) is learning theory. For uniform convergence bounds, you consider the probability of a supremum over an infinite set of functions, but "out of the box" measure theory only allows for constructions with countably infinite index sets, so you need a bit of extra. However, the book Weak convergence and empirical processes (http://books.google.com/books/ab...) is the only one I know of which deals with this in a rigorous manner. In the end, the things you can do are very similar, so probably it doesn't really matter.    Embed Quote