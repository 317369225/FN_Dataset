★Why do we use least squares rather than mod?Appreciate this probably a very naive question. Obvious we want to minimise both + & - value of the error, but why square it rather than just using the absolute Presumably squaring is better than linear (because bigger errors get more weight?)
Imagine we pick four samples from some distribution—maybe we get 14, 5, 11, 6—and we want to somehow model the center of the distribution.  If we pick the that minimizes , then we don’t even get a unique answer: any between and gives the same result.  But if we pick the that minimizes , we get the mean, .  This turns out to be an important property.    Embed Quote