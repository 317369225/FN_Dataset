★Why is the output of logistic regression interpreted as a probability?
The function for a logistic function is given below, where a linear function is transformed as such. Note -- alpha can also be shown as beta-initial, and there can be multiple terms representing multiple features. Parameters (such as beta) can be adjusted based on the data, resulting in this function.  From: Figure 7.1: Logistic regression Because this classifier is binary, we want Y to only equal 0 or 1, and nothing in the middle. However, the logistic function is perpetually increasing between X = 0 and X = 1 (and theoretically never even reaches Y=1), so there is a probability associated with every X value on the curve. Generally, we'd assume that anything over P(y|x) = .5 is a success case (Y=1), and give the associated probability along with that. In the graph above, when X = 6, Y is over .5 and can be assumed that it equals to 1;  according to the function there is only a 70% probability that is the case. You can see that at X = 6, there are mostly Y = 1 cases in the data, but also a Y= 0 case. This is why the output of logistic regression is given as a probability rather than a definite Y = 0 or Y = 1.    Embed Quote