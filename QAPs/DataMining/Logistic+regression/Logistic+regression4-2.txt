★What is logistic regression in layman's terms?
I really like answering "laymen's terms" questions. This does take more time to answer, but I think it is worth my time as sometimes I understand stuff even more clearly when I think I am explaining it to somebody in high school. I'll try to make this as non-technical as possible by writing this entire article without any complex equations, which is will be a challenge to a math junkie such as myself. But rest assured, this won't be a one-liner. You may have heard about logistic regression from a blog, newspaper article etc. You'll only understand what it is, when you understand what it can solve. Problem: Let us examine a simple and a very hypothetical prediction problem. You have data from past years about students in your class: say math score, science score, history scores and physical education scores of their final board exams. Also when they come back for school re-union 5 years later you've been collecting data whether they were successful or not in life. You have about 20 years worth of data. Now you want to see how the students passing out this year are going to be 5 years from now (we'll keep ourselves simple, let's just consider them being successful or not). I know it is debatable whether high school score really can predict whether a person is successful or not, but for now let's assume that in our perfect world that these things are related, and it does really help in determining a person's success. Now we'll add one more character in our example, say you know that Sarah's scored 94 in History, 82 in Math, ... and now you want to predict how Sarah successful she would be 5 years from now. This exactly is the problem logistic regression is out to solve. This is called a classification problem as you classify an object as: belongs or does not belong. Side Note: Your data might look something like this: She, Ben and Rock (from the spreadsheet screenshot) will stay with us till the end of our problem. OK, now we know what logistic regression solves, I'll explain how it solves it: The How Part: Logistic regression makes its predictions using probability (There are tons of debates going on to understand what exactly probability means, for our understanding it'll be sufficient if you know this much): 0 = you are absolutely sure that the person is not going to be successful in her life 1 = you are absolutely sure that the person is going to be successful 5 years from now on Any value above 0.5 you're pretty sure about that person succeeding. Say you predict 0.8, then you are 80% confident that the person will succeed. Likewise, any value below 0.5 you can say with some degree that the person will not succeed. How does it make this prediction? We develop something called a model using your training data. You have your scores (independent variable), you also know whether a person succeeded or not (dependent variable). You somehow[1] come up with some predictions and you look at how you close your predictions were with your recorded data. Say you predicted 0.9 on Ben, and in the same manner you're pretty close in all your predictions then you have a very developed a pretty good model. On the contrary you could also predict 0.2 on Ben, then you're model is way off in predicting whether Ben succeeded or not. We go about looking at various models[2] (of course not randomly) and find out the model which fits very closely with our recorded data. This step by which we arrive at a model is called model selection. Then you plug in Sarah's (and also everyone in your current class if you wish) scores into this model and it spits out a number between 0 and 1. By looking at this, if it is greater than 0.5 you say you predict person is successful. If it is less than 0.5 you'll say they might not be successful. Note to readers: If you think things can be simplified even further, leave a comment. If you think you can explain it even more simpler terms, please don't hesitate write another answer I'd love to see diverse answers. Advanced Note (Gobbledy gook, you can safely ignore): Logistic Regression can also solve multi-classification problems like whether it belongs to category A, B, C or D. [1] You could refer the answer below written by Alaka Halder as she does a fine job in explaining the mathematics behind logistic regression. Alaka Halder's answer [2] We try to do something called minimizing the squared error. We take a look at sum of errors for each prediction in each model and try to see if we can go even lower than it.    Embed Quote