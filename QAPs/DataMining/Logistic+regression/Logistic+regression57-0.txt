★In what circumstances or properties of the data will decision trees perform worse than logistic regression?
I can see this happening under only two circumstances: Decision trees (DTs) find you decision boundaries that are composed of "axis-parallel" line segments - i.e. your decision boundary is composed of smaller boundaries each of which is parallel to an axis. Logistic regression (LR) finds you a line, oriented in whatever direction the line separates the data best. If the ideal boundary for your data is just one line, which is not axis parallel, DTs are going to have problems compared to LR ( 3 Oblique decision trees may be able to address this - but these are computationally hard problems to solve) .   For a decision boundary that does not have the property mentioned above, asymptotically DTs should always beat LR. What if circumstances are far from being asymptotic? Since DTs suffer from higher variance compared to LR, at small quantities of data they are susceptible to overfitting and thus, would result in higher generalization error.    Embed Quote