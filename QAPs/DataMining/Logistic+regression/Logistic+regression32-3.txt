★Why is Support vector Machine hard to code from scratch where Logistic Regression is not?In SVM, each of the feature gets modified by application of kernel function on it, the cost function remains the same as in logistic regression but with modified features. Whereas, logistic regression is SVM with linear(or no) kernel , still why it is said that SVM is hard to implement and an already implemented library like libsvm should be used.
The main difference between SVMs and Logistic Regression is not in kernels but in math behind. Most simple SVMs have a linear kernel, but in practice non-linear kernels were more robust. If you have some mathematical background, you might have noticed that unlike other regression methods, SVMs are based on concept of Lagrange multipliers (optimization under constraint). They are not only performing a gradient descent, but they also enforce a separation of the variables from different classes, despite them being extremely close one to another. This makes SVMs converge so rapidly, but it requires to get correctly the matrix manipulation required to solve Lagrangian, which is quite tricky, especially if your memory of linear algebra is not rock-solid. And even if it is, you still might make some minor coding errors that would literally take hours if not days to track down or would go unnoticed unless you perform an extensive (and time-consuming) testing. On the opposite, Logistic Regression is just gradient descent and thus is pretty straightforward to program and test    Embed Quote