★Why is the output of logistic regression interpreted as a probability?
This question brings up the issue of Calibration (statistics): just because the outputs are between 0 and 1, why should we believe they are accurate probability estimates? Depending on what the model is used for, this may or may not be important. Sometimes all that matters is the ranking of instances produced by the model or the ballpark estimates "probably class 0" and "probably class 1." In other cases, you need an assurance that if the model predicts 0.15, then very close to 15% of the instances receiving that score will be of class 1. There’s been research on model calibration—transforming (arbitrary numerical) classifier predictions to accurate probabilities. See the above wikipedia link for a starting point. But those calibration methods don’t seem to get applied to logistic regression, and I think the reason is that, as the answer by My Incas already says, logistic regression is a probabilistic model. If you trust the model’s assumptions, then you should trust the output; it’s a valid probability estimate within the best fitting model. (Of course, you could say the same about naive Bayes, a model people do re-calibrate—but then, people rarely believe that the assumptions of naive Bayes are correct.) On the other hand, why should you trust logistic regression’s assumptions? You shouldn’t necessarily. One thing you might want to do is run a goodness-of-fit test, traditionally a Hosmer–Lemeshow test, to see how well the model’s predictions match the data, and create a calibration plot, like here: Hosmer-Lemeshow goodness of fit test. There’s a nice discussion of the distinction between high predictive accuracy and the fit of a model (something we often gloss over in machine learning) at this link: Hosmer-Lemeshow Test for Logistic Regression. If the model fit is poor, then there's room for improvement by changing the feature set, the form of the model, etc. And one would hope that such improvement would then translate into better accuracy and better probability estimates.    Embed Quote