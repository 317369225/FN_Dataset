★What is logistic regression in layman's terms?
Logistic (or logit) regression is a modeling technique: For any given X, the logit model provides the value for the observation that can be used with the logistic cumulative density function to find the probability that Y = 1 for that observation. In simple (i.e. binary) logistic regression, the dependent variable is a dummy variable (coded 0,1). The image below (from Econometrics For Dummies, by Roberto Pedace: ISBN 9781118533840) shows how we can find the probability for any given observation. Hence the logit model and linear probability model (LPM) using ordinary least-squares (OLS) estimation answer the same question. So why even use the logit model? Because it gives more “sensible” predicted results (Y values) than an LPM might. An LPM model might output Y values outside the [0,1] range of probabilities. Furthermore, the error terms for LPM estimation are always heteroskedastic. The probability distributions for both models appear similar, as shown below, so they give equivalent results: With the logit model, we use the logistic distribution. The function approaches 0 and 1 asymptotically, so Y values stay within the [0,1] range. The conditional probability distributions (CDF) for the three main "probability" models -- logit, probit, and LPM -- are given below (diagrams from the same book), to illustrate this: There’s no real difference between using a logit or a probit model; sometimes one is more efficient than the other. Edit: As Shakti Amarantha points out in the comments, the logistic distribution can lead to an underestimation of "fat tails" or rare events. Usually this is not a problem, unless you are working in fields like risk analysis (and thus dealing with pretty rare events). Please let me know if you would like more clarifications. I realize that I had to gloss over certain things, and I'm not sure what your level of understanding is. I'd be happy to answer questions.    Embed Quote