★Simple algorithm for trend detection in time series data?I'm looking for a simple algorithm to detect trends in time series data. It would be great if there is even an implemented java version of it. I'm not looking for the best most accurate algorithm, but I just want an algorithm that simple and good enough for the job.
There is a crude form of a Kalman filter called the Holt-Winters method: The local trend is indicated by the Growth parameter b_t which is updated as new data y_t arrives. The primary user input is the choice of alpha and beta, which can be thought of as smoothing factors (see Sarah Gelper, 2007, Robust Forecasting with Exponential and Holt-Winters smoothing, useful for parameter values). As alpha and beta (both < 1)  approach zero, one gets an estimation of a longer term trend.  The estimation of the seasonal component is optional, depending on your understanding of the data (Level  l_t is often used to deseasonalize data). The algorithm is very simple to implement in any programming language, and in many cases, more accurate in practice than sophisticated Box-Jenkins ARIMA models for forecasting trends (see the Makridakis competitions).    Embed Quote