What are the most important things to consider when designing a data model for a performant website?
Unless you're working on a site that you know with 100% certainty is going to be massive on day one (say, a reimplementation of the cnn.com home page) the most important thing is to make sure you know how to migrate your data from its initial model to something else. This can be in the form of making sure you have a working export/import API, among other techniques. The ability to export and import your data has the additional advantage of being usable for certain kinds of automated tests so it's worth doing even if you never need to migrate anything. You may be able to anticipate some of your bottlenecks up front, and to the extent you can design your data model to mitigate them without adding to your development effort, you can do that -- if you have a choice between equally complex models A and B, and you are pretty sure B will perform better with your anticipated workload, choose B. But if B is more work, lean toward choosing A; getting something out there quickly is more important. The reason to focus on migration paths in terms of designing your data model for performance is simply that you can only anticipate *some* of your bottlenecks. You need to be able to react cleanly to the ones you didn't think of ahead of time, including ones that come from changes to your product you haven't realized you need yet.    Embed Quote 