★How does probability distribution work when constructing a new random variable?
This question is so incredibly vague that it's impossible to know what you actually want to know, so instead, I'll tell you what I want to tell you. First, random variables are created to model something in the real world.  Do you want to see how long it will take for a particle to radioactively decay?  We can make a random variable for that.  Do you want to know how much money you'll win on those ten scratch-off lottery tickets you just bought?  We can make a random variable for that.  Do you want to know hold old you'll be when you die?  We can make a random variable for that too.  The next question is, what does it take to make a random variable?  Without getting into the technical details (which are important but not very interesting to a novice), the most important thing you have to specify is the distribution function (also called the cumulative distribution function and sometimes the probability distribution).  In fact, in some sense, the distribution function tells you EVERYTHING there is to know about your random variable.  So what is the distribution function?  Check out  Michael Lamar's answer to What is a cumulative distribution function?  I won't bother to rewrite that bit. Now, the distribution function is really the bottom line, but when you're modeling the real world, you don't usually start immediately with the distribution function.  That's just not how people naturally think about probability.  Instead, we typically start by describing the probability mass function (i.e. the PMF) or the probability density function (i.e. the PDF) depending on what kind of real-world problem we're trying to model.  So what's the difference between the PMF and the PDF?  Check out Michael Lamar's answer to What is an intuitive explanation of the difference between probability and probability density in PMFs and PDFs, respectively?  Again, I won't bother to repeat what's already written on Quora. The reason that the PMF or the PDF is the natural place to start is that those are the functions that tell you which values are the most likely to be seen and which are the least likely to be seen.  If you're trying to model some random variable, that's probably what you understand the best.   Once you have the distribution function or the density function or the mass function, you're on your way.  You can do all sorts of useful things with them.  You can find the (or rather a) median value of your random variable.  You can find the mean (assuming it has one).  You can find the probability that your random variables falls in ANY interval.  You can find distribution functions for NEW random variables that are just functions of your old random variable, and then start all over finding new means and medians of this new random variable.  You can try to infer some unknown parameter from your distribution based on an observed random variate.  You can think about what might happen if you had lots of independent copies of your random variable.  You might be able to make a better inference in that case.  And those are just the things you might learn how to do in your first course in probability and statistics.  Just imagine how much more you could do if you keep learning even more!    Embed Quote