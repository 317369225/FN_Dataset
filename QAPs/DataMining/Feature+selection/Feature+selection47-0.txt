★Does support vector regression have the ability to deal with very sparse features? When do I need to do feature selection?
Yes, SVR has the same properties with respect to feature sparsity as SVM does. However, if you have thousands of such features there are probably more appropriate or efficient algorithms. Whether and how to do feature selection depends on whether the problem you are experiencing is one of poor results or unacceptable computation time (it is not unheard of to use SVM for feature selection in the context of other more complex learning algorithms), and why you opted for SVR in the first place. Pre-selecting (filtering) features can make things easier for many algorithms, but you should ask what assumptions your particular feature selection algorithm is making that your regression algorithm is not, and whether the combination makes sense. In your case (and especially if you are using a non-linear kernel), any feature selection algorithm which is based on analysing the potential of features independently from one another will immediately make half of the benefit of using SVR redundant. Conversely, wrapper approaches make fewer assumptions and therefore better leverage the particular strengths of your regression algorithm, but they can be expensive - which doesn't help if your problem is unacceptable computation time.    Embed Quote