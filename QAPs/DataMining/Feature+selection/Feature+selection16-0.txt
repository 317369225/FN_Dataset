★Which one is harder, feature engineering or feature selection? Why?
Feature engineering, hands down. There are dozens if not hundreds of well-researched feature selection algorithms, many of them already implemented in an open source package in whatever language you use. Feature selection algorithms that work well tend to work well for many domains. Feature engineering has to be reinvented for every new problem. It is sometimes hard to find engineers that are competent machine learning researchers who also have enough domain knowledge to engineer features for your problem. Part of the promise of deep learning is the ability to skip the difficult feature engineering process and use relatively raw representations of your training data. Even then, it's not always immediately obvious how to turn an instance from your training set into a vector that can be fed into a neural network. Feature selection, on the other hand, is brute force solvable. If you had enough computing resources and time, you could try every combination of your features to determine which subset works the best. The art of feature selection is figuring out how to come up with a decently good subset of features in a reasonable amount of time.    Embed Quote