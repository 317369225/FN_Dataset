★Which feature selection approach typically yields a more accurate (in out of sample performance) model: black box or intuition (more detailed explanation of question inside)?
TL;DR Three observations: 1. There's one critical variable that determines which is more likely to succeed: the amount of data that you have. 2. There's a third option that's an iterative variant of the other two: taking an experimental approach to testing your intuition. Intuition isn't fully useful; if it was, we wouldn't be using a classifier. More details follow. The amount of data you have When working with Ross Quinlan (inventor of ID3, C4.5, Cubist, FOIL, etc) many years ago, he told me of a rule of thumb which I have found to be incredibly useful. If you you have n classes and f features, then generally you need at leas 5.n.f training examples. Anything more than that and you're almost definitely overfitting. Of course this is a massive simplification and ignores cross correlations, attribute complexity (binary vs floating point) etc. Still very useful. And let's assume for now your set of attributes is pretty comprehensive -- it characterizes the instances well. Say your Quinlan factor (a term I just coined) is 10,000, i.e you have 10,000 examples for every class and attribute combination.  It pretty much doesn't matter what you do: pretty much any learner will work.  If you really want to make sure you're not overfitting, run some feature subset selection algorithm (e.g. Kohavi's and John's Wrapper -- Page on Stanford). But if your Quinlan factor is 6, then you have to be very careful with your features, and you don't really need to go to the next stage below.  A hybrid approach I don't put a lot of faith in the intuition approach, because if our intuition approach was any good, we wouldn't be using machine learning at all. We'd work out the one magic feature that was 100% correlated with the label class and build a lookup table. What I've found most practitioners do is take an iterative approach that is something like this. This involves getting down and dirty with the data. 1. Start with a basic set of features that you think might be useful. 2. Run some tests on this data to get accuracy numbers. 3. Do some analysis of the data; this is where the intuition and cleverness comes in. This is the real point where data scientists earn their keep. Look at the confusion matrix and see which classes are being confused. Why is Class A confused with Class B so much? Are there features we could add that would tell these two apart? Zero in on why these two features are confused. If you have a comprehensible algorithm like a decision tree, look at different paths. If you have an SVM, look at which concepts are being chosen as part of the support vector. Look for signs of overfitting. Understand what the issues are: is the concept too difficult to express in the hypothesis language of the learner -- (e.g. am I using Naive Bayes when correlation is a big deal? Am I using a linear SVM when things are clearly not linear?) or is it that you need more features? If you do need more features, try to craft features that would help with the misclassified instances. 4. Make a selection of the next step: expanding the search space/algorithm of the learner, adding more features, removing features.  5. Go back to step 2. This is really what I think most practitioners do. What differentiates the strong from the not-so-strong is their depth and understanding in step 3 -- in being able to understand what's going on with the classifiers, and their creativity in coming up with new features.    Embed Quote