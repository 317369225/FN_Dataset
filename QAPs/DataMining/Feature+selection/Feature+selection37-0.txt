★How do I use cross validation for feature selection in a linear regression?
The simplest form of cross validation randomly splits the sample into two pieces, a training sample and a validation sample, usually 2/3 and 1/3, respectively. You use the training sample to fit the model. Then you use the estimated coefficients from the training sample to generate predicted values and the resulting R^2. That R^2 will be more accurate than the R^2 from the training sample because the original model will be affected by peculiarities in the training sample. If you seriously overfit the training sample, the cross-validation R^2 will crash. There are more complex versions such as K-fold cross validation but that should give you the idea.    Embed Quote