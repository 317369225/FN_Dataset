★How valuable do you think feature selection is in machine learning? Which do you think improves accuracy more, feature selection or feature engineering?How valuable is perhaps an analysis like this (see link)  when dealing with a regression or a classification problem? Feature importances with forests of trees     Would it be better to engineer features in your opinion?
Feature engineering and feature selection are not mutually exclusive.  They are both useful.  I'd say feature engineering is more important though, especially because you can't really automate it. In the real world, my team at Google generates a feature importance report like the one you linked to every time we train our classifier.  It's helpful, and it complements feature engineering since it gives some information about how well a new feature compares to our existing ones and also how well a tweaked feature compares to the original one. Feature selection is itself useful, but it mostly acts as a filter, muting out features that aren't useful in addition to your existing features.  A lot of making a real world classification system work well is understanding of the problem domain and creatively making good features.  Feature selection does nothing for you there. On a more technical and practical note, we've found that if you take a good but sparse signal (high precision/low recall feature) and add random noise to fill in the sparseness, the random forest variable importance measure increases.  This is a bad quality of the measure.