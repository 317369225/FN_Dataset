★What are some general tips on feature selection and engineering that every data scientist should know?In most of Kaggle competitions the participants talk about selecting what they call Golden features and how it is more important than selecting the classification algorithm. So how can I derive such good features and what are some good measures for assessing them?
Actually the success of all Machine Learning algorithms depends on how you present the data. For example, an image can be presented by both pixels or other high level features such as edges. These golden features can be extracted in two ways: 1. By a human expert (known as hand-crafted) or 2. By using automated feature extraction methods such as PCA, or Deep Learning tools such as DBN. Both 1 and 2 can be used on top of each other, too. But to evaluate the goodness of each feature, there are some criteria such as Gini-index, Info-gain, Likelihood ratio, etc.    Embed Quote