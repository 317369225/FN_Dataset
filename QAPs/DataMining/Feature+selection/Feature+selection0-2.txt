★What are some feature selection methods for SVMs?
While L1 SVM is a great technique, it does not actually solve the problem of selecting features when the solver fails to converge (i.e. due to round off error when dealing with millions of features). Vapnik discusses this in: Feature Selection for SVMs J. Weston , S. Mukherjee , O. Chapelle , M. Pontil T. Poggio , V. Vapnik and suggests first relaxing the integer constraints on the SVM optimization problem to get a partial solution, and then running a full SVM For problems like IR (text classification), a crude way to select features is just pruning by IDF. For example, why include a feature if it only appears in 1 document, or in every document?   In traditional non-linear signal processing this is just a band-pass filter A "fancier" approach is to run SVD/LSA on the documents first...the idea here being that if the SVM can not converge (that is, the  constrained convex optimization problem), maybe an unconstrained optimization problem (SVD) can converge in the same space.  This is, in a crude sincesense, in the spirit of what Vapnik is saying (above) by relaxing the constraints on the convex optimization problem.