★What is the difference between a recurrent markov chain and an absorbing markov chain?
In a recurrent Markov chain, the probability that you will return to any given state at some point after visiting it is one.  However, you can visit other states along the way. In a Markov chain with absorbing states, there is at least one state such that .  Once you get in that state, you're not leaving. There's also the possibility that there's an absorbing set of states.  Consider the Markov chain on the state space with and .  In this case, neither of the states or is absorbing, but the state is not recurrent. In Markov chains over infinite state spaces you also have the possibility that no set of states is absorbing and there are no recurrent states.  An example of this is a Markov chain on the integers started at with the transition probabilities given by for all .    Embed Quote