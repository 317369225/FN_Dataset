★What is a Markov chain?
Simply put, it's a process where transitions from a given state are random, and only depend on the current state. The following analogy might help (there are others at http://en.wikipedia.org/wiki/Mar... but I tried to come up with one of my own, as silly as it seems). Assume that you are on date. Assume the probability of a second date is 50%, unless the weather is hot, which causes you to sweat excessively and thus reduces your chance of a next date to 20%. This probability is not dependent on how your previous dates turned out, or whether it rained a week ago.  So it is a Markov Chain.    Embed Quote