★How are artificial neural networks and Markov chains different?
Let me first start by defining artificial neural nets and Markov chains. That should let us easily see their differences. Sometimes a mathematical system can be characterized by the state it occupies. For example the properties of a system with discrete states may be described fully once one knows which of S possible states is currently occupied. A Markov chain is a mathematical system that undergoes transformation from one state to another on a state space (eg over successive time instants). Such a sequence of states is characterized by a Markovian state transition probability, ie the probability of occupying the next state only depends on the current (and potentially previous m) states. One does not have to known the entire state sequence to be able to compute the probability distribution for the next state. Thus, each state transition can be stochastically described using a state transition matrix that maps the probability of occupying the new state based on the current (+ potentially previous few) states.  If the number of discrete states is very large, the state transition probability matrix may be very large, and its estimation from example training data (ie learning the state transition probability matrix) may benefit from some approximate model such as an artificial neural net. An artificial neural net is just a (potentially nonlinear) parametric function which maps a d-dimensional input space into a k-dimensional output. Just like a linear function has a set of parameters that characterize it, the neural network has a set of  weights which define the mapping. In particular the net is formed by repeatedly transforming the input space via a series of operations at each layer of the neural net. Often such transformations may include a linear projection followed by a nonlinear transformation (e.g., sigmoid, rectified linear units ReLU etc). There is no constraint on each layer of the Neural net, ie the layers are often projected onto different feature dimensionalities, may use different non-linear transformation functions etc. Differences between the two models: While a new student may think Markov chains and artificial neural nets both seem to display a series of sequential transformations, they are entirely unrelated, and quite different in nature. The layers of the Artificial neural net are not constrained to describe state occupancy probabilities -- you can think of each layer, and indeed the entire neural net as an arbitrary nonlinear function. For example, a Neural network can be used for linear or nonlinear regression, which has nothing to do with state transition probabilities. Relationship: Of course one is free to use soft-max non-linear transformations so that the output (or any hidden layer in the middle of the neural net) can be interpreted as the probabilities of occupying one of m different states. If we do this, we map the input (which itself may be the probability of occupying a set of states) and transform it to the probability of occupying various states at the next layer or time instant. If we stack several such layers together one may interpret the series of transformations at each layer as the probability of occupying states at the hidden layers -- one may easily add additional inputs at each stage as well, potentially augmenting the set of state occupancy probabilities derived in the previous stage. It is not uncommon to learn the state transition probability matrix for a Markov chain (eg Hidden Markov Models) at each time instant by estimating the weights of a multi-layer neural network. This approach has been popularized by several researchers over the last 20 + years -- see for example the work by Pierre Baldi who often uses deep neural nets to learn state transition or observation probability distributions for HMMs and other similar models. However the neural net in general does not have to only use such one-of-m softmax functions for the nonlinearity! Thus while one may use neural nets to help learn state transition probabilities, it has many other uses unrelated to Markov chains.    Embed Quote