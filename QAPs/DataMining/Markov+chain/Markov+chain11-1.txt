★What is the relationship between Markov chains and Poisson processes?
Poison processes - and the Poisson probability distribution - are a key component of continuous time Markova chains. A Markov Chain, in general, is a way to describe what could be thought of as the movement of an object from one position, or "state", to another.  Based on the object's current state, every other state it could move to next has a specific probability associated with it.  In this way, if you know the current state of the object, you can make inferences about how likely it is to move to any other possible state.  If these probabilities change depending on the passage of time, the Poisson distribution can be used to determine the different states' probabilities, and this is done by modeling an object's movement between states as a Poisson Process.  This all may seem opaque at first, but a bit of context and a few short examples will hopefully make it clearer. Let's start with Markov Chains overall.  The simples types of Markov Chains are called Discrete Markov Chains, and do not require keeping track of the amount of time an object remains in one state or another.  A brief and often-used example is the sum of multiple rolls of a 6-sided die - the "object" in this case is the sum, and the states are the values which the sum can take.  If your first roll gave you a 6, then the sum has a probability of 1/6 of moving from the "state" of 6 to a state of 7, 8, 9, 10, 11, or 12 - and a probability of zero of moving to any other state (since if you start with a sum of 6 and then roll the die again, your sum can't be lower than 7 or higher than 12).  Such a Markov Chain is one-directional, since the sum only increases.  However, multi-directional processes can be easily modeled with discrete chains as well.  To illustrate with another classic example, say you flipped a coin in a game, where you won $1 every time you landed on heads and lost $1 every time you landed on tails.  The sum of your winnings could be described by a Markov chain just as the sum of the die rolls - if your current "state" in the game is $7, then if the coin is fairly weighted you have a 1/2 chance of moving to a state of either $6 or $8.  (one note - this type of scenario is actually called a Random Walk.  It has been studied by statisticians and mathematicians for centuries, and has a number of interesting properties related to Markov Chains.  The wikipedia article about Random Walks provides a decent overview if you want to learn more). In the Markov Chains I described above, the probability of our "object" moving to a new state does not change depending on how long it remains in it's current state.  If we roll a die eight times and arrive at a sum of 30, the probability of getting to 31 does not change if we walk away for 5 minutes before making the next roll.  There are processes, however, for which the passage of time matters a great deal.  If you are a barista, for example, the number of customers waiting in line for a latte could change dramatically depending on how long it took you to fill each order.  If you were a mechanic, the number of cars in your repair shop would change depending on how long you took to repair each one.  If you worked at an office and stepped away from your computer, the number of unanswered emails in your inbox would be very different depending on how long it took you to return.  These are all examples of what are called Continuous Time Markov Chains, and they can each be modeled by representing the passage from one state to another as a Poisson Process. On it's own, a Poisson distribution describes the probability of an event occurring after a given amount of time, t.  It uses a single parameter, lambda, which expresses the average rate at which the event occurs.  A recurring event, or process, whose probability follows this distribution is called a Poisson Process with rate lambda.  To fully classify something as a Poisson Process, there are a few criteria that must be met, however the ones most pertinent to Markov Chains are shift invariance and independent inter-arrival times.  Shift invariance means that the probability of an event occurring within given amount of time, t, does not change depending on the point at which you start counting time; the probability of an event occurring over the span of an hour does not change whether that hour is from 1pm-2pm or from 8am-9am.  Independent inter-arrival times indicates that once an event in a Poisson Process has occurred once, the probability of it occurring a second time can be modeled using the same Poisson distribution, as if time started from t=0 after the first event - the Poisson Process starts from scratch after each occurrence. Now, how does this relate to Markov Chains?  Say the object you are modeling with your chain is the number of customers waiting in line for a slice of pizza.  There are a few rates that will impact this number.  There is the rate at which people show up at the pizza parlor, and the rate at which the person behind the counter fills each order, and the rate at which people get fed up while waiting and take their business elsewhere.  If each of those rates can be though of as expressing a Poisson Process, then the entire system can be modeled as a continuous time Markov Chain, so that the number of people waiting in line is dependent on the passage of time (i.e. how quickly people show up, orders are filled, and people leave the line).  Under this model, the number of people waiting in line (i.e. the state of your object) after a given amount of time, t, can be expressed as a function of the rates of the three Poisson Processes that impact that number. The model described above is actually one "flavor" of a set of models called Birth and Death processes.  There are many, many iterations of such models - some that use multiple serving stations, others that have sequential stations, and still others that have multiple drop-out points - and they can actually be adapted to encompass a good amount of complexity.  There are  also a number of formulas associated with such models that will give you the state of such systems at a given point in time, as well as the state that the system would be expected to stay in after infinite time.  I am not going to go into these here, but they can be found in a number of text books that deal with probability models in general, and Stochastic Processes in particular (a Markov Chain is one of a family of models associated with stochastic processes).  Introduction to Probability Models by Sheldon Ross is a great start in this subject. As a side note, there are number of ways that Continuous Time Markov Chains can be useful for real-life applications in business.  Keeping with the pizza example, you can use Poisson random number generators to simulate the movement of people in and out of the pizza parlor.  You can also take the limit to infinite of the entire system, and determine the average number of people that will always be waiting in line for pizza.  Each of these exercises would tell you different things about the operation of the business, and where efficiencies might be gained so that more pizza can be sold and/or fewer customers walk away disgruntled.  If your model told you that, on average, there are always five people in line at any given time, perhaps you could offer some free samples while they wait and try to lower the drop-off rate.  Maybe you discover that customers are actually showing up at a far more rapid pace that you can serve them, and there is an opportunity to add another pizza oven and expand the business.  Seasonality would likely have an impact, and maybe you would have to design different Markov models for summer vs. winter.  For the budding statistician-restauranteur, the possibilities go on and on. All that is to say that there is a very strong link between Markov Chains and Poisson Processes.  Their theory and application get quite deep, and make for very interesting reading...if you're into that sort of thing.    Embed Quote