★How do you find the meanings of hidden states in hidden markov models?When training a HMM, we only give the observed sequence and the number of hidden states. Then how do we know the meanings of hidden states? I found in certain applications such as speech recognition, researchers seem to be very well aware of what each states represents (what letter, or what syllabus, for example). How does this work? Thanks.
HMM is a generative model, so you are the one who decides the meaning of the hidden states. You enforce the structure - what are the meanings of observed/hidden variables and what are the emission/transition distributions (not only the number of hidden states). How well your assumptions are about the underneath process is a different matter - model selection.    Embed Quote