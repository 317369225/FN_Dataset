★Hidden Markov Models: Why is there no analytical method to solve for HMM parameters?
Good question!  Since Rabiner's seminal paper, we've actually come a long way in understanding hidden markov models.  And in fact in a certain sense, there is an analytical solution to fitting an HMM (based on spectral decompositions) that has garnered quite a bit of attention in the machine learning community over the last few years. I would recommend reading the following paper:  [0811.4413] A Spectral Algorithm for Learning Hidden Markov Models by D. Hsu, S. Kakade, T. Zhang The algorithm estimates marginal probabilities of observable quantities such as P(x0=i) (the probability that the observed symbol at timestep 0 is i), as well as higher order probabilities such as P(x0=i,x1=j) and P(x0=i,x1=j,x2=k). If you knew these marginal probabilities exactly, there is an exact svd based algorithm (given in the paper) for recovering the so-called "observable parameterization" of the HMM which would allow you to predict future observations. In the limit of infinite data which was actually drawn from an HMM, their svd based algorithm is provably the correct thing to do, and as such, is the closest thing we have to an analytical solution to HMM learning.    Embed Quote