★What are the ways of deciding probabilities in hidden Markov models?
There are many ways of estimating the probabilities of a hidden Markov model. But the most common is the Baum-Welch re-estimation algorithm (http://en.wikipedia.org/wiki/Bau...). There are two key things about this algorithm: It's a kind of generalized expectation-maximization algorithm: in other words, you start with an initial guess of the probabilities, you then run the data through and adjust the parameters, and then you run it again with the improved parameters being your new initial guess. This type of algorithm turns up all over the place (http://en.wikipedia.org/wiki/Exp...). It is built on the forward-backward algorithm (http://en.wikipedia.org/wiki/For...). The forward/backward algorithm works by taking a single observed sequence, and running it through an existing HMM. For each timestep in the sequence, and for each state you say "Right: if I was in this state at this time, how probable was it that I got here from the beginning (the forward probability) and what is the probability from here that I will get to the end (the backward probability). You then work out at each state how probable it was, and then smooth the probability of the transitions at each state. So basically, you apply forward-backward on each element of the training data, smoothing as you go, then repeat until the probabilities don't change much.    Embed Quote