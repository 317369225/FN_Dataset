★Can Hidden Markov Models be used as binary classifiers? If yes, how?
As @Tao Xu explains, Hidden markov models are used for sequence or structured predictions.  It is a sequence model. Say you want to identify nouns and verbs in a sentence. Then there are multiple labels in a sentence, we can of course use a simple classification model for each type of the label, but it would not take the context of the other label in to consideration. To explain sequence models with another useful scenario, assume you are doing click analytics for a website. You keep track of the sequence of clicks made by the user, you want to predict the next possible clicks. This is a sequence model. Also, Hidden Markov Models could be considered as the graphical extension of Naive Bayes model. The paper  "An Introduction to Conditional Random Fields for Relational Learning" explains this beautifully.  Here is a picture from the paper NaiveBayes and HMM model the joint distribution and are generative models, where as Logistic Regression and CRF model the conditional distribution and are discriminative models. Please read the section 1.2.3 Discriminative and Generative Models from the paper. All these models are related based on the probability distribution that they model and it helps a lot of get a feel of how these models work. This blog is also very helpful in understanding the big picture Introduction to Conditional Random Fields. In short, it helps to understand the relation between HMM, CRF, naivebayes and Logistic regression to learn the concepts behind them. So its better to treat them together rather than learning one at a time.    Embed Quote