★What is the relation between singular value decomposition and principal component analysis?
Principal component analysis is usually presented in terms of the eigendecomposition of the covariance matrix.  But the eigendecomposition of the covariance matrix is closely related to the singular value decomposition of the centered data matrix (where columns have zero mean.)  I will explain why these are basically the same thing. Let X be the original data matrix is rescaled so that the columns correspond to variables and the rows to observations, and so that the columns have mean 0.  Then the sample covariance matrix, is equal to . The eigendecomposition finds such that V is orthogonal, is diagonal and . The singular value decomposition finds U and V with orthogonal columns such that The V here is the same as the V found by the eigendecomposition, and D is related to in terms of the diagonal elements, .  You can see this by writing: Now, because U has orthogonal columns, . Hence the above reduces to hence we know that matches up with . The columns of V are the principal component directions.  The diagonal entries in D are the square root of the variances of the principal component directions.  If is the ith diagonal element, is the percent of variance explained by the th direction. However note that the SVD provides the matrix U, which is not provided by eigendecomposition.  What is U?  Each row of U provides the 'coordinates'  of each observation , which can be used to plot the data in terms of the first few principal directions.  For example, the 'x' and 'y' axes of the following plot are the first and second columns of U:    Embed Quote