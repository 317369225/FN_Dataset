★Principal Component Analysis: What is the intuitive meaning of a covariance matrix?If a matrix is a linear operator that transform space in a certain way, what transformation does a covariance matrix produce?
I personally would not try to think about what the covariance matrix can do to other vectors or matrices. I would try to think about what the covariance matrix is and why it is useful. In the simplest terms: 1.) Covariance is just unscaled correlation.  If a number at a certain position in the covariance matrix is large, then the variable that corresponds to that row and the variable that corresponds to that column change with one another. When one goes up, the other goes up. When one goes down, the other goes down. If a number at a certain position in the covariance matrix is close to zero, then the variable that corresponds to that row and the variable that corresponds to that column do not change with one another. When one goes up, the other doesn't change very much. 2.) We need a square matrix to invert to do more exciting things (with more immediate geometric interpretations), like Regression and Principal Components. The covariance matrix is a representative transformation of our data that will always be square and usually have other nice properties.    Embed Quote