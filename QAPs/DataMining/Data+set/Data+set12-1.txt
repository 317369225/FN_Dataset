★Why is it that, in many data sets, there are about six times more numbers starting with the digit 1 than with the digit 9?
"Benford's law" is the claim that some dataset's logarithm is uniformly distributed; that is, it is the claim that the amount of datapoints between the numbers A and B is the same as the amount of datapoints between kA and kB, for any scaling factor k (for example, if a list of positive numbers satisfies Benford's law, then there should be as many datapoints in the interval from 2 to 5 as there are in the interval from 6 to 15 [the latter being the former scaled up by a factor of 3]). One might expect this scale-invariance property to appear whenever looking at a compilation of similar data reported in many different units (the different units acting as different scaling factors). And, even for datasets reported entirely in the same units: one sometimes says Benford's law should only be expected for datasets which equally span many orders of magnitude; but if this is meant to be taken as "There is the same amount of data at each order of magnitude", then this is tautological; that's just another way of phrasing the scaling-invariance property which simply is Benford's law. So if one restricts attention to those datasets which seem likely to equally span many orders of magnitude in this sense, then one is restricting attention to those datasets which seem likely to satisfy Benford's law (and ought not, therefore, be that surprised if/when they do). ---- Addendum: It occurs to me that there is an important subtlety not previously accounted for by my above original "It's just scale-invariance!" answer: I stated above that Benford's Law is the claim that some data's logarithm is uniformly distributed. But actually, this isn't exactly right; Benford's Law is actually the claim that some data's logarithm modulo log(10) is uniformly distributed. What's so important about this relaxation? Well, even data which is normally distributed (and thus not at all uniformly distributed) becomes very nearly uniformly distributed when you take its residue modulo a value which is not very high in comparison to its standard deviation. (In other words, the fractional component of normally distributed data is approximately uniformly distributed so long as the variance isn't too low*). And, of course, by the usual reasoning of the Central Limit Theorem, we might expect a normal distribution to arise whenever adding together many independent random variables. Putting this all together, then, we should expect Benford's law to very nearly hold whenever looking at a product of many independent random variables of sizable variance, simply because we expect such data to be nearly log-normally distributed with a sizable standard deviation (by the Central Limit Theorem), which means its logarithm modulo log(10) will be nearly uniformly distributed, which is precisely the claim of Benford's law. This, I think, is the phenomenon accounting for the ubiquity of Benford-esque distributions in many real-world datasets. [*: An excellent account of this fact via Fourier theory (and its applicability to explaining Benford's Law) can be found in Chapter 34 of The Scientist and Engineer's Guide to Digital Signal Processing, available here: http://www.dmae.upm.es/Webperson.... In short, a random variable's residue modulo some period is described by a periodic probability density function, whose Fourier series is given by the values of the random variable's characteristic function at the multiples of the period. Thus, it will be uniformly distributed just in case the original variable's characteristic function is zero at the nonzero multiples of the period. In particular, if a random variable is normally distributed, then its characteristic function is Gaussian centered at 0, with dispersion parameter inversely proportional to the standard deviation (remember, we're looking at the characteristic function, not the density function). Thus, so long as the standard deviation is reasonably large relative to the sampling period, the characteristic function decays so quickly that its values at the nonzero multiples of the sampling period will be nearly zero, and so the random variable's residue modulo the sampling period will be nearly uniformly distributed.]    Embed Quote Updated 30 Jul, 2011. 1,800 views.