What is a training data set & test data set in machine learning? What are the rules for selecting them?
Here is my penny. Basically you have three data sets: training, validation and testing. You train the classifier using 'training set', tune the parameters using 'validation set' and then test the performance of your classifier on unseen 'test set'. There is no 'one' way of choosing the size of training/testing set and people apply heuristics such as 10% testing and 90% training. However, doing so can bias the classification results and the results may not be generalizable. A well accepted method is N-Fold cross validation, in which you randomize the dataset and create N (almost) equal size partitions. Then choose Nth partition for testing and N-1 partitions for training the classifier. Within the training set you can further employ another K-fold cross validation to create a validation set and find the best parameters. And repeat this process N times to get an average of the metric. Since we want to get rid of classifier 'bias' we repeat this above process M times (by randomizing data and splitting into N fold) and take average of the metric.  Cross-validation is almost unbiased, but it can also be misused if training and validation set comes from different populations and knowledge from training set is used in the test set.    Embed Quote 