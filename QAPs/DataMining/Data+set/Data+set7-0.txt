What is the best way to implement an autocomplete search feature when dealing with large data sets?
The best way to add an autocomplete over a large dataset is with ElasticSearch, Hadoop, Pig and Wonderdog. ElasticSearch is built on top of distributed Lucene.  It provides a simple JSON/RESTful interface that makes it very easy to use. http://www.elasticsearch.org/gui...  A simple introduction is available here: http://www.elasticsearchtutorial... A simple query against elasticsearch might look like this: curl 'http://localhost:9200/blog/post/_search?q=user:dilbert&pretty=true' ElasticSearch has Hadoop and Pig integration via Wonderdog, by Infochimps. Wonderdog makes it a one-line command to index your records on HDFS or S3 in your ElasticSearch cluster via Pig.  Check it out at https://github.com/infochimps/wo... There are any number of ways to use ElasticSearch for autocomplete, and all of them are simple.  One is here: http://support.elasticsearchhq.c... You can test an ElasticSearch cluster on many different cloud providers using WHIRR with a one-line command: https://issues.apache.org/jira/b...  Additionally, Heroku is adding support for ElasticSearch through Bonsai.io: https://devcenter.heroku.com/art... Using this stack, you can have an autocomplete working against large datasets in no time.  Simplicity is the essential character of scalability, and elasticsearch has it.    Embed Quote 