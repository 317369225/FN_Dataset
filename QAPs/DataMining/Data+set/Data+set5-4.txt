How do data analysts at companies like Facebook and Twitter run queries on extremely large data sets?
Facebook developed a number of technologies for working with large data which they gradually improved to be more analyst-friendly. Starting with Apache Hadoop as their big data processing system, they developed Hive as system for processing SQL-like queries, which are internally compiled into complex Map/Reduce jobs run in Hadoop. Facebook also developed Cassandra, which is a key/value store inspired by Google's BigTable project, but this system is more developer-centric. Facebook has also developed technology to help integrate their systems with visualization tools like Microstrategy and Tableau. As an aside, Facebook released Hive and Cassandra as open-source projects run by the Apache Software Foundation.    Embed Quote 