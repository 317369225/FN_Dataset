How can I crunch big data sets with my laptop?
If you really want to work with it on your laptop, exploit your laptops multiple cores (assuming it has them).  In Python this is very easy using iPython's cluster ability or R's multicore libraries.  You could install hadoop on your laptop as well.  If you really want to be smart about it, you would just use hadoop on your laptop to prototype and then once you got it down you will throw Amazon EC2 or even Elastic MapReduce (EMR) at it, will likely cost you very little and will run ALOT faster.  I can understand if your trying to do it all on your laptop though, I do that too sometimes, and as mentioned 1GB isn't a huge amount of data. As mentioned by Dima Korolev, you could convert it into a compressed matrix representation, this would allow you to work on the data more easily. You mention Java.  If you want to work in Java, you can use a thread pool, perhaps a basic producer/consumer design pattern, and make use of multiple cores that way.    Embed Quote 