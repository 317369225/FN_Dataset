★Linear Algebra: Why is the dimension of a vector space well-defined?The dimension of a vector space is the number of vectors in any basis. But I can write down many different bases for a given vector space. How do I know that all such bases must have the same number of elements? (This question is part of my Technical Notes Project.)
Standard textbooks treat this result really terribly, in my opinion.  It is common to prove a horribly technical result called the "exchange lemma," and then deduce the result from this.  To be fair, some work does need to be done.  However, most linear algebra courses have already discussed Gaussian elimination in great detail by the time they get to vector spaces, and this algorithm easily provides the needed technical step. There's really just one minor thing that you need to prove; the rest is just a notational hack.  If you want to remember how to prove dimension is well-defined, remember that all you need to do is prove the next easy lemma.  The rest is really quite trivial. Key Lemma. If are vectors in and , then they are linearly dependent. Proof: Write the as column vectors and put them in a matrix, . The vectors are linearly dependent if and only if there is a nonzero solution to the matrix equation , where the 0 vector on the right is in .  But this is a homogeneous linear system of equations in unknowns, so it has a nonzero solution, say by Gaussian elimination.  QED. To complete the proof that dimension is well-defined, suppose is a vector space and that and are two bases.  Without loss of generality, assume Since the 's are a basis, we can write the 's in terms of the 's: . Then the coefficients of these expansions are vectors in .  By the lemma, the coefficient vectors are linearly dependent.  But then the 's satisfy the same linear relation as their coefficient vectors, contradicting the fact that they are a basis.    Embed Quote