★When would one use hierarchical clustering vs. Centroid-based clustering(K-MEANS) vs. Density-based clustering?
Each has qualitatively different behaviors, and will do better or worse depending on the structure of the underlying data. k-means works well when the clusters are linearly separable (by hyperplanes). Clusters are 'compact' in the sense that two points in the cluster tend to be close. You typically have to run k-means several times to avoid local minima, and have to know k ahead of time. But it is effective on a range of problems. Hierarchical clustering can be slow. It can result in clusters that are more spread out, filament-like. You don't have to choose a number of clusters ahead of time, and instead can pick a cutoff dynamically to stop on. As a bonus you get extra structure -- a hierarchy of clusters.You can later break down / combine clusters to the level you want. I think of density-based as qualitatively somewhat in between. It wants "separable" clusters like k-means, but can discover the same spread-out, less compact clusters that hierarchical could.    Embed Quote