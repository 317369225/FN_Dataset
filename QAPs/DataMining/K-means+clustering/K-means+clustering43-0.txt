★What are the proper settings for document clustering with K-means?
The biggest problem in applying clustering on text data is the curse of dimensionality. In high dimensional data like text, every point becomes close to every other point in vector space, So distance measure like euclidean (L2) might not work as expected on real data. That said, some directions on setup: Features: Binary features only amplify dimensionality curse. It is like all documents that are just "one word apart" are neighbours, irrelevant of the feature's worth! So tf-idf is better as it statistically weighs important (less frequent) words. Also make sure that you remove very common words and highly infrequent noise words. Dimensionality reduction: It helps to some extent. You can try latent semantic analysis or probabilistic topic models like LDA. In fact there is a strong connection between PCA and K-means : principal components are continuous solution to cluster membership (Paper). Distance: K-means is assumed to work with euclidean distance and cosine similarity + k-means is not straightforward. You could look at these papers for the spherical K-means variant (Paper1, Paper2) Convergence: It depends on the data and you can look at the ratio of Mean square error to the difference at successive iterations to decide on an optimal threshold. This can be done experimentally and would not be tough.    Embed Quote