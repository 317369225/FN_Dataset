★What is the difference between Naive Bayes and K-Means clustering?
I personally had the same question and this is my attempt to answer it. Let's consider the more general gaussian mixture models, (k - means is a special case of these). For simplicity, it's assumed here that in each class/mixture, the covariance matrix is diagonal. Implying indirectly that the features are independent within a mixture. That is exactly what naive bayes is built on - the conditional independence. So, GMMs with diagonal covariance matrices are unsupervised analogs of naive bayes models. Correct me if I'm wrong.    Embed Quote