★What are the most exciting areas of current research/applications in semi-supervised learning?
One exciting area is that of transductive support vector machines (TSVMs). The intuition behind that algorithm is that one could obtain a better decision boundary by maximizing the margin to unlabeled data as well as labeled data, with the assumption that a dense clusters of datapoints are likely of the same class. Formally, the SVM objective function (linear, binary, with no slack variables for clarity) is extended to where and with the regularization term missing because of length limits on equations. This penalizes unlabeled datapoints falling within the margin, with some appropriate weight . Note that term 1, corresponding to the normal SVM objective term, is convex whereas term 2, the TSVM part, is concave. This property makes the function difficult to optimize directly. There are two main approaches for minimizing . [1] describes the application of convex-concave programming to the problem, where they optimize the objective function directly. It is a fairly complicated algorithm, so an alternative is given in [2]: use the approximation which is differentiable. The authors appear to have had some success with it. [1] Ronan Collobert, Fabian Sinz, Jason Weston, Lon Bottou, and Thorsten Joachims. Large scale transductive svms. JMLR, page 2006. [2] Olivier Chapelle and Alexander Zien. Semi-supervised classification by low density separation. In Proc. of Int. Workshop on AI and Statistics, 2005.    Embed Quote