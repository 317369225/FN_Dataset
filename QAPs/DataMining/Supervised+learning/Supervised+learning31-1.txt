★What are the best statistical methods for analyzing the performance of a supervised learning algorithm with binary outputs (labels)?Obviously you can produce a confusion matrix and look at the number of true-positives and false-negatives, but what other methods are informative?
If you are interested in the probability calibration - that is how accurately your algorithm can estimate the probability of each label - then you should consider a Homer-Lemeshow test (Hosmer–Lemeshow test). Another related approach is plotting the estimated probability against the empirical probability (in order to do this you would need to bin your observations). If your model is doing a good job then you should see a points along the y=x line (indicating that the predicted values are close to the observed probabilities)    Embed Quote