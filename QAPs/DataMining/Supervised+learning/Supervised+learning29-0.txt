★How do corporations like Apple or Google create annotated datasets for supervised learning algorithms to use with their sensors?For example, to interpret user intentions with capacitive touch screen signals from gestures. What approach would a company like Google or Microsoft use to create a tagged/annotated training dataset? Would they just hire temp workers that record their gestures while touching the screen? Or would they source it out to a mechanical turk service for the scale such services can afford?
Collect of a large amount of realistic, if possible supervised, data is usually a crucial step to building a robust pattern recognition system. Depending on the stage of development of a concept (from research prototype to released product), the amount of required data is likely not the same, so companies/labs will collect data with different methods. Of course the machine learning intended to be used can require by nature more or less training data so it should also be taken into consideration.   - Small scale data collection. The easiest way to collect data is to build an collecting application and ask people around to provide data by using the interface. This is often done as a first collect stage because it is very cheap, fast and flexible. However, this kind of informal data collect is likely biased (for example with only male IT engineers participants), and one should not draw definitive conclusions from such experiments.   - Use of publicly available datasets. For a growing number of pattern recognition problems, there exist available datasets that were (more or less) carefully collected for research purposes, usually by academics. These collect conditions of the datasets is normally documented in a relevant publication. Advantages is that the amount of data can be substantially larger, and less biased. In most cases, the dataset has been used by other researchers to build and compare pattern recognition methods, so you can compare you in-house method to alternative solutions. This kind of datasets are mostly provided for free for research purposes. Some possible drawbacks are the lack of flexibility, and the usual shift from your precise problem/platform (for example a touch dataset has been collected on a specific device which has different resampling properties, resolution...). The exact acqusition conditions can sometimes be obscure, so one should not blindly trust the results of a method on a single dataset, and it is recommended to consider various datasets for building a robust system. A a matter of fact, I have recently built a list of publicly available datasets related to problems of touch/pen gestures and symbols on smartphone and tablets Pen and Touch Datasets - Adrien Delaye.   - Crowdsourcing. It is now relatively easy for a research lab or a company to leverage crwodsourcing platform to get a large number of data provided or annotated by humans. It is relatively cheap and flexible, but is not always possible (if special hardware is required, for example) and the control of acquisition conditions is somehow loosened, as well as the knowledge of the participants background (hence possible bias). I believe that companies would not hire temporary workers for such tasks. If data is to be collected in the lab, they would run campaigns to attract public interested in participating in a collect experiments, providing coupons or small amount of money as incentive, just like most labs collect data from students.   - Outsourcing. Some companies offer services such as collecting massive amounts of annotated data that you can buy exclusively. For examples, you can buy handwritten Chinese character datasets collected from thousands of people in China, that have been paid by the company to provide samples. This method is more costly and less flexible with respect to others. It requires a very careful design of the collect campaign and control of acquisition conditions. As far as I know, companies that build handwriting recognition engines use this kind of service, because they need a large amount of data to account for many languages, user styles variations and large alphabets or vocabularies.   Finally, the companies you cite can access to data directly collected from their users, if legally possible and according to user privacy policy. Such data is very useful because it reflects the exact conditions of acquisition that you are interested in, and may provide a lot of insight into the future product's users.    Embed Quote