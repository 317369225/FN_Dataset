★In regression analysis, does it make sense to continue adding independent variables to predict a dependent variable so long as your adjusted R^2 improves and your standard error falls?Say you don't have a large enough sample to run meaningful cross-validation techniques.  Is your best bet for prediction to feed enough independent variables to maximize R^2 and minimize standard error?  Why or why not?
No, continually adding independent variables to a regression to overfit the model is bad habit and form, for instance, adding in the breeding patterns of gazelles into a regression on car sales in the United States would be ridiculous; however, it may result in a better fitting model. A better idea would be to add relevant variables to the regression, such as time variables, or descriptive variables depending on your regression. Adding house color into a regression on home prices might prove worthwhile, but regressing the number of electrical sockets in the house may prove pointless. Look at other measures such as the SIC and AIC, as well as other measures such as the Durbin-Watson and the the p-values associated with each of your variables and making sure they are less than .05 assuming that the software your using runs statistical tests on a 5% test size    Embed Quote