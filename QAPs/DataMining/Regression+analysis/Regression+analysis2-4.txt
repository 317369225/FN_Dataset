★How would linear regression be described and explained in layman's terms?
A  Simple Linear Regression allows you to determine functional dependency  between two sets of numbers. For example, we can use regression to  determine the relation between ice cream sales and average temperature. Since  we are talking about functional dependency between two sets of  variables, we need an independent variable and one dependent variable. In the example above, if change in temperature leads to change in ice  cream sales then, temperature is independent variable and sales is  dependent variable. Dependent variables is also called as criterion, response variable or label. It is denoted by Y. The independent variable is also referred as covariates, predictor or features. It is denoted by X. How it works? Most of the modeling techniques, including regression make certain assumptions about the data they deal with. The principal assumption in linear regression is "Linearity and additivity". Let's focus on the linearity part as of now. It means the dependent variable is a linear function of independent variable.[Explore more] Now if we consider a 2 dimensional space, then each pair of observation (Xi,Yi) is a point. Based on linearity assumption discussed above, this model fitting given data(points) should be a straight line. So  in simple linear regression we have a bunch of points and we are trying  to find a straight line with 'best fit' to accommodate them. The equation of a straight line is, Y = c + mX So the regression (line) equation can be written as, Y = β0 + β1 X β0 is the intercept and β1 is the slope. Both are called model coefficients or model parameters. β1 represents the amount by which Y should change if we change X by one unit. So basically building simple linear regression model is, solving this equation for values of model coefficients. Now  looking at the scatter plot above, it is impossible to fit a straight  line through all data points. So we modify the equation slightly. Y = β0 + β1 X + e  Where "e" is the error while calculating Y. Now  let's get back to how do we decide the best fit. A regression line,  which helps us to minimize the error component discussed in equation  above, will be considered best fit. Consider following image, to understand the error components. The distance between predicted point (on true regression line) and observed point is an error. It is also called disturbance. There  is a similar concept called residual. Important thing to note here is,  the term residual is NOT same as error. The distance between predicted  point (on estimated regression line) and observed point is an residual. [Explore more] It  bothered me for a while why the error is not a shortest distance  between point and regression line. (Why it is parallel to Y axis and not  perpendicular to regression line like following) ... (more)Loading...