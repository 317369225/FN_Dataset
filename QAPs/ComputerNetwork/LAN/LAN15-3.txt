★What is consider decent latency / RTT for WAN / LAN?For instance, is 8ms across 40 miles horrible? =)
This question is almost 2 years old so I'm not sure if anyone is still interested in an answer but it is a topic that I needed to research for myself recently so here goes. There is no single answer to this question. Depending on what the WAN/LAN link is being used for, different RTT's will be perceived as acceptable or not by the users. The key word here is "Perceived". The research papers I drew my conclusions from were based on interviews with end users of the different types of network services that rated their experience of the quality of the link and then correlated those with the actual measured performance of the networks - of which RTT was only one of seven key metrics that were found to have an effect on users' perceptions. Also note that in this context the Round Trip Time (or RTT) is not as useful a metric as the Oneway Trip Time from producer to consumer since many services are initiated with a few very short requests for data that require a number of long responses (e.g. "tuning in" to a podcast) so that it doesn't really make much difference if the UP trip takes much longer than the DOWN trip (if that makes any sense?). Unfortunately OTT is much more difficult to measure than RTT which can be done with simple Ping utilities. The OTT is more commonly called the Delay time of a WAN link. For each of the common network services that are consumed by modern internet users the "acceptable" delay times are summarized below. As mentioned above, the research I did showed that, apart from Delay, there are six other key metrics that affect the users' perceptions of the quality of the WAN/LAN link, sometimes even more than Delay. These metrics are summarised below:- Response Time Expected by Users: The end users' expectations of the time that will elapse between sending a request and the reception of the first response by the user. Delay (or One Way Trip Time): The time between the emission of the first bit of a data block by the transmitting end-system and its reception by the receiving end-system. Jitter: Variations in delay generated by the transmission equipment. Thus, if the Delay is fixed at 150ms and never changes the Jitter will be 0%. Data Rate: Data rate refers to the raw data rate of encoded multimedia data before transmission, that is, the rate in which data are encoded. Required Bandwidth: The required bandwidth is defined by the required data transfer rate, measured in bits per second, of each specific application in telecommunication. This metric includes raw data and overhead. Loss Rate:The bit loss rate is the number of bits lost between two points in telecommunications after transmission. Error Rate:The bit error rate is the frequency of erroneous bits between two points in telecommunication after transmission. I have more information about the various services requirements of the these other metrics if anyone is interested in them.    Embed Quote