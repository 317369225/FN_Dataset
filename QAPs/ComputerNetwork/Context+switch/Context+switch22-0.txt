â˜…Why is it in some operating systems, while physical memory is still abundantly available (at least from observing the system monitor), in some cases, there can be lots of page fault caused system traps resulting in context switch related perf degradation?
Did some research, going to answer my own question here: According to Wikipedia, this occurs most likely in cases where OS delays loading dynamically linked libraries and caused hard page faults: "This is the mechanism used by an operating system to increase the amount of program memory available on demand. The operating system delays loading parts of the program from disk until the program attempts to use it and the page fault is generated. If the page is not loaded in memory at the time of the fault, then it is called a major or hard page fault. The page fault handler in the OS needs to find a free location: either a page in memory, or another non-free page in memory. This latter might be used by another process, in which case the OS needs to write out the data in that page (if it has not been written out since it was last modified) and mark that page as not being loaded in memory in its process page table. Once the space has been made available, the OS can read the data for the new page into memory, add an entry to its location in the memory management unit, and indicate that the page is loaded. Thus major faults are more expensive than minor faults and add disk latency to the interrupted program's execution."