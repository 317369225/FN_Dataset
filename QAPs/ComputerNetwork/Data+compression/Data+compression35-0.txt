â˜…In MapReduce, does the reduce function work like data compression?Is it correct? And when mapreduce distribute data to different nodes how does map reduce work in a parallel way.
1) The Reduce function in MapReduce does not necessarily compress data, it depends on the requirements of the problem on which the mapreduce technique is being applied. Eg: The well known word count example has output as files that contain the number of times each word occurred in the input. This is not compression, it may contain just one word if your input is filled with that word or it might contain huge list of words. But if you were trying to find the sum of millions of numbers then the reduce function (if run on a single machine) will give you just one number as the output. 2) Map & Reduce do not work in a parallel fashion. Ideally, until the map function is done processing the input, the reduce function cannot start. The input is split and distributed to different machines and each machine starts its own map task. These different machine are the ones that are working parallel. Same is the case for reduce. The technique of MapReduce is to distribute data to different data nodes, as you correctly understand that the input data is now present on different nodes/machines, so each machine can run its own mapper function, thus it means that data is processed on these various data nodes together at the same time. Once the map function is done, in a similar fashion the data is again aggregated/shuffled and sorted and given to different worker machines. These worker machines (or data nodes) start their own reducer functions and thus they are able to work together. So what a single machine would do as a single node cluster now multiple machines are doing by splitting the input.