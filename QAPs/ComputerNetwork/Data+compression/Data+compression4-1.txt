â˜…Is data compression a dual of learning? If not, why?Just like the reverse version of MDL
Here is a fun stuff. You can use data compression for classification, at least for data sets with discrete valued attributes. The criteria for binary classification is, if compressed_size(positive_training_points + test_example) - compressed_size(positive_training_points) < compressed_size(negative_training_points + test_example) - compressed_size(negative_training_points) then classify the test_example as positive else negative. Surprisingly, it works quite well, but it is quite sensitive to the order in which the data is presented to it, for example sorting of the data points improves performance. The reasons for this are pretty much the same as what Anon User has pointed out.