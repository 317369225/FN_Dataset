★Data Compression: Does bzip2 work as well on gzipped files as it does on uncompressed files?Is there any difference in net compression depending on whether you apply better compression algorithms in sequence or start with the raw data and go straight to the best compression algorithm?
No. In fact, there's an entire field of mathematics devoted to data transmission and compression called "Information Theory" that not only is the foundation of data compression schemes, but also easily describes their limits. Information theory describes data in terms of how complex the information is. If it's very simple, you can describe it simply. For example, a file that's a billion 0's can be described as "a file with a billion 0's in it" which is a very small representation from which you can recreate the giant file, if need be. However, if the file contained billions of truly random bits, then there's no short-form way of describing the information. The randomness of information, called "entropy", can be measured, and the unit of measurement is "bits" - the minimum number of bots of information required to reproduce the original message. If the message repeats large chunks of data, you can represent it with fewer bits. In the phrase "I cannot can candied canapés", you'll notice that the letters 'can' are repeated. We could write it as "I 4not 4 4died 4apés" and make the phrase 8 letters shorter, but still have enough information to recreate the original phrase (assuming that we make a note that '4 = can' and replace it accordingly).  That's data compression. The thing is, the data compression works by replacing longer series of repeating bits with shorter series of non-repeating bits. If you think about it a bit, you might realize that the shorter series of bits have a higher density of information in them, and the series of those bits is more random. Since the more information-dense pattern is more random, it is also less possible to compress. There is a hard limit on how few bits can be used to represent any message. Differences in compression algorithms are mostly in how big a buffer is used to analyze a file and how big a dictionary it uses (remember, we do need to jot down that '4 = can'). Most compression algorithms today get respectably close to the theoretical limit. bzip2 compresses a little better than gzip because of differences on how they handle their dictionaries and the size of file chunks that they consider at one time, but that's about it. The data, post-compression, is close enough to the theoretical maximum, that no other compression algorithm can make the file smaller (and, in fact, they tend to make the file bigger because they've got to add some data at the beginning to identify the file type and the dictionary). So, in practice, not only will bzip2 not be able to effectively compress a gzip file, but just about any other compression algorithm will be unable to do so either (and gzip can't generally make them smaller either). Note that these rule apply to "lossless" compression - where you get out the exact same data that you put in. There's also lossy data compression where you throw away data knowing that you can get a "close enough" representation of it later. JPEG pictures work this way - some of the picture information is thrown away because small changes in the picture are unlikely to be noticed, and sometimes you guess the color of a pixel with decent accuracy if you have and idea of the color and pattern of pixels in the proximity. If you ever use software that has a "quality" setting for JPEG pictures, that setting is really adjusting how much information you're willing to throw away when storing the picture. The more you throw away, the less disk space is required to save it, but the quality of the image also declines.