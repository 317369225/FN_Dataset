★What are the current applications of machine learning in data compression?
I'm not an expert on this subject but in my limited experience I've encountered some  papers out there on image compression algorithms which utilize machine learning concepts to encode/decode compressed images. A google search will likely reveal a few examples. In addition I believe some forms of video compression utilize previously encoded data to predict the next frame that will be decoded. Not sure if this is considered more information theory based rather than machine learning based. In addition trellis quantization, a method of making image adaptive quantization tables appears to use something similar to viterbi to identify the optimal quantization table that minimizes the rate-distortion metric for a trellis of states corresponding to different distortion rates for various quantization step values across the MCU blocks of an image to be encoded. Apologies if I misinterpreted the question or am misinforming about the topics mentioned, this was based on my own interpretation of the papers related to the above topics.