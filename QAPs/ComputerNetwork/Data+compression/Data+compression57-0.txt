★What happens inside when a folder/data is compressed?I hope you got my question. Specifically speaking, how all it happens?
Let me start by asking you to write down the largest number you can think of—all its digits! Let's say you think of a googol (http://en.m.wikipedia.org/wiki/G...). You get a piece of paper, and maybe a minute later you're done writing it all down. Next, let me ask you to simply describe it. Well, if you just read the Wikipedia article then you'd probably go, "one followed by a hundred zeroes" or even "10^100". The 100 digit number is your raw or uncompressed data. Notice how it's highly repetitive (lots of zeroes). Most real world data is like that (though not as extreme)—they can be rather redundant. We say they have "low entropy" or a low amount of randomness. When something is highly redundant or repetitive, it becomes a good candidate for compression. Like in our example, we were basically able to denote or describe the same number simply by using a different representation (words or scientific notation). Take another example: turn to any random page in a phone book (does anybody still have those lying around?) and look at the list of names. Sometimes, a whole column of them will all have the same last name ("Smith") followed by different first names. If you had to say all of them over the phone to someone writing them down on the other end, it might take both of you a while. Or, you could start taking shortcuts, like, "The next 100 names will all have the last name Smith" and just start saying their first names. The person on the other end can still write down their complete names but you've saved both of yourselves some time. That's not very far from how most text or data is compressed, by the way. A typical compression algorithm can recognize or pick out character or bit sequences that occur frequently, and replace them with a shorter bit sequence in the compressed output. When decompressing, the reverse just happens: the token that represents a particular sequence of bits of characters is translated back into the original sequence. The 'translation table' (if you will) can be precomputed beforehand (by examining the whole data stream) and sent before the compressed representation, or, it can be built along as the data stream is read (and similarly rebuilt on the receiving end). When compressing images or audio, something similar happens though those types of compression are tuned around how we see images or hear sounds. In some cases, it's acceptable for compression algorithms for audio, images or video to "miss out" or discard some information since we know that, on average, people seeing or hearing the result probably wouldn't notice the difference. We call those "lossy compression" schemes (compared with data compression schemes which are almost always "lossless"). For example, a 30 second recording of a pure sine wave at 440Hz can be described in a highly lossy manner as just that "440Hz for 30 seconds". Or, a picture taken by a camera with its lens covered can be "compressed" from an 8 megapixel image into a few characters: "3266 by 2450 of RGB 0,0,0".