★Why is it easier to detect radio wave than measuring the shorter wavelengths?
Saying something is "easier" is somewhat subjective. However, it is true that creation and detection of radio waves ~(1kHz - 1GHz) is in some ways easier than in other frequency regions. In the most basic form, to detect (create) a radio wave, all you need is a length of a conducting wire (an "antenna") connected to an amplifying circuit. Designing a simple detector is a common high school science project. The difficulties come about when you try creating high intensity signals (as compared to, say, optical), or detecting low intensity ones - mainly due to the low energy/high wavelength of each photon. To do this effectively you need a physically large setup such as the Arecibo telescope, which has famously been used to transmit a high intensity signal. When you go to higher frequencies/lower wavelengths, viz. infrared (1mm-1um), visible (1um-100nm), UV and X-ray (10eV and above) creation and detection methods involve band absorption of photons in semiconductors (such as in your phone camera) and eventually currents generated by the photoelectric effect. Notice how I used different units for different ranges - this is typical, it emphasizes the nature of light that you're dealing with. If you're careful, you will also notice that I have missed a patch between 1GHz (~10cm) to 100GHz (~1mm), which is the infamous "Terahertz gap". This is the intermediate range where radio technologies (amplifier circuits etc.) no longer work because of the high speeds, and yet optical technologies (photodetectors etc.) don't work because of the low energies. For a long time, physics in this range was not well studied, however, in recent years there has been some progress made by using a combination of techniques for terahertz spectroscopy. See: Terahertz spectroscopy and technology Hope that answers your question. Thanks for A2A.    Embed Quote