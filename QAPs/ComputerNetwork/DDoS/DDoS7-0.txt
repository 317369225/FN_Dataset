★What is the state-of-the-art in DDoS protection?I am looking for a technical review. How does Amazon, for instance, protect against DDoS, having been a victim multiple times in the past?
So first - a DOS attack isn't necessarily what you're hinting at it being. Specifically, a DOS attack results in a denial of service to legitimate users of a service. This is usually the result of using more resources than are readily available, be they CPU, memory, disk, simultaneous connections, or network bandwidth. You're probably most familiar with the last one, which requires the attacker have access to large amounts of bandwidth; If a malicious user can leverage a resource management weakness and bring a service down for cheaper (eg, slowloris attacks against Iranian gvnt), he's not going to turn down the opportunity... So, let's consider it as two types: DOS vulnerabilities resulting from application misconfiguration or bugs, and DOS vulnerabilities resulting from pure brute force. Application misconfiguration or bugs - this should at least sound easy to fix. Run your applications through a profiler like HP Software Security (http://www8.hp.com/us/en/softwar...) which will spot most instances of resource mismanagement (think: memory management, IO handle management potential null-pointer dereferences and the like).  Application/appserver configuration issues can be addressed by tuning the application stack, or in the case of something like Apache httpd, putting a reverse cache like Varnish in front of it. The brute force attacks are harder to handle. On a small scale, something like mod_evasive (http://www.zdziarski.com/blog/?p...) or Ddos Deflate (http://deflate.medialayer.com/) will help. As the scale grows the appliances as others have mentioned sorta help, but IMHO they're unimpressive. What most of the devices do is block a DOS from passing the device - so that means the DOS is only pushed back to as far out as you can place the appliance. Unless you've got a nationwide network with appliances throughout, or are automatically sharing information with one, you've basically pushed the picketers to the curb in front of your house. Hosting companies usually have some sort of setup like this, and the devices have gotten better, but I don't consider this best practice yet. Until recently, what was state of the art (to my knowledge) is several non-public communities with members from various large ISPs and hosting companies. When large attacks were in progress, various network operators get on the phone together, track down the major sources, and drop their traffic. There's been talk of automating this process, but network administrators are really really cagey about letting a program automatically block traffic. Before I mention what I consider current state of the art, here's what a lot of companies do: make as much of the content static, then push it out to a content distribution network (CDN) like Akamai. Then anything that's dynamic, put it on an efficient setup that can handle loads - if possible have it in multiple, globally load-balanced datacenters. Akamai can actually do dynamic content now as well, but I don't believe it's as simple as giving them you're code and being done with it. Really what they're doing is spreading out the attack surface so an attacker has to have more and more resources to effecively take down the target. As you can see so far, we're following the standard "security hockey stick" - the more secure you want to be, the more it's going to cost you. So - current state of the art has a very low cost of entry - Cloudflare.  Lulzsec themselves use CloudFlare - that's a pretty good vote of confidence. In a nutshell, you let them take over serving DNS for your domain, then you specify which dns records you want them to protect. Traffic to those records is then run through their own CDN and anti-DDOS devices. Best yet, their basic service is free.  I'm actually starting to recommend them to my customers. Obviously there's other ways as well, but this should get you thinking in the right direction.