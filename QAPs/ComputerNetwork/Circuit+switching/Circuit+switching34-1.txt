â˜…Why did Asynchronous Transfer Mode (ATM) lose to IP?
Just to complement excellent's Tony Li's answer, a few points: Tony's is totally right about the cost factor. In this sense, one of the things that killed ATM was the need for very expensive gear to break packets into cells, and vice versa. If ATM was implemented end to end, as some folks advocated, the network would have to carry cells, and (at least in theory) the cost of the switches would be kept low. However, ATM as implemented in the 1990's had to deal with the fact that the hosts used other protocols. Even before IP took of as the standard, other protocols like IPX and mainframe protocols used larger packets. These packets had to be broken in cells and reassembled later. Pure ATM switches could potentially use less memory than routers at the time. Fixed cell sizes could make it way easier to implement things in hardware. However, the need to carry IP packets required ATM switches to have both the cell buffers, and also buffers for IP packets, which used more memory and had to support variable size allocations. So in the end, ATM switches had to implement both the fixed buffering for cells, and the flexible buffering for packets - if only, to implement the segment assembly-reassembly process, which was necessary for interoperability. Another problem with ATM was the licensing cost. Ethernet had very friendly licensing terms compared to ATM, which was still a moving target in the late 1990's when the technology was quickly surpassed by developments in optical transport (SDH/SONET, OTN and DWDM) and MPLS (which added more intelligence than ATM ever had and worked better with IP and Ethernet).