★How do computer networks handle data overload?
Computer networks deal with excess data by simply discarding the excess data. This is one of the cool and non-intuitive things about the Internet and TCP/IP.  If you have too much congestion, you just throw data away. This discarding of a packet acts as a congestion signal to the end hosts.  When end hosts detect data loss, they retransmit, but they also slow down.  The health of the Internet depends on this rule-following behavior among its end hosts in order to fairly share the limited bandwidth during congested periods but also to make the absolute most of the bandwidth when there is no congestion. But wait!  Why not cheat?  If all these other schmucks are following the rules, I can just send data like mad when they are slowing down and WIN.  Ha ha! Well, not so much.  Most routers implement clever queuing disciplines to deal with such shenanigans.  Weighted fair queueing is a typical method which effectively assigns queue space to well behaved data streams and increases the discard rate on poorly behaving ones. The discipline of queue management and quality of service (QoS) runs deep, and there are lots of techniques for prioritizing real time data like voice and video as well as tricks to give priority to short lived streams (Mouse flow) vs. long lived streams (Elephant flow).  Books upon books have been written on the topic, and they are still being written.  The key principle for end hosts is: "don't be an asshole." The key principle for routers is: "punish the assholes."