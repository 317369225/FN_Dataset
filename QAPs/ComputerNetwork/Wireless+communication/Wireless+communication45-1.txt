★How important was Claude Shannon's "A Mathematical Theory of Communication" article to the fields of information theory, encoding, wireless communication, and compression?
It is the paper in the field. He describes the paradigm of "information as statistics" and proves two of the most important results in classical information theory. Compression: n iid copies of a of a source X={x, p(x)} can be represented with nH(X) bits. Channel capacity: The maximum rate of communication using a channel with input X, output Y and channel transition probability p(y|x) is given by sup_{p(x)} I(X;Y). The quantities H(X) (entropy) and I(X;Y) (mutual information) didn't exist before Shannon's paper. Most results in IT since then are generalization and re-implementations of Shannon's original ideas. So long story short -- this paper is VERY important.    Embed Quote