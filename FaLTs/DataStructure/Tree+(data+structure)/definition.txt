As stated above, in different contexts it may be useful to define the term graph with different degrees of generality. Whenever it is necessary to draw a strict distinction, the following terms are used. Most commonly, in modern texts in graph theory, unless stated otherwise, graph means "undirected simple finite graph" (see the definitions below).
According to Knuth's definition, a B-tree of order m (the maximum number of children for each node) is a tree which satisfies the following properties:
Every node has at most m children. Every non-leaf node (except root) has at least �?span class="frac nowrap">m�?sub>2�?children. The root has at least two children if it is not a leaf node. A non-leaf node with k children contains k�? keys. All leaves appear in the same level, and carry information.
Each internal node’s keys act as separation values which divide its subtrees. For example, if an internal node has 3 child nodes (or subtrees) then it must have 2 keys: a1 and a2. All values in the leftmost subtree will be less than a1, all values in the middle subtree will be between a1 and a2, and all values in the rightmost subtree will be greater than a2.
Internal nodes Internal nodes are all nodes except for leaf nodes and the root node. They are usually represented as an ordered set of elements and child pointers. Every internal node contains a maximum of U children and a minimum of L children. Thus, the number of elements is always 1 less than the number of child pointers (the number of elements is between L�? and U�?). U must be either 2L or 2L�?; therefore each internal node is at least half full. The relationship between U and L implies that two half-full nodes can be joined to make a legal node, and one full node can be split into two legal nodes (if there’s room to push one element up into the parent). These properties make it possible to delete and insert new values into a B-tree and adjust the tree to preserve the B-tree properties.
The root node The root node’s number of children has the same upper limit as internal nodes, but has no lower limit. For example, when there are fewer than L�? elements in the entire tree, the root will be the only node in the tree, with no children at all.
Leaf nodes Leaf nodes have the same restriction on the number of elements, but have no children, and no child pointers.
A B-tree of depth n+1 can hold about U times as many items as a B-tree of depth n, but the cost of search, insert, and delete operations grows with the depth of the tree. As with any balanced tree, the cost grows much more slowly than the number of elements.
Some balanced trees store values only at leaf nodes, and use different kinds of nodes for leaf nodes and internal nodes. B-trees keep values in every node in the tree, and may use the same structure for all nodes. However, since leaf nodes never have children, the B-trees benefit from improved performance if they use a specialized structure.
A directed edge refers to the link from the parent to the child (the arrows in the picture of the tree). The root node of a tree is the node with no parents. There is at most one root node in a rooted tree. A leaf node has no children. The depth of a node n is the length of the path from the root to the node. The set of all nodes at a given depth is sometimes called a level of the tree. The root node is at depth zero. The depth (or height) of a tree is the length of the path from the root to the deepest node in the tree. A (rooted) tree with only one node (the root) has a depth of zero. Siblings are nodes that share the same parent node. A node p is an ancestor of a node q if it exists on the path from the root to node q. The node q is then termed as a descendant of p. The size of a node is the number of descendants it has including itself. In-degree of a node is the number of edges arriving at that node. Out-degree of a node is the number of edges leaving that node. The root is the only node in the tree with In-degree = 0. All the leaf nodes have Out-degree = 0.
The suffix tree for the string of length is defined as a tree such that:[2]
the paths from the root to the leaves have a one-to-one relationship with the suffixes of , edges spell non-empty strings, and all internal nodes (except perhaps the root) have at least two children.
Since such a tree does not exist for all strings, is padded with a terminal symbol not seen in the string (usually denoted $). This ensures that no suffix is a prefix of another, and that there will be leaf nodes, one for each of the suffixes of . Since all internal non-root nodes are branching, there can be at most n �?#160; 1 such nodes, and n + (n �?#160;1) + 1 = 2n nodes in total (n leaves, n �?#160;1 internal nodes, 1 root).
Suffix links are a key feature for older linear-time construction algorithms, although most newer algorithms, which are based on Farach's algorithm, dispense with suffix links. In a complete suffix tree, all internal non-root nodes have a suffix link to another internal node. If the path from the root to a node spells the string , where is a single character and is a string (possibly empty), it has a suffix link to the internal node representing . See for example the suffix link from the node for ANA to the node for NA in the figure above. Suffix links are also used in some algorithms running on the tree.
Directed Edge - The link from the parent to the child. Root - The node with no parents. There is at most one root node in a rooted tree. Leaf Node - The node which has no children. Child Node - The nodes that are located underneath of a node. Depth - Length of the path from the root to the node. The set of all nodes at a given depth is sometimes called a level of the tree. The root node is at depth zero. Height - Length of the path from the root to the deepest node in the tree. A (rooted) tree with only one node (the root) has a height of zero. In the example diagram, the tree has height of 2. Sibling - Nodes that share the same parent node.
- A node p is an ancestor of a node q if it exists on the path from q to the root. The node q is then termed a descendant of p.
- A size of a node is the number of descendants it has including itself.
A free tree or unrooted tree is a connected undirected graph with no cycles. The vertices with one neighbor are the leaves of the tree, and the remaining vertices are the internal nodes of the tree. The degree of a vertex is its number of neighbors; in a tree with more than one node, the leaves are the vertices of degree one. An unrooted binary tree is a free tree in which all internal nodes have degree exactly three.
In some applications it may make sense to distinguish subtypes of unrooted binary trees: a planar embedding of the tree may be fixed by specifying a cyclic ordering for the edges at each vertex, making it into a plane tree. In computer science, binary trees are often rooted and ordered when they are used as data structures, but in the applications of unrooted binary trees in hierarchical clustering and evolutionary tree reconstruction, unordered trees are more common.[1]
Additionally, one may distinguish between trees in which all vertices have distinct labels, trees in which the leaves only are labeled, and trees in which the nodes are not labeled. In an unrooted binary tree with n leaves, there will be n �?#160;2 internal nodes, so the labels may be taken from the set of integers from 1 to 2n �?#160;1 when all nodes are to be labeled, or from the set of integers from 1 to n when only the leaves are to be labeled.[1]
In the "imperative" view, which is closer to the philosophy of imperative programming languages, an abstract data structure is conceived as an entity that is mutable �?meaning that it may be in different states at different times. Some operations may change the state of the ADT; therefore, the order in which operations are evaluated is important, and the same operation on the same entities may have different effects if executed at different times �?just like the instructions of a computer, or the commands and procedures of an imperative language. To underscore this view, it is customary to say that the operations are executed or applied, rather than evaluated. The imperative style is often used when describing abstract algorithms. This is described by Donald E. Knuth and can be referenced from here The Art of Computer Programming.
According to Knuth's definition, a B-tree of order m (the maximum number of children for each node) is a tree which satisfies the following properties:
Every node has at most m children. Every non-leaf node (except root) has at least �?span class="frac nowrap">m�?sub>2�?children. The root has at least two children if it is not a leaf node. A non-leaf node with k children contains k�? keys. All leaves appear in the same level, and carry information.
Each internal node’s keys act as separation values which divide its subtrees. For example, if an internal node has 3 child nodes (or subtrees) then it must have 2 keys: a1 and a2. All values in the leftmost subtree will be less than a1, all values in the middle subtree will be between a1 and a2, and all values in the rightmost subtree will be greater than a2.
Internal nodes Internal nodes are all nodes except for leaf nodes and the root node. They are usually represented as an ordered set of elements and child pointers. Every internal node contains a maximum of U children and a minimum of L children. Thus, the number of elements is always 1 less than the number of child pointers (the number of elements is between L�? and U�?). U must be either 2L or 2L�?; therefore each internal node is at least half full. The relationship between U and L implies that two half-full nodes can be joined to make a legal node, and one full node can be split into two legal nodes (if there’s room to push one element up into the parent). These properties make it possible to delete and insert new values into a B-tree and adjust the tree to preserve the B-tree properties.
The root node The root node’s number of children has the same upper limit as internal nodes, but has no lower limit. For example, when there are fewer than L�? elements in the entire tree, the root will be the only node in the tree, with no children at all.
Leaf nodes Leaf nodes have the same restriction on the number of elements, but have no children, and no child pointers.
A B-tree of depth n+1 can hold about U times as many items as a B-tree of depth n, but the cost of search, insert, and delete operations grows with the depth of the tree. As with any balanced tree, the cost grows much more slowly than the number of elements.
Some balanced trees store values only at leaf nodes, and use different kinds of nodes for leaf nodes and internal nodes. B-trees keep values in every node in the tree, and may use the same structure for all nodes. However, since leaf nodes never have children, the B-trees benefit from improved performance if they use a specialized structure.
A biconnected undirected graph is a connected graph that is not broken into disconnected pieces by deleting any single vertex (and its incident edges).
A biconnected directed graph is one such that for any two vertices v and w there are two directed paths from v to w which have no vertices in common other than v and w.
Nonseparable (or 2-connected) graphs (or blocks) with n nodes (sequence A002218 in OEIS) Vertices Number of Possibilities 1 0 2 1 3 1 4 3 5 10 6 56 7 468 8 7123 9 194066 10 9743542 11 900969091 12 153620333545 13 48432939150704 14 28361824488394169 15 30995890806033380784 16 63501635429109597504951 17 244852079292073376010411280 18 1783160594069429925952824734641 19 24603887051350945867492816663958981
A Boolean function can be represented as a rooted, directed, acyclic graph, which consists of several decision nodes and terminal nodes. There are two types of terminal nodes called 0-terminal and 1-terminal. Each decision node is labeled by Boolean variable and has two child nodes called low child and high child. The edge from node to a low (or high) child represents an assignment of to 0 (resp. 1). Such a BDD is called 'ordered' if different variables appear in the same order on all paths from the root. A BDD is said to be 'reduced' if the following two rules have been applied to its graph:
Merge any isomorphic subgraphs. Eliminate any node whose two children are isomorphic.
In popular usage, the term BDD almost always refers to Reduced Ordered Binary Decision Diagram (ROBDD in the literature, used when the ordering and reduction aspects need to be emphasized). The advantage of an ROBDD is that it is canonical (unique) for a particular function and variable order.[1] This property makes it useful in functional equivalence checking and other operations like functional technology mapping.
A path from the root node to the 1-terminal represents a (possibly partial) variable assignment for which the represented Boolean function is true. As the path descends to a low (or high) child child from a node, then that node's variable is assigned to 0 (resp. 1).
A directed edge refers to the link from the parent to the child (the arrows in the picture of the tree). The root node of a tree is the node with no parents. There is at most one root node in a rooted tree. A leaf node has no children. The depth of a node n is the length of the path from the root to the node. The set of all nodes at a given depth is sometimes called a level of the tree. The root node is at depth zero. The depth (or height) of a tree is the length of the path from the root to the deepest node in the tree. A (rooted) tree with only one node (the root) has a depth of zero. Siblings are nodes that share the same parent node. A node p is an ancestor of a node q if it exists on the path from the root to node q. The node q is then termed as a descendant of p. The size of a node is the number of descendants it has including itself. In-degree of a node is the number of edges arriving at that node. Out-degree of a node is the number of edges leaving that node. The root is the only node in the tree with In-degree = 0. All the leaf nodes have Out-degree = 0.
A directed edge refers to the link from the parent to the child (the arrows in the picture of the tree). The root node of a tree is the node with no parents. There is at most one root node in a rooted tree. A leaf node has no children. The depth of a node n is the length of the path from the root to the node. The set of all nodes at a given depth is sometimes called a level of the tree. The root node is at depth zero. The depth (or height) of a tree is the length of the path from the root to the deepest node in the tree. A (rooted) tree with only one node (the root) has a depth of zero. Siblings are nodes that share the same parent node. A node p is an ancestor of a node q if it exists on the path from the root to node q. The node q is then termed as a descendant of p. The size of a node is the number of descendants it has including itself. In-degree of a node is the number of edges arriving at that node. Out-degree of a node is the number of edges leaving that node. The root is the only node in the tree with In-degree = 0. All the leaf nodes have Out-degree = 0.
The Cartesian tree for a sequence of distinct numbers can be uniquely defined by the following properties:
The Cartesian tree for a sequence has one node for each number in the sequence. Each node is associated with a single sequence value. A symmetric (in-order) traversal of the tree results in the original sequence. That is, the left subtree consists of the values earlier than the root in the sequence order, while the right subtree consists of the values later than the root, and a similar ordering constraint holds at each lower node of the tree. The tree has the heap property: the parent of any non-root node has a smaller value than the node itself.[1]
Based on the heap property, the root of the tree must be the smallest number in the sequence. From this, the tree itself may also be defined recursively: the root is the minimum value of the sequence, and the left and right subtrees are the Cartesian trees for the subsequences to the left and right of the root value. Therefore, the three properties above uniquely define the Cartesian tree.
If a sequence of numbers contains repetitions, the Cartesian tree may be defined by determining a consistent tie-breaking rule (for instance, determining that the first of two equal elements is treated as the smaller of the two) before applying the above rules.
An example of a Cartesian tree is shown in the figure above.
Suppose that is a group and is a generating set. The Cayley graph is a colored directed graph constructed as follows[2]
Each element of is assigned a vertex: the vertex set of is identified with Each generator of is assigned a color . For any the vertices corresponding to the elements and are joined by a directed edge of colour Thus the edge set consists of pairs of the form with providing the color.
In geometric group theory, the set is usually assumed to be finite, symmetric (i.e. ) and not containing the identity element of the group. In this case, the uncolored Cayley graph is an ordinary graph: its edges are not oriented and it does not contain loops (single-element cycles) if and only if .
A clique in an undirected graph G = (V, E) is a subset of the vertex set C �?#160;V, such that for every two vertices in C, there exists an edge connecting the two. This is equivalent to saying that the subgraph induced by C is complete (in some cases, the term clique may also refer to the subgraph).
A maximal clique is a clique that cannot be extended by including one more adjacent vertex, that is, a clique which does not exist exclusively within the vertex set of a larger clique.
A maximum clique is a clique of the largest possible size in a given graph. The clique number ω(G) of a graph G is the number of vertices in a maximum clique in G. The intersection number of G is the smallest number of cliques that together cover all edges of G.
The opposite of a clique is an independent set, in the sense that every clique corresponds to an independent set in the complement graph. The clique cover problem concerns finding as few cliques as possible that include every vertex in the graph. A related concept is a biclique, a complete bipartite subgraph. The bipartite dimension of a graph is the minimum number of bicliques needed to cover all the edges of the graph.
Any cograph may be constructed using the following rules:
any single vertex graph is a cograph; if is a cograph, so is its complement ; if and are cographs, so is their disjoint union .
Several alternative characterizations of cographs can be given. Among them:
A cograph is a graph which does not contain the path P4 on 4 vertices (and hence of length 3) as an induced subgraph. That is, a graph is a cograph if and only if for any four vertices , if and are edges of the graph then at least one of or is also an edge (Corneil, Lerchs & Burlingham 1981). A cograph is a graph all of whose induced subgraphs have the property that any maximal clique intersects any maximal independent set in a single vertex. A cograph is a graph in which every nontrivial induced subgraph has at least two vertices with the same neighbourhoods. A cograph is a graph in which every connected induced subgraph has a disconnected complement. A cograph is a graph all of whose connected induced subgraphs have diameter at most 2. A cograph is a graph in which every connected component is a distance-hereditary graph with diameter at most 2. A cograph is a graph with clique-width at most 2 (Courcelle & Olariu 2000).
All complete graphs, complete bipartite graphs, threshold graphs, and Turán graphs are cographs. Every cograph is distance-hereditary, a comparability graph, and perfect.
Cographs are the comparability graphs of series-parallel partial orders (Jung 1978).
A directed edge refers to the link from the parent to the child (the arrows in the picture of the tree). The root node of a tree is the node with no parents. There is at most one root node in a rooted tree. A leaf node has no children. The depth of a node n is the length of the path from the root to the node. The set of all nodes at a given depth is sometimes called a level of the tree. The root node is at depth zero. The depth (or height) of a tree is the length of the path from the root to the deepest node in the tree. A (rooted) tree with only one node (the root) has a depth of zero. Siblings are nodes that share the same parent node. A node p is an ancestor of a node q if it exists on the path from the root to node q. The node q is then termed as a descendant of p. The size of a node is the number of descendants it has including itself. In-degree of a node is the number of edges arriving at that node. Out-degree of a node is the number of edges leaving that node. The root is the only node in the tree with In-degree = 0. All the leaf nodes have Out-degree = 0.
A complete bipartite graph, G := (V1 + V2, E), is a bipartite graph such that for any two vertices, v1 �?V1 and v2 �?V2, v1v2 is an edge in G. The complete bipartite graph with partitions of size |V1|=m and |V2|=n, is denoted Km,n.
In an undirected graph G, two vertices u and v are called connected if G contains a path from u to v. Otherwise, they are called disconnected. If the two vertices are additionally connected by a path of length 1, i.e. by a single edge, the vertices are called adjacent. A graph is said to be connected if every pair of vertices in the graph is connected.
A connected component is a maximal connected subgraph of G. Each vertex belongs to exactly one connected component, as does each edge.
A directed graph is called weakly connected if replacing all of its directed edges with undirected edges produces a connected (undirected) graph. It is connected if it contains a directed path from u to v or a directed path from v to u for every pair of vertices u, v. It is strongly connected or strong if it contains a directed path from u to v and a directed path from v to u for every pair of vertices u, v. The strong components are the maximal strongly connected subgraphs.
A cut, vertex cut, or separating set of a connected graph G is a set of vertices whose removal renders G disconnected. The connectivity or vertex connectivity κ(G) (where G is not a complete graph) is the size of a minimal vertex cut. A graph is called k-connected or k-vertex-connected if its vertex connectivity is k or greater. This means a graph G is said to be k-connected if there does not exist a set of k-1 vertices whose removal disconnects the graph. A complete graph with n vertices, denoted , has no vertex cuts at all, but by convention κ() = n-1. A vertex cut for two vertices u and v is a set of vertices whose removal from the graph disconnects u and v. The local connectivity κ(u, v) is the size of a smallest vertex cut separating u and v. Local connectivity is symmetric for undirected graphs; that is, κ(u,v)=κ(v,u). Moreover, except for complete graphs, κ(G) equals the minimum of κ(u,v) over all nonadjacent pairs of vertices u, v.
2-connectivity is also called biconnectivity and 3-connectivity is also called triconnectivity.
Analogous concepts can be defined for edges. In the simple case in which cutting a single, specific edge would disconnect the graph, that edge is called a bridge. More generally, the edge cut of G is a group of edges whose total removal renders the graph disconnected. The edge-connectivity λ(G) is the size of a smallest edge cut, and the local edge-connectivity λ(u,v) of two vertices u, v is the size of a smallest edge cut disconnecting u from v. Again, local edge-connectivity is symmetric. A graph is called k-edge-connected if its edge connectivity is k or greater.
(Parnas, Shore & Weiss 1976) identified five definitions of a "type" that were used—sometimes implicitly—in the literature:
Syntactic A type is a purely syntactic label associated with a variable when it is declared. Such definitions of "type" do not give any semantic meaning to types. Representation A type is defined in terms of its composition of more primitive types—often machine types. Representation and behaviour A type is defined as its representation and a set of operators manipulating these representations. Value space A type is a set of possible values which a variable can possess. Such definitions make it possible to speak about (disjoint) unions or Cartesian products of types. Value space and behaviour A type is a set of values which a variable can posses and a set of functions that one can apply to these values.
The definition in terms of a representation was often done in imperative languages such as ALGOL and Pascal, while the definition in terms of a value space and behaviour was used in higher-level languages such as Simula and CLU.
As stated above, in different contexts it may be useful to define the term graph with different degrees of generality. Whenever it is necessary to draw a strict distinction, the following terms are used. Most commonly, in modern texts in graph theory, unless stated otherwise, graph means "undirected simple finite graph" (see the definitions below).
Formally, an intersection graph is an undirected graph formed from a family of sets
Si, i = 0, 1, 2, ...
by creating one vertex vi for each set Si, and connecting two vertices vi and vj by an edge whenever the corresponding two sets have a nonempty intersection, that is,
E(G) = {{vi, vj} | Si �?#160;Sj �?#160;∅}.
Let {I1, I2, ..., In} �?#160;P(R) be a set of intervals.
The corresponding interval graph is G = (V, E), where
V = {I1, I2, ..., In}, and {Iα, Iβ} �?#160;E if and only if Iα �?#160;Iβ �?#160;�?
From this construction one can verify a common property held by all interval graphs. That is, graph G is an interval graph if and only if the maximal cliques of G can be ordered M1, M2, ..., Mk such that for any v �?#160;Mi �?#160;Mk, where i < k, it is also the case that v �?#160;Mj for any Mj, i �?#160;j �?#160;k.[1]
Let G = (E,V) be an arbitrary graph. If G' = (E \ X,V) is connected for all X �?#160;E where |X| < k, then G is k-edge-connected. Trivially, a graph that is k-edge-connected is also (k�?)-edge-connected.
Given a graph G, its line graph L(G) is a graph such that
each vertex of L(G) represents an edge of G; and two vertices of L(G) are adjacent if and only if their corresponding edges share a common endpoint ("are adjacent") in G.
That is, it is the intersection graph of the edges of G, representing each edge by the set of its two endpoints.
The abstract list type L with elements of some type E (a monomorphic list) is defined by the following functions:
nil: () �?L cons: E × L �?L first: L �?E rest: L �?L
with the axioms
first (cons (e, l)) = e rest (cons (e, l)) = l
for any element e and any list l. It is implicit that
cons (e, l) �?l cons (e, l) �?e cons (e1, l1) = cons (e2, l2) if e1 = e2 and l1 = l2
Note that first (nil ()) and rest (nil ()) are not defined.
These axioms are equivalent to those of the abstract stack data type.
In type theory, the above definition is more simply regarded as an inductive type defined in terms of constructors: nil and cons. In algebraic terms, this can be represented as the transformation 1 + E × L �?L. first and rest are then obtained by pattern matching on the cons constructor and separately handling the nil case.
In any graph, for any two vertices a and b, define the interval of vertices that lie on shortest paths
I(a,b) = {v | d(a,b) = d(a,v) + d(v,b)}. 
A median graph is defined by the property that, for any three vertices a, b, and c, these intervals intersect in a single point:
For all a, b, and c, |I(a,b) �?I(a,c) �?I(b,c)| = 1.
Equivalently, for every three vertices a, b, and c one can find a vertex m(a,b,c) such that the unweighted distances in the graph satisfy the equalities
d(a,b) = d(a,m(a,b,c)) + d(m(a,b,c),b) d(a,c) = d(a,m(a,b,c)) + d(m(a,b,c),c) d(b,c) = d(b,m(a,b,c)) + d(m(a,b,c),c)
and m(a,b,c) is the only vertex for which this is true.
It is also possible to define median graphs as the solution sets of 2-satisfiability problems, as the retracts of hypercubes, as the graphs of finite median algebras, as the Buneman graphs of Helly split systems, and as the graphs of windex 2; see the sections below.
An n-vertex graph G is pancyclic if, for every k in the range 3 �?k �?n, G contains a cycle of length k.[1] It is node-pancyclic or vertex-pancyclic if, for every vertex v and every k in the same range, it contains a cycle of length k that contains v.[2] Similarly, it is edge-pancyclic if, for every edge e and every k in the same range, it contains a cycle of length k that contains e.[2]
A bipartite graph cannot be pancyclic, because it does not contain any odd-length cycles, but it is said to be bipancyclic if it contains cycles of all even lengths from 4 to n.[3]
Every planar graph without loops is 4-partite, or 4-colorable; this is the graph-theoretical formulation of the four color theorem.
Fáry's theorem states that every simple planar graph admits an embedding in the plane such that all edges are straight line segments which don't intersect. Similarly, every simple outerplanar graph admits an embedding in the plane such that all vertices lie on a fixed circle and all edges are straight line segments that lie inside the disk and don't intersect.
A planar graph and its dual
Given an embedding G of a (not necessarily simple) connected graph in the plane without edge intersections, we construct the dual graph G* as follows: we choose one vertex in each face of G (including the outer face) and for each edge e in G we introduce a new edge in G* connecting the two vertices in G* corresponding to the two faces in G that meet at e. Furthermore, this edge is drawn so that it crosses e exactly once and that no other edge of G or G* is intersected. Then G* is again the embedding of a (not necessarily simple) planar graph; it has as many edges as G, as many vertices as G has faces and as many faces as G has vertices. The term "dual" is justified by the fact that G** = G; here the equality is the equivalence of embeddings on the sphere. If G is the planar graph corresponding to a convex polyhedron, then G* is the planar graph corresponding to the dual polyhedron.
Duals are useful because many properties of the dual graph are related in simple ways to properties of the original graph, enabling results to be proven about graphs by examining their dual graphs.
While the dual constructed for a particular embedding is unique (up to isomorphism), graphs may have different (i.e. non-isomorphic) duals, obtained from different (i.e. non-homeomorphic) embeddings.
A Euclidean graph is a graph in which the vertices represent points in the plane, and the edges are assigned lengths equal to the Euclidean distance between those points; see Geometric graph theory.
A plane graph is said to be convex if all of its faces (including the outer face) are convex polygons. A planar graph may be drawn convexly if and only if it is a subdivision of a 3-vertex-connected planar graph.
Scheinerman's conjecture (now a theorem) states that every planar graph can be represented as an intersection graph of line segments in the plane.
The planar separator theorem states that every n-vertex planar graph can be partitioned into two subgraphs of size at most 2n/3 by the removal of O(�?i>n) vertices. As a consequence, planar graphs also have treewidth and branch-width O(�?i>n).
For two planar graphs with v vertices, it is possible to determine in time O(v) whether they are isomorphic or not (see also graph isomorphism problem).[5]
In this context, the term graph means multigraph.
There are several ways to define series-parallel graphs. The following definition basically follows the one used by David Eppstein.[1]
A two-terminal graph (TTG) is a graph with two distinguished vertices, s and t called source and sink, respectively.
The parallel composition Pc = Pc(X,Y) of two TTGs X and Y is a TTG created from the disjoint union of graphs X and Y by merging the sources of X and Y to create the source of Pc and merging the sinks of X and Y to create the sink of Pc.
The series composition Sc = Sc(X,Y) of two TTGs X and Y is a TTG created from the disjoint union of graphs X and Y by merging the sink of X with the source of Y. The source of X becomes the source of Sc and the sink of Y becomes the sink of Sc.
A two-terminal series-parallel graph (TTSPG) is a graph that may be constructed by a sequence of series and parallel compositions starting from a set of copies of a single-edge graph K2 with assigned terminals.
Definition 1. Finally, a graph is called series-parallel (sp-graph), if it is a TTSPG when some two of its vertices are regarded as source and sink.
In a similar way one may define series-parallel digraphs, constructed from copies of single-arc graphs, with arcs directed from the source to the sink.
As stated above, in different contexts it may be useful to define the term graph with different degrees of generality. Whenever it is necessary to draw a strict distinction, the following terms are used. Most commonly, in modern texts in graph theory, unless stated otherwise, graph means "undirected simple finite graph" (see the definitions below).
A stack is a basic computer science data structure and can be defined in an abstract, implementation-free manner, or it can be generally defined as a linear list of items in which all additions and deletion are restricted to one end that is Top.
This is a VDM (Vienna Development Method) description of a stack:[4]
Function signatures:
init: -> Stack
  push: N x Stack -> Stack
  top: Stack -> (N U ERROR)
  remove: Stack -> Stack
  isempty: Stack -> Boolean
(where N indicates an element (natural numbers in this case), and U indicates set union)
Semantics:
top(init()) = ERROR
  top(push(i,s)) = i
  remove(init()) = init()
  remove(push(i, s)) = s
  isempty(init()) = true
  isempty(push(i, s)) = false
Directed Edge - The link from the parent to the child. Root - The node with no parents. There is at most one root node in a rooted tree. Leaf Node - The node which has no children. Child Node - The nodes that are located underneath of a node. Depth - Length of the path from the root to the node. The set of all nodes at a given depth is sometimes called a level of the tree. The root node is at depth zero. Height - Length of the path from the root to the deepest node in the tree. A (rooted) tree with only one node (the root) has a height of zero. In the example diagram, the tree has height of 2. Sibling - Nodes that share the same parent node.
- A node p is an ancestor of a node q if it exists on the path from q to the root. The node q is then termed a descendant of p.
- A size of a node is the number of descendants it has including itself.
As stated above, in different contexts it may be useful to define the term graph with different degrees of generality. Whenever it is necessary to draw a strict distinction, the following terms are used. Most commonly, in modern texts in graph theory, unless stated otherwise, graph means "undirected simple finite graph" (see the definitions below).
A free tree or unrooted tree is a connected undirected graph with no cycles. The vertices with one neighbor are the leaves of the tree, and the remaining vertices are the internal nodes of the tree. The degree of a vertex is its number of neighbors; in a tree with more than one node, the leaves are the vertices of degree one. An unrooted binary tree is a free tree in which all internal nodes have degree exactly three.
In some applications it may make sense to distinguish subtypes of unrooted binary trees: a planar embedding of the tree may be fixed by specifying a cyclic ordering for the edges at each vertex, making it into a plane tree. In computer science, binary trees are often rooted and ordered when they are used as data structures, but in the applications of unrooted binary trees in hierarchical clustering and evolutionary tree reconstruction, unordered trees are more common.[1]
Additionally, one may distinguish between trees in which all vertices have distinct labels, trees in which the leaves only are labeled, and trees in which the nodes are not labeled. In an unrooted binary tree with n leaves, there will be n �?#160;2 internal nodes, so the labels may be taken from the set of integers from 1 to 2n �?#160;1 when all nodes are to be labeled, or from the set of integers from 1 to n when only the leaves are to be labeled.[1]
