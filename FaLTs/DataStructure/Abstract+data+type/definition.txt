In the "imperative" view, which is closer to the philosophy of imperative programming languages, an abstract data structure is conceived as an entity that is mutable �?meaning that it may be in different states at different times. Some operations may change the state of the ADT; therefore, the order in which operations are evaluated is important, and the same operation on the same entities may have different effects if executed at different times �?just like the instructions of a computer, or the commands and procedures of an imperative language. To underscore this view, it is customary to say that the operations are executed or applied, rather than evaluated. The imperative style is often used when describing abstract algorithms. This is described by Donald E. Knuth and can be referenced from here The Art of Computer Programming.
(Parnas, Shore & Weiss 1976) identified five definitions of a "type" that were used—sometimes implicitly—in the literature:
Syntactic A type is a purely syntactic label associated with a variable when it is declared. Such definitions of "type" do not give any semantic meaning to types. Representation A type is defined in terms of its composition of more primitive types—often machine types. Representation and behaviour A type is defined as its representation and a set of operators manipulating these representations. Value space A type is a set of possible values which a variable can possess. Such definitions make it possible to speak about (disjoint) unions or Cartesian products of types. Value space and behaviour A type is a set of values which a variable can posses and a set of functions that one can apply to these values.
The definition in terms of a representation was often done in imperative languages such as ALGOL and Pascal, while the definition in terms of a value space and behaviour was used in higher-level languages such as Simula and CLU.
The abstract list type L with elements of some type E (a monomorphic list) is defined by the following functions:
nil: () �?L cons: E × L �?L first: L �?E rest: L �?L
with the axioms
first (cons (e, l)) = e rest (cons (e, l)) = l
for any element e and any list l. It is implicit that
cons (e, l) �?l cons (e, l) �?e cons (e1, l1) = cons (e2, l2) if e1 = e2 and l1 = l2
Note that first (nil ()) and rest (nil ()) are not defined.
These axioms are equivalent to those of the abstract stack data type.
In type theory, the above definition is more simply regarded as an inductive type defined in terms of constructors: nil and cons. In algebraic terms, this can be represented as the transformation 1 + E × L �?L. first and rest are then obtained by pattern matching on the cons constructor and separately handling the nil case.
A stack is a basic computer science data structure and can be defined in an abstract, implementation-free manner, or it can be generally defined as a linear list of items in which all additions and deletion are restricted to one end that is Top.
This is a VDM (Vienna Development Method) description of a stack:[4]
Function signatures:
init: -> Stack
  push: N x Stack -> Stack
  top: Stack -> (N U ERROR)
  remove: Stack -> Stack
  isempty: Stack -> Boolean
(where N indicates an element (natural numbers in this case), and U indicates set union)
Semantics:
top(init()) = ERROR
  top(push(i,s)) = i
  remove(init()) = init()
  remove(push(i, s)) = s
  isempty(init()) = true
  isempty(push(i, s)) = false
In the "imperative" view, which is closer to the philosophy of imperative programming languages, an abstract data structure is conceived as an entity that is mutable �?meaning that it may be in different states at different times. Some operations may change the state of the ADT; therefore, the order in which operations are evaluated is important, and the same operation on the same entities may have different effects if executed at different times �?just like the instructions of a computer, or the commands and procedures of an imperative language. To underscore this view, it is customary to say that the operations are executed or applied, rather than evaluated. The imperative style is often used when describing abstract algorithms. This is described by Donald E. Knuth and can be referenced from here The Art of Computer Programming.
According to Knuth's definition, a B-tree of order m (the maximum number of children for each node) is a tree which satisfies the following properties:
Every node has at most m children. Every non-leaf node (except root) has at least �?span class="frac nowrap">m�?sub>2�?children. The root has at least two children if it is not a leaf node. A non-leaf node with k children contains k�? keys. All leaves appear in the same level, and carry information.
Each internal node’s keys act as separation values which divide its subtrees. For example, if an internal node has 3 child nodes (or subtrees) then it must have 2 keys: a1 and a2. All values in the leftmost subtree will be less than a1, all values in the middle subtree will be between a1 and a2, and all values in the rightmost subtree will be greater than a2.
Internal nodes Internal nodes are all nodes except for leaf nodes and the root node. They are usually represented as an ordered set of elements and child pointers. Every internal node contains a maximum of U children and a minimum of L children. Thus, the number of elements is always 1 less than the number of child pointers (the number of elements is between L�? and U�?). U must be either 2L or 2L�?; therefore each internal node is at least half full. The relationship between U and L implies that two half-full nodes can be joined to make a legal node, and one full node can be split into two legal nodes (if there’s room to push one element up into the parent). These properties make it possible to delete and insert new values into a B-tree and adjust the tree to preserve the B-tree properties.
The root node The root node’s number of children has the same upper limit as internal nodes, but has no lower limit. For example, when there are fewer than L�? elements in the entire tree, the root will be the only node in the tree, with no children at all.
Leaf nodes Leaf nodes have the same restriction on the number of elements, but have no children, and no child pointers.
A B-tree of depth n+1 can hold about U times as many items as a B-tree of depth n, but the cost of search, insert, and delete operations grows with the depth of the tree. As with any balanced tree, the cost grows much more slowly than the number of elements.
Some balanced trees store values only at leaf nodes, and use different kinds of nodes for leaf nodes and internal nodes. B-trees keep values in every node in the tree, and may use the same structure for all nodes. However, since leaf nodes never have children, the B-trees benefit from improved performance if they use a specialized structure.
A Boolean function can be represented as a rooted, directed, acyclic graph, which consists of several decision nodes and terminal nodes. There are two types of terminal nodes called 0-terminal and 1-terminal. Each decision node is labeled by Boolean variable and has two child nodes called low child and high child. The edge from node to a low (or high) child represents an assignment of to 0 (resp. 1). Such a BDD is called 'ordered' if different variables appear in the same order on all paths from the root. A BDD is said to be 'reduced' if the following two rules have been applied to its graph:
Merge any isomorphic subgraphs. Eliminate any node whose two children are isomorphic.
In popular usage, the term BDD almost always refers to Reduced Ordered Binary Decision Diagram (ROBDD in the literature, used when the ordering and reduction aspects need to be emphasized). The advantage of an ROBDD is that it is canonical (unique) for a particular function and variable order.[1] This property makes it useful in functional equivalence checking and other operations like functional technology mapping.
A path from the root node to the 1-terminal represents a (possibly partial) variable assignment for which the represented Boolean function is true. As the path descends to a low (or high) child child from a node, then that node's variable is assigned to 0 (resp. 1).
The Cartesian tree for a sequence of distinct numbers can be uniquely defined by the following properties:
The Cartesian tree for a sequence has one node for each number in the sequence. Each node is associated with a single sequence value. A symmetric (in-order) traversal of the tree results in the original sequence. That is, the left subtree consists of the values earlier than the root in the sequence order, while the right subtree consists of the values later than the root, and a similar ordering constraint holds at each lower node of the tree. The tree has the heap property: the parent of any non-root node has a smaller value than the node itself.[1]
Based on the heap property, the root of the tree must be the smallest number in the sequence. From this, the tree itself may also be defined recursively: the root is the minimum value of the sequence, and the left and right subtrees are the Cartesian trees for the subsequences to the left and right of the root value. Therefore, the three properties above uniquely define the Cartesian tree.
If a sequence of numbers contains repetitions, the Cartesian tree may be defined by determining a consistent tie-breaking rule (for instance, determining that the first of two equal elements is treated as the smaller of the two) before applying the above rules.
An example of a Cartesian tree is shown in the figure above.
(Parnas, Shore & Weiss 1976) identified five definitions of a "type" that were used—sometimes implicitly—in the literature:
Syntactic A type is a purely syntactic label associated with a variable when it is declared. Such definitions of "type" do not give any semantic meaning to types. Representation A type is defined in terms of its composition of more primitive types—often machine types. Representation and behaviour A type is defined as its representation and a set of operators manipulating these representations. Value space A type is a set of possible values which a variable can possess. Such definitions make it possible to speak about (disjoint) unions or Cartesian products of types. Value space and behaviour A type is a set of values which a variable can posses and a set of functions that one can apply to these values.
The definition in terms of a representation was often done in imperative languages such as ALGOL and Pascal, while the definition in terms of a value space and behaviour was used in higher-level languages such as Simula and CLU.
As stated above, in different contexts it may be useful to define the term graph with different degrees of generality. Whenever it is necessary to draw a strict distinction, the following terms are used. Most commonly, in modern texts in graph theory, unless stated otherwise, graph means "undirected simple finite graph" (see the definitions below).
The abstract list type L with elements of some type E (a monomorphic list) is defined by the following functions:
nil: () �?L cons: E × L �?L first: L �?E rest: L �?L
with the axioms
first (cons (e, l)) = e rest (cons (e, l)) = l
for any element e and any list l. It is implicit that
cons (e, l) �?l cons (e, l) �?e cons (e1, l1) = cons (e2, l2) if e1 = e2 and l1 = l2
Note that first (nil ()) and rest (nil ()) are not defined.
These axioms are equivalent to those of the abstract stack data type.
In type theory, the above definition is more simply regarded as an inductive type defined in terms of constructors: nil and cons. In algebraic terms, this can be represented as the transformation 1 + E × L �?L. first and rest are then obtained by pattern matching on the cons constructor and separately handling the nil case.
A stack is a basic computer science data structure and can be defined in an abstract, implementation-free manner, or it can be generally defined as a linear list of items in which all additions and deletion are restricted to one end that is Top.
This is a VDM (Vienna Development Method) description of a stack:[4]
Function signatures:
init: -> Stack
  push: N x Stack -> Stack
  top: Stack -> (N U ERROR)
  remove: Stack -> Stack
  isempty: Stack -> Boolean
(where N indicates an element (natural numbers in this case), and U indicates set union)
Semantics:
top(init()) = ERROR
  top(push(i,s)) = i
  remove(init()) = init()
  remove(push(i, s)) = s
  isempty(init()) = true
  isempty(push(i, s)) = false
A free tree or unrooted tree is a connected undirected graph with no cycles. The vertices with one neighbor are the leaves of the tree, and the remaining vertices are the internal nodes of the tree. The degree of a vertex is its number of neighbors; in a tree with more than one node, the leaves are the vertices of degree one. An unrooted binary tree is a free tree in which all internal nodes have degree exactly three.
In some applications it may make sense to distinguish subtypes of unrooted binary trees: a planar embedding of the tree may be fixed by specifying a cyclic ordering for the edges at each vertex, making it into a plane tree. In computer science, binary trees are often rooted and ordered when they are used as data structures, but in the applications of unrooted binary trees in hierarchical clustering and evolutionary tree reconstruction, unordered trees are more common.[1]
Additionally, one may distinguish between trees in which all vertices have distinct labels, trees in which the leaves only are labeled, and trees in which the nodes are not labeled. In an unrooted binary tree with n leaves, there will be n �?#160;2 internal nodes, so the labels may be taken from the set of integers from 1 to 2n �?#160;1 when all nodes are to be labeled, or from the set of integers from 1 to n when only the leaves are to be labeled.[1]
