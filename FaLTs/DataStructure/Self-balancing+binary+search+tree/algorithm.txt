Parallel algorithms for constructing red–black trees from sorted lists of items can run in constant time or O(loglog n) time, depending on the computer model, if the number of processors available is proportional to the number of items. Fast search, insertion, and deletion parallel algorithms are also known.[7]
Most often, the weights used in implementations of Huffman coding represent numeric probabilities, but the algorithm given above does not require this; it requires only that the weights form a totally ordered commutative monoid, meaning a way to order weights and to add them. The Huffman template algorithm enables one to use any kind of weights (costs, frequencies, pairs of weights, non-numerical weights) and one of many combining methods (not just addition). Such algorithms can solve other minimization problems, such as minimizing , a problem first applied to circuit design [2].
A sorting algorithm can also be used to implement a priority queue. Specifically, Thorup says[4]:
We present a general deterministic linear space reduction from priority queues to sorting implying that if we can sort up to n keys in S(n) time per key, then there is a priority queue supporting delete and insert in O(S(n)) time and find-min in constant time.
That is, if there is a sorting algorithm which can sort in O(S) time per key, where S is some function of n and word size,[5] then one can use the given procedure to create a priority queue where pulling the highest-priority element is O(1) time, and inserting new elements (and deleting elements) is O(S) time. For example if one has an O(n lg lg n) sort algorithm, one can create a priority queue with O(1) pulling and O(lg lg n) insertion.
Parallel algorithms for constructing red–black trees from sorted lists of items can run in constant time or O(loglog n) time, depending on the computer model, if the number of processors available is proportional to the number of items. Fast search, insertion, and deletion parallel algorithms are also known.[7]
Input: An array P with n elements
Output: An array S of n elements such that S[i] is the largest integer k such that k <= i + 1 and P[y] <= P[i] for j = i - k + 1,.....,i
Algorithm:
1. Initialize an array P which contains the daily prices of the stocks
       2. Initialize an array S which will store the span of the stock
       3. for i = 0 to i = n - 1
               3.1 Initialize k to zero
               3.2 Done with a false condition
               3.3 repeat
                     3.3.1 if ( P[i - k] <= P[i] ) then
                               Increment k by 1
                     3.3.2 else
                               Done with true condition
               3.4 Till (k > i) or done with processing
                     Assign value of k to S[i] to get the span of the stock
       4. Return array S
Now, analyzing this algorithm for running time, we observe:
We have initialized the array S at the beginning and returned it at the end. This is a constant time operation, hence takes O(1) time
The repeat loop is nested within the for loop. The for loop, whose counter is i is executed n times. The statements which are not in the repeat loop, but in the for loop are executed n times. Therefore these statements and the incrementing and condition testing of i take O(n) time.
In repetition of i for the outer for loop, the body of the inner repeat loop is executed maximum i + 1 times. In the worst case, element S[i] is greater than all the previous elements. So, testing for the if condition, the statement after that, as well as testing the until condition, will be performed i + 1 times during iteration i for the outer for loop. Hence, the total time taken by the inner loop is O(n(n + 1)/2), which is O()
The running time of all these steps is calculated by adding the time taken by all these three steps. The first two terms are O() while the last term is O(). Therefore the total running time of the algorithm is O().
There are many algorithms for processing strings, each with various trade-offs. Some categories of algorithms include:
String searching algorithms for finding a given substring or pattern String manipulation algorithms Sorting algorithms Regular expression algorithms Parsing a string Sequence mining
Advanced string algorithms often employ complex mechanisms and data structures, among them suffix trees and finite state machines.
This section requires expansion. (June 2008)
During the Tango Search after encountering any new auxiliary tree (NAT) the Tango Cut being applied on the tree above the NAT results in a new structure of auxiliary trees. We can think of that as a Tango sub tree. It will normally contain at least two connected auxiliary trees. The top tree A containing the nodes we want to keep close to the surface of the Tango Tree (so we can achieve the ‘bring to top�?approach) and ‘hang�?to it is auxiliary tree D which was pushed downwards. In case of search for 23 all of the nodes from previous auxiliary tree should be kept close to surface and the set of nodes destined to be moved in D is empty so we have no D. Regardless of the situation the result of the Tango cut will contain at least one node (the Tango root) in Tree A. Let's call this result of the cut A.
The Join will join A set of nodes with the nodes in the NAT. That is done via two splits, an un-mark and two concatenates.
Fig. 12 shows the high level sequence where A is coming from the previous cut tree and B is the NAT. We observe that NAT is actually hung under the tree that was just cut therefore the values of its keys are all in a range of two adjacent keys (a key and its successor) in the tree that was just cut. That is normal for any BST. If the NAT is hanging as a left tree the parent node marks the right side of the range while its predecessor (in the tree that was just cut universe) marks the left side of the range. So in order to join the two trees we just have to wedge B under to the left of its parent in A. Similarly for the case where B happens to hang to the right of its parent where we wedge the content of B to the right of its parent. In order to find the wedge insertion point we can just search in the A for the root of NAT. Of course that value is not in NAT but it will find a close value and by taking its predecessor or successor (depending on the search algorithm and if the close value was before or after the value) we find the two nodes between where B should be wedged. Let's call these values lPrime and rPrime. Next is to split A first at lPrime and then at rPrime therefore creating three trees, a First part (FP), middle part (MP) and last part (LP). While these operations were done in the A universe they also need to carry all the other auxiliary trees as in the Tango universe. In the Tango (forest) universe we discover that MD is actually is B however is severed logically from rPrime because its root is marked as isRoot and it appears like a hung auxiliary tree. Since we want that wedged, we "un-mark" it) by resetting its isRoot attribute and making it logically part of rPrime. Now we have the final structure in place but we still need to concatenate it first at rPrime and then at lPrime to absorb all the nodes under the same Joined resulting tree.
The difficulty in doing this is the fact that the standard concatenates do not take nodes but just trees. A two tree and a node operation could be constructed and then repeated to obtain a Tango concatenate; however, it is hard to preserve the RB integrity and is dependant on the order of operations so the resulting structure is different even if it contains the same node. That is an issue because we can not control the exact reproduction of the ideal structure as if generated from the reference tree. It can be done in such a way to contain all nodes and preserve the correct RB tree structure however the geometry is dictated by the RB concatenates and is not necessarily the ideal geometry mirroring perfectly the reference tree.
Fig. 12 Tango cut consisting of split, mark and concatenate operations on an auxiliary tree
So for example let's say search for 23. We obtain A as the result on the first Tango cut on the top auxiliary tree. See Fig. 13 where 22 is the root of NAT.
Fig. 13 Tango tree before a search for 23
We use the value of NAT (22) to search in the tree above and we obtain 20 and 24 as the lPrime and rPrime nodes.
We split at lPrime (20) and we obtain FP as in Fig. 14.
Fig. 14 First sub-tree of Tango tree (FP) after executing the first split of Tango join operation
We then split for the second time at rPrime (24) to get the last tree LP as in Fig. 15.
FIg. 15 Last sub-tree of Tango tree (LP) after executing the second split of the Tango join operation
Next we unmark B which is rooted at 22 and we obtain the result in Fig 16. As you can see 22 now is part of the top of the structure. That makes sense if you look at Fig. 10 representing the ‘virtual�?reference tree. To reach 23 which is our target we would have had to go through 22.
Fig. 16 Sub-tree rooted at rPrime after executing the second split of the Tango join operation
We then concatenate with rPrime and obtain the result in presented in Fig. 17:
Second concatenation takes place and it this particular example will not result in rearranging of the nodes so Fig. 17 is the final result of the Join operation.
Step-1: For the current node check whether it has a left child which is not there in the visited list. If it has then go to step-2 or else step-3.
Step-2: Put that left child in the list of visited nodes and make it your current node in consideration. Go to step-6.
Step-3: For the current node check whether it has a right child. If it has then go to step-4 else go to step-5
Step-4: Make that right child as your current node in consideration. Go to step-6.
Step-5: Check for the threaded node and if its there make it your current node.
Step-6: Go to step-1 if all the nodes are not over otherwise quit
Li step-1 'A' has a left child i.e. B, which has not been visited.So, we put B in our "list of visited nodes" and B becomes our current node in consideration. B step-2 'B' also has a left child, 'D', which is not there in our list of visited nodes. So, we put 'D' in that list and make it our current node in consideration. B D step-3 'D' has no left child, so we print 'D'. Then we check for its right child. 'D' has no right child and thus we check for its thread-link. It has a thread going till node 'B'. So, we make 'B' as our current node in consideration. B D D step-4 'B' certainly has a left child but its already in our list of visited nodes. So, we print 'B'. Then we check for its right child but it doesn't exist. So, we make its threaded node (i.e. 'A') as our current node in consideration. B D D B step-5 'A' has a left child, 'B', but its already there in the list of visited nodes. So, we print 'A'. Then we check for its right child. 'A' has a right child, 'C' and it's not there in our list of visited nodes. So, we add it to that list and we make it our current node in consideration. B D C D B A step-6 'C' has 'E' as the left child and it's not there in our list of visited nodes even. So, we add it to that list and make it our current node in consideration. B D C E D B A step-7 and finally..... D B A E C
