A beam search is most often used to maintain tractability in large systems with insufficient amount of memory to store the entire search tree.[4] For example, it is used in many machine translation systems.[5] To select the best translation, each part is processed, and many different ways of translating the words appear. The top best translations according to their sentence structures are kept and the rest are discarded. The translator then evaluates the translations according to a given criteria, choosing the translation which best keeps the goals. The first use of a beam search was in the Harpy Speech Recognition System, CMU 1976.[6]
A beam search is most often used to maintain tractability in large systems with insufficient amount of memory to store the entire search tree.[4] For example, it is used in many machine translation systems.[5] To select the best translation, each part is processed, and many different ways of translating the words appear. The top best translations according to their sentence structures are kept and the rest are discarded. The translator then evaluates the translations according to a given criteria, choosing the translation which best keeps the goals. The first use of a beam search was in the Harpy Speech Recognition System, CMU 1976.[6]
Even if we do not know a fixed range the number k falls in, we can still determine its value by asking simple yes/no questions of the form "Is k greater than x?" for some number x. As a simple consequence of this, if you can answer the question "Is this integer property k greater than a given value?" in some amount of time then you can find the value of that property in the same amount of time with an added factor of . This is called a reduction, and it is because of this kind of reduction that most complexity theorists concentrate on decision problems, algorithms that produce a simple yes/no answer.
For example, suppose we could answer "Does this n x n matrix have permanent larger than k?" in O(n2) time. Then, by using binary search, we could find the (ceiling of the) permanent itself in O(n2 log p) time, where p is the value of the permanent. Notice that p is not the size of the input, but the value of the output; given a matrix whose maximum item (in absolute value) is m, p is bounded by . Hence log p = O(n log n + log m). A binary search could find the permanent in O(n3 log n + n2 log m).
This approach is used for a number of NP-hard problems, such as
Knapsack problem Integer programming Nonlinear programming Traveling salesman problem (TSP) Quadratic assignment problem (QAP) Maximum satisfiability problem (MAX-SAT) Nearest neighbor search (NNS) Cutting stock problem False noise analysis (FNA) Computational phylogenetics
Branch-and-bound may also be a base of various heuristics. For example, one may wish to stop branching when the gap between the upper and lower bounds becomes smaller than a certain threshold. This is used when the solution is "good enough for practical purposes" and can greatly reduce the computations required. This type of solution is particularly applicable when the cost function used is noisy or is the result of statistical estimates and so is not known precisely but rather only known to lie within a range of values with a specific probability. An example of its application here is in biology when performing cladistic analysis to evaluate evolutionary relationships between organisms, where the data sets are often impractically large without heuristics[citation needed].
For this reason, branch-and-bound techniques are often used in game tree search algorithms, most notably through the use of alpha-beta pruning.
Breadth-first search can be used to solve many problems in graph theory, for example:
Finding all nodes within one connected component Copying Collection, Cheney's algorithm Finding the shortest path between two nodes u and v (with path length measured by number of edges) Testing a graph for bipartiteness (Reverse) Cuthill–McKee mesh numbering Ford–Fulkerson method for computing the maximum flow in a flow network Serialization/Deserialization of a binary tree vs serialization in sorted order, allows the tree to be re-constructed in an efficient manner.
Sorry, your browser either has JavaScript disabled or does not have any supported player. You can download the clip or download a player to play the clip in your browser. Randomized algorithm similar to depth-first search used in generating a maze.
Algorithms that use depth-first search as a building block include:
Finding connected components. Topological sorting. Finding 2-(edge or vertex)-connected components. Finding 3-(edge or vertex)-connected components. Finding the bridges of a graph. Finding strongly connected components. Planarity testing[4][5] Solving puzzles with only one solution, such as mazes. (DFS can be adapted to find all solutions to a maze by only including nodes on the current path in the visited set.) Maze generation may use a randomized depth-first search. Finding biconnectivity in graphs.
Linear search is usually very simple to implement, and is practical when the list has only a few elements, or when performing a single search in an unordered list.
When many values have to be searched in the same list, it often pays to pre-process the list in order to use a faster method. For example, one may sort the list and use binary search, or build any efficient search data structure from it. Should the content of the list change frequently, repeated re-organization may be more trouble than it is worth.
As a result, even though in theory other search algorithms may be faster than linear search (for instance binary search), in practice even on medium sized arrays (around 100 items or less) it might be infeasible to use anything else. On larger arrays, it only makes sense to use other, faster search methods if the data is large enough, because the initial time to prepare (sort) the data is comparable to many linear searches [2]
