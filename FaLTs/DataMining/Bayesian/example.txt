The following mathematical descriptions are fully written out and explained, for ease of implementation.
A typical non-Bayesian HMM with Gaussian observations looks like this:

A typical Bayesian HMM with Gaussian observations looks like this:

A typical non-Bayesian HMM with categorical observations looks like this:

A typical Bayesian HMM with categorical observations looks like this:

Note that in the above Bayesian characterizations, (a concentration parameter) controls the density of the transition matrix. That is, with a high value of (significantly above 1), the probabilities controlling the transition out of a particular state will all be similar, meaning there will be a significantly probability of transitioning to any of the other states. In other words, the path followed by the Markov chain of hidden states will be highly random. With a low value of (significantly below 1), only a small number of the possible transitions out of a given state will have significant probability, meaning that the path followed by the hidden states will be somewhat predictable.
