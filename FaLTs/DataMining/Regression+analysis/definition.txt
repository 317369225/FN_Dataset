In 1959, Arthur Samuel defined machine learning as a "Field of study that gives computers the ability to learn without being explicitly programmed".[2]
Tom M. Mitchell provided a widely quoted, more formal definition: "A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E".[3] This definition is notable for its defining machine learning in fundamentally operational rather than cognitive terms, thus following Alan Turing's proposal in Turing's paper "Computing Machinery and Intelligence" that the question "Can machines think?" be replaced with the question "Can machines do what we (as thinking entities) can do?"[4]
A statistical model is a collection of probability distribution functions or probability density functions (collectively referred to as distributions for brevity). A parametric model is a collection of distributions, each of which is indexed by a unique finite-dimensional parameter: , where is a parameter and is the feasible region of parameters, which is a subset of d-dimensional Euclidean space. A statistical model may be used to describe the set of distributions from which one assumes that a particular data set is sampled. For example, if one assumes that data arise from a univariate Gaussian distribution, then one has assumed a Gaussian model: .
A non-parametric model is a set of probability distributions with infinite dimensional parameters, and might be written as . A semi-parametric model also has infinite dimensional parameters, but is not dense in the space of distributions. For example, a mixture of Gaussians with one Gaussian at each data point is dense is the space of distributions. Formally, if d is the dimension of the parameter, and n is the number of samples, if as and as , then the model is semi-parametric.
Figure 1. The logistic function, with on the horizontal axis and on the vertical axis
An explanation of logistic regression begins with an explanation of the logistic function, which always takes on values between zero and one:[2]

and

and

A graph of the function is shown in figure 1. The input is and the output is . The logistic function is useful because it can take as an input any value from negative infinity to positive infinity, whereas the output is confined to values between 0 and 1. In the above equations, g(X) refers to the logit function of some given predictor X, ln denotes the natural logarithm, is the probability of being a case, is the intercept from the linear regression equation (the value of the criterion when the predictor is equal to zero), is the regression coefficient multiplied by some value of the predictor, base e denotes the exponential function. The first formula illustrates that the probability of being a case is equal to the odds of the exponential function of the linear regression equation. This is important in that it shows that the input of the logistic regression equation (the linear regression equation) can vary from negative to positive infinity and yet, after exponentiating the odds of the equation, the output will vary between zero and one. The second equation illustrates that the logit (i.e., log-odds or natural logarithm of the odds) is equivalent to the linear regression equation. Likewise, the third equation illustrates that the odds of being a case is equivalent to the exponential function of the linear regression equation. This illustrates how the logit serves as a link function between the odds and the linear regression equation. Given that the logit varies from it provides an adequate criterion upon which to conduct linear regression and the logit is easily converted back into the odds.[2]
Example database with 4 items and 5 transactions transaction ID milk bread butter beer 1 1 1 0 0 2 0 0 1 0 3 0 0 0 1 4 1 1 1 0 5 0 1 0 0
Following the original definition by Agrawal et al.[2] the problem of association rule mining is defined as: Let be a set of binary attributes called items. Let be a set of transactions called the database. Each transaction in has a unique transaction ID and contains a subset of the items in . A rule is defined as an implication of the form where and . The sets of items (for short itemsets) and are called antecedent (left-hand-side or LHS) and consequent (right-hand-side or RHS) of the rule respectively.
To illustrate the concepts, we use a small example from the supermarket domain. The set of items is and a small database containing the items (1 codes presence and 0 absence of an item in a transaction) is shown in the table to the right. An example rule for the supermarket could be meaning that if butter and bread are bought, customers also buy milk.
Note: this example is extremely small. In practical applications, a rule needs a support of several hundred transactions before it can be considered statistically significant, and datasets often contain thousands or millions of transactions.
Suppose we have a set of observable random variables, with means .
Suppose for some unknown constants and unobserved random variables , where and , where , we have

Here, the are independently distributed error terms with zero mean and finite variance, which may not be the same for all . Let , so that we have

In matrix terms, we have

If we have observations, then we will have the dimensions , , and . Each column of and denote values for one particular observation, and matrix does not vary across observations.
Also we will impose the following assumptions on .
and are independent. (to make sure that the factors are uncorrelated)
Any solution of the above set of equations following the constraints for is defined as the factors, and as the loading matrix.
Suppose . Then note that from the conditions just imposed on , we have

or

or

Note that for any orthogonal matrix if we set and , the criteria for being factors and factor loadings still hold. Hence a set of factors and factor loadings is identical only up to orthogonal transformations.
X is a Bayesian network with respect to G if its joint probability density function (with respect to a product measure) can be written as a product of the individual density functions, conditional on their parent variables:[10]

where pa(v) is the set of parents of v (i.e. those vertices pointing directly to v via a single edge).
For any set of random variables, the probability of any member of a joint distribution can be calculated from conditional probabilities using the chain rule (given a topological ordering of X) as follows:[10]

Compare this with the definition above, which can be written as:
for each which is a parent of
The difference between the two expressions is the conditional independence of the variables from any of their non-descendents, given the values of their parent variables.
In this case, the solid and empty dots can be correctly classified by any number of linear classifiers. H1 (blue) classifies them correctly, as does H2 (red). H2 could be considered "better" in the sense that it is also furthest from both groups. H3 (green) fails to correctly classify the dots.
If the input feature vector to the classifier is a real vector , then the output score is

where is a real vector of weights and f is a function that converts the dot product of the two vectors into the desired output. (In other words, is a one-form or linear functional mapping onto R.) The weight vector is learned from a set of labeled training samples. Often f is a simple function that maps all values above a certain threshold to the first class and all other values to the second class. A more complex f might give the probability that an item belongs to a certain class.
For a two-class classification problem, one can visualize the operation of a linear classifier as splitting a high-dimensional input space with a hyperplane: all points on one side of the hyperplane are classified as "yes", while the others are classified as "no".
A linear classifier is often used in situations where the speed of classification is an issue, since it is often the fastest classifier, especially when is sparse. However, decision trees can be faster.[citation needed] Also, linear classifiers often work very well when the number of dimensions in is large, as in document classification, where each element in is typically the number of occurrences of a word in a document (see document-term matrix). In such cases, the classifier should be well-regularized.
Figure 1. The logistic function, with on the horizontal axis and on the vertical axis
An explanation of logistic regression begins with an explanation of the logistic function, which always takes on values between zero and one:[2]

and

and

A graph of the function is shown in figure 1. The input is and the output is . The logistic function is useful because it can take as an input any value from negative infinity to positive infinity, whereas the output is confined to values between 0 and 1. In the above equations, g(X) refers to the logit function of some given predictor X, ln denotes the natural logarithm, is the probability of being a case, is the intercept from the linear regression equation (the value of the criterion when the predictor is equal to zero), is the regression coefficient multiplied by some value of the predictor, base e denotes the exponential function. The first formula illustrates that the probability of being a case is equal to the odds of the exponential function of the linear regression equation. This is important in that it shows that the input of the logistic regression equation (the linear regression equation) can vary from negative to positive infinity and yet, after exponentiating the odds of the equation, the output will vary between zero and one. The second equation illustrates that the logit (i.e., log-odds or natural logarithm of the odds) is equivalent to the linear regression equation. Likewise, the third equation illustrates that the odds of being a case is equivalent to the exponential function of the linear regression equation. This illustrates how the logit serves as a link function between the odds and the linear regression equation. Given that the logit varies from it provides an adequate criterion upon which to conduct linear regression and the logit is easily converted back into the odds.[2]
