The simplex algorithm, developed by George Dantzig in 1947, solves LP problems by constructing a feasible solution at a vertex of the polytope and then walking along a path on the edges of the polytope to vertices with non-decreasing values of the objective function until an optimum is reached. In many practical problems, "stalling" occurs: Many pivots are made with no increase in the objective function.[3][4] In rare practical problems, the usual versions of the simplex algorithm may actually "cycle".[4] To avoid cycles, researchers developed new pivoting rules.[5][6][3][4][7][8]
In practice, the simplex algorithm is quite efficient and can be guaranteed to find the global optimum if certain precautions against cycling are taken. The simplex algorithm has been proved to solve "random" problems efficiently, i.e. in a cubic number of steps,[9] which is similar to its behavior on practical problems.[3][10]
However, the simplex algorithm has poor worst-case behavior: Klee and Minty constructed a family of linear programming problems for which the simplex method takes a number of steps exponential in the problem size.[3][6][7] In fact, for some time it was not known whether the linear programming problem was solvable in polynomial time, i.e. of complexity class P.
