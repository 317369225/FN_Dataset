Training a neural network model essentially means selecting one model from the set of allowed models (or, in a Bayesian framework, determining a distribution over the set of allowed models) that minimizes the cost criterion. There are numerous algorithms available for training neural network models; most of them can be viewed as a straightforward application of optimization theory and statistical estimation.
Most of the algorithms used in training artificial neural networks employ some form of gradient descent. This is done by simply taking the derivative of the cost function with respect to the network parameters and then changing those parameters in a gradient-related direction.
Evolutionary methods,[3] gene expression programming,[4] simulated annealing,[5] expectation-maximization, non-parametric methods and particle swarm optimization[6] are some commonly used methods for training neural networks.
See also: machine learning
Below is an example of a learning algorithm for a (single-layer) perceptron. For multilayer perceptrons, where a hidden layer exists, more complicated algorithms such as backpropagation must be used. Alternatively, methods such as the delta rule can be used if the function is non-linear and differentiable, although the one below will work as well.
When multiple perceptrons are combined in an artificial neural network, each output neuron operates independently of all the others; thus, learning each output can be considered in isolation.
We first define some variables:
denotes the output from the perceptron for an input vector . is the bias term, which in the example below we take to be 0. is the training set of samples, where: is the -dimensional input vector. is the desired output value of the perceptron for that input.
We show the values of the nodes as follows:
is the value of the th node of the th training input vector. .
To represent the weights:
is the th value in the weight vector, to be multiplied by the value of the th input node.
An extra dimension, with index , can be added to all input vectors, with , in which case replaces the bias term. To show the time-dependence of , we use:
is the weight at time . is the learning rate, where .
Too high a learning rate makes the perceptron periodically oscillate around the solution unless additional steps are taken.
The appropriate weights are applied to the inputs, and the resulting weighted sum passed to a function that produces the output y.
