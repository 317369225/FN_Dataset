The line goes through the "center of mass" point (x, y). The sum of the residuals is equal to zero, if the model includes a constant: The linear combination of the residuals, in which the coefficients are the x-values, is equal to zero:
The basic idea of bootstrapping is that the sample we have collected is often the best guess we have as to the shape of the population from which the sample was taken. For instance, a sample of observations with two peaks in its histogram would not be well approximated by a Gaussian or normal bell curve, which has only one peak. Therefore, instead of assuming a mathematical shape (like the normal curve or some other) for the population, we instead use the shape of the sample.
As an example, assume we are interested in the average (or mean) height of people worldwide. We cannot measure all the people in the global population, so instead we sample only a tiny part of it, and measure that. Assume the sample is of size N; that is, we measure the heights of N individuals. From that single sample, only one value of the mean can be obtained. In order to reason about the population, we need some sense of the variability of the mean that we have computed.
To use the simplest bootstrap technique, we take our original data set of N heights, and, using a computer, make a new sample (called a bootstrap sample) that is also of size N. This new sample is taken from the original using sampling with replacement so it is not identical with the original "real" sample. We repeat this a lot (maybe 1000 or 10,000 times), and for each of these bootstrap samples we compute its mean (each of these are called bootstrap estimates). We now have a histogram of bootstrap means. This provides an estimate of the shape of the distribution of the mean from which we can answer questions about how much the mean varies. (The method here, described for the mean, can be applied to almost any other statistic or estimator.)
The key principle of the bootstrap is to provide a way to simulate repeated observations from an unknown population using the obtained sample as a basis.
Lafferty, McCallum and Pereira[1] define a CRF on observations and random variables as follows:
Let be a graph such that , so that is indexed by the vertices of . Then is a conditional random field when the random variables , conditioned on , obey the Markov property with respect to the graph: , where means that and are neighbors in .
What this means is that a CRF is a undirected graphical model whose nodes can be divided into exactly two disjoint sets and , the observed and output variables, respectively; the conditional distribution is then modeled.
Such models assist in controlling for unobserved heterogeneity when this heterogeneity is constant over time and correlated with independent variables. This constant can be removed from the data through differencing, for example by taking a first difference which will remove any time invariant components of the model.
There are two common assumptions made about the individual specific effect, the random effects assumption and the fixed effects assumption. The random effects assumption (made in a random effects model) is that the individual specific effects are uncorrelated with the independent variables. The fixed effect assumption is that the individual specific effect is correlated with the independent variables. If the random effects assumption holds, the random effects model is more efficient than the fixed effects model. However, if this assumption does not hold (i.e., if the Durbinâ€“Watson test fails), the random effects model is not consistent.
X is a Bayesian network with respect to G if it satisfies the local Markov property: each variable is conditionally independent of its non-descendants given its parent variables:[11]

where de(v) is the set of descendants of v.
This can also be expressed in terms similar to the first definition, as
for each which is not a descendent of for each which is a parent of
Note that the set of parents is a subset of the set of non-descendants because the graph is acyclic.
The line goes through the "center of mass" point (x, y). The sum of the residuals is equal to zero, if the model includes a constant: The linear combination of the residuals, in which the coefficients are the x-values, is equal to zero:
